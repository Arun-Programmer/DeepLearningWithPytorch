{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Blood Pressure (s/d)</th>\n",
       "      <th>Cholesterol Level (mg/dL)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Blood Glucose Level (mg/dL)</th>\n",
       "      <th>Bone Density (g/cm²)</th>\n",
       "      <th>Vision Sharpness</th>\n",
       "      <th>Hearing Ability (dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Family History</th>\n",
       "      <th>Cognitive Function</th>\n",
       "      <th>Mental Health Status</th>\n",
       "      <th>Sleep Patterns</th>\n",
       "      <th>Stress Levels</th>\n",
       "      <th>Pollution Exposure</th>\n",
       "      <th>Sun Exposure</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Income Level</th>\n",
       "      <th>Age (years)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>171.148359</td>\n",
       "      <td>86.185197</td>\n",
       "      <td>151/109</td>\n",
       "      <td>259.465814</td>\n",
       "      <td>29.423017</td>\n",
       "      <td>157.652848</td>\n",
       "      <td>0.132868</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>58.786198</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.059172</td>\n",
       "      <td>Good</td>\n",
       "      <td>Insomnia</td>\n",
       "      <td>2.797064</td>\n",
       "      <td>5.142344</td>\n",
       "      <td>7.108975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>172.946206</td>\n",
       "      <td>79.641937</td>\n",
       "      <td>134/112</td>\n",
       "      <td>263.630292</td>\n",
       "      <td>26.626847</td>\n",
       "      <td>118.507805</td>\n",
       "      <td>0.629534</td>\n",
       "      <td>0.267312</td>\n",
       "      <td>54.635270</td>\n",
       "      <td>...</td>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>45.312298</td>\n",
       "      <td>Good</td>\n",
       "      <td>Normal</td>\n",
       "      <td>9.339930</td>\n",
       "      <td>7.272720</td>\n",
       "      <td>3.918489</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Medium</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>155.945488</td>\n",
       "      <td>49.167058</td>\n",
       "      <td>160/101</td>\n",
       "      <td>207.846206</td>\n",
       "      <td>20.217553</td>\n",
       "      <td>143.587550</td>\n",
       "      <td>0.473487</td>\n",
       "      <td>0.248667</td>\n",
       "      <td>54.564632</td>\n",
       "      <td>...</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>56.246991</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Insomnia</td>\n",
       "      <td>9.234637</td>\n",
       "      <td>8.500386</td>\n",
       "      <td>5.393408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>169.078298</td>\n",
       "      <td>56.017921</td>\n",
       "      <td>133/94</td>\n",
       "      <td>253.283779</td>\n",
       "      <td>19.595270</td>\n",
       "      <td>137.448581</td>\n",
       "      <td>1.184315</td>\n",
       "      <td>0.513818</td>\n",
       "      <td>79.722963</td>\n",
       "      <td>...</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>55.196092</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Insomnia</td>\n",
       "      <td>4.693446</td>\n",
       "      <td>7.555511</td>\n",
       "      <td>2.745578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>163.758355</td>\n",
       "      <td>73.966304</td>\n",
       "      <td>170/106</td>\n",
       "      <td>236.119899</td>\n",
       "      <td>27.582078</td>\n",
       "      <td>145.328695</td>\n",
       "      <td>0.434562</td>\n",
       "      <td>0.306864</td>\n",
       "      <td>52.479469</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.023379</td>\n",
       "      <td>Good</td>\n",
       "      <td>Normal</td>\n",
       "      <td>4.038537</td>\n",
       "      <td>9.429097</td>\n",
       "      <td>3.878435</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>High</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>Male</td>\n",
       "      <td>161.632502</td>\n",
       "      <td>88.323405</td>\n",
       "      <td>134/91</td>\n",
       "      <td>204.175510</td>\n",
       "      <td>33.807917</td>\n",
       "      <td>112.075747</td>\n",
       "      <td>1.583006</td>\n",
       "      <td>0.665907</td>\n",
       "      <td>27.997736</td>\n",
       "      <td>...</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>57.820282</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Normal</td>\n",
       "      <td>8.091897</td>\n",
       "      <td>9.846088</td>\n",
       "      <td>9.111205</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>High</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>Male</td>\n",
       "      <td>163.443512</td>\n",
       "      <td>93.217007</td>\n",
       "      <td>110/78</td>\n",
       "      <td>197.384424</td>\n",
       "      <td>34.894725</td>\n",
       "      <td>101.177692</td>\n",
       "      <td>1.785129</td>\n",
       "      <td>0.720304</td>\n",
       "      <td>32.866623</td>\n",
       "      <td>...</td>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>68.783715</td>\n",
       "      <td>Good</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2.427081</td>\n",
       "      <td>1.141303</td>\n",
       "      <td>8.578184</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Medium</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Male</td>\n",
       "      <td>177.857644</td>\n",
       "      <td>86.258847</td>\n",
       "      <td>159/116</td>\n",
       "      <td>238.641542</td>\n",
       "      <td>27.268332</td>\n",
       "      <td>110.548146</td>\n",
       "      <td>0.366012</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>39.756270</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.133807</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Normal</td>\n",
       "      <td>7.671837</td>\n",
       "      <td>5.101134</td>\n",
       "      <td>2.199199</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Low</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>Female</td>\n",
       "      <td>162.287164</td>\n",
       "      <td>41.371018</td>\n",
       "      <td>134/82</td>\n",
       "      <td>198.244328</td>\n",
       "      <td>15.708252</td>\n",
       "      <td>123.704379</td>\n",
       "      <td>1.452963</td>\n",
       "      <td>0.648158</td>\n",
       "      <td>43.338594</td>\n",
       "      <td>...</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>68.864629</td>\n",
       "      <td>Good</td>\n",
       "      <td>Insomnia</td>\n",
       "      <td>7.920076</td>\n",
       "      <td>4.452130</td>\n",
       "      <td>5.051613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>Male</td>\n",
       "      <td>175.341710</td>\n",
       "      <td>78.718038</td>\n",
       "      <td>167/91</td>\n",
       "      <td>279.118184</td>\n",
       "      <td>25.603762</td>\n",
       "      <td>156.577316</td>\n",
       "      <td>0.704319</td>\n",
       "      <td>0.578625</td>\n",
       "      <td>43.926230</td>\n",
       "      <td>...</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>60.892114</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Insomnia</td>\n",
       "      <td>8.013913</td>\n",
       "      <td>4.624968</td>\n",
       "      <td>3.745138</td>\n",
       "      <td>High School</td>\n",
       "      <td>High</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Height (cm)  Weight (kg) Blood Pressure (s/d)  \\\n",
       "0       Male   171.148359    86.185197              151/109   \n",
       "1       Male   172.946206    79.641937              134/112   \n",
       "2     Female   155.945488    49.167058              160/101   \n",
       "3     Female   169.078298    56.017921               133/94   \n",
       "4     Female   163.758355    73.966304              170/106   \n",
       "...      ...          ...          ...                  ...   \n",
       "2995    Male   161.632502    88.323405               134/91   \n",
       "2996    Male   163.443512    93.217007               110/78   \n",
       "2997    Male   177.857644    86.258847              159/116   \n",
       "2998  Female   162.287164    41.371018               134/82   \n",
       "2999    Male   175.341710    78.718038               167/91   \n",
       "\n",
       "      Cholesterol Level (mg/dL)        BMI  Blood Glucose Level (mg/dL)  \\\n",
       "0                    259.465814  29.423017                   157.652848   \n",
       "1                    263.630292  26.626847                   118.507805   \n",
       "2                    207.846206  20.217553                   143.587550   \n",
       "3                    253.283779  19.595270                   137.448581   \n",
       "4                    236.119899  27.582078                   145.328695   \n",
       "...                         ...        ...                          ...   \n",
       "2995                 204.175510  33.807917                   112.075747   \n",
       "2996                 197.384424  34.894725                   101.177692   \n",
       "2997                 238.641542  27.268332                   110.548146   \n",
       "2998                 198.244328  15.708252                   123.704379   \n",
       "2999                 279.118184  25.603762                   156.577316   \n",
       "\n",
       "      Bone Density (g/cm²)  Vision Sharpness  Hearing Ability (dB)  ...  \\\n",
       "0                 0.132868          0.200000             58.786198  ...   \n",
       "1                 0.629534          0.267312             54.635270  ...   \n",
       "2                 0.473487          0.248667             54.564632  ...   \n",
       "3                 1.184315          0.513818             79.722963  ...   \n",
       "4                 0.434562          0.306864             52.479469  ...   \n",
       "...                    ...               ...                   ...  ...   \n",
       "2995              1.583006          0.665907             27.997736  ...   \n",
       "2996              1.785129          0.720304             32.866623  ...   \n",
       "2997              0.366012          0.200000             39.756270  ...   \n",
       "2998              1.452963          0.648158             43.338594  ...   \n",
       "2999              0.704319          0.578625             43.926230  ...   \n",
       "\n",
       "     Family History Cognitive Function Mental Health Status Sleep Patterns  \\\n",
       "0               NaN          44.059172                 Good       Insomnia   \n",
       "1     Heart Disease          45.312298                 Good         Normal   \n",
       "2      Hypertension          56.246991                 Poor       Insomnia   \n",
       "3      Hypertension          55.196092                 Poor       Insomnia   \n",
       "4               NaN          53.023379                 Good         Normal   \n",
       "...             ...                ...                  ...            ...   \n",
       "2995       Diabetes          57.820282                 Fair         Normal   \n",
       "2996  Heart Disease          68.783715                 Good         Normal   \n",
       "2997            NaN          50.133807                 Fair         Normal   \n",
       "2998   Hypertension          68.864629                 Good       Insomnia   \n",
       "2999   Hypertension          60.892114                 Poor       Insomnia   \n",
       "\n",
       "     Stress Levels Pollution Exposure Sun Exposure  Education Level  \\\n",
       "0         2.797064           5.142344     7.108975              NaN   \n",
       "1         9.339930           7.272720     3.918489    Undergraduate   \n",
       "2         9.234637           8.500386     5.393408              NaN   \n",
       "3         4.693446           7.555511     2.745578              NaN   \n",
       "4         4.038537           9.429097     3.878435    Undergraduate   \n",
       "...            ...                ...          ...              ...   \n",
       "2995      8.091897           9.846088     9.111205    Undergraduate   \n",
       "2996      2.427081           1.141303     8.578184    Undergraduate   \n",
       "2997      7.671837           5.101134     2.199199    Undergraduate   \n",
       "2998      7.920076           4.452130     5.051613              NaN   \n",
       "2999      8.013913           4.624968     3.745138      High School   \n",
       "\n",
       "     Income Level Age (years)  \n",
       "0          Medium          89  \n",
       "1          Medium          77  \n",
       "2          Medium          70  \n",
       "3             Low          52  \n",
       "4            High          79  \n",
       "...           ...         ...  \n",
       "2995         High          22  \n",
       "2996       Medium          19  \n",
       "2997          Low          85  \n",
       "2998         High          30  \n",
       "2999         High          66  \n",
       "\n",
       "[3000 rows x 26 columns]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "train_df = pd.read_csv(\"Train.csv\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Blood Pressure (s/d)</th>\n",
       "      <th>Cholesterol Level (mg/dL)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Blood Glucose Level (mg/dL)</th>\n",
       "      <th>Bone Density (g/cm²)</th>\n",
       "      <th>Vision Sharpness</th>\n",
       "      <th>Hearing Ability (dB)</th>\n",
       "      <th>Physical Activity Level</th>\n",
       "      <th>Chronic Diseases</th>\n",
       "      <th>Medication Use</th>\n",
       "      <th>Cognitive Function</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Age (years)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.148359</td>\n",
       "      <td>86.185197</td>\n",
       "      <td>151/109</td>\n",
       "      <td>259.465814</td>\n",
       "      <td>29.423017</td>\n",
       "      <td>157.652848</td>\n",
       "      <td>0.132868</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>58.786198</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.059172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.946206</td>\n",
       "      <td>79.641937</td>\n",
       "      <td>134/112</td>\n",
       "      <td>263.630292</td>\n",
       "      <td>26.626847</td>\n",
       "      <td>118.507805</td>\n",
       "      <td>0.629534</td>\n",
       "      <td>0.267312</td>\n",
       "      <td>54.635270</td>\n",
       "      <td>Low</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.312298</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155.945488</td>\n",
       "      <td>49.167058</td>\n",
       "      <td>160/101</td>\n",
       "      <td>207.846206</td>\n",
       "      <td>20.217553</td>\n",
       "      <td>143.587550</td>\n",
       "      <td>0.473487</td>\n",
       "      <td>0.248667</td>\n",
       "      <td>54.564632</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Regular</td>\n",
       "      <td>56.246991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169.078298</td>\n",
       "      <td>56.017921</td>\n",
       "      <td>133/94</td>\n",
       "      <td>253.283779</td>\n",
       "      <td>19.595270</td>\n",
       "      <td>137.448581</td>\n",
       "      <td>1.184315</td>\n",
       "      <td>0.513818</td>\n",
       "      <td>79.722963</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Occasional</td>\n",
       "      <td>55.196092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>163.758355</td>\n",
       "      <td>73.966304</td>\n",
       "      <td>170/106</td>\n",
       "      <td>236.119899</td>\n",
       "      <td>27.582078</td>\n",
       "      <td>145.328695</td>\n",
       "      <td>0.434562</td>\n",
       "      <td>0.306864</td>\n",
       "      <td>52.479469</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.023379</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>161.632502</td>\n",
       "      <td>88.323405</td>\n",
       "      <td>134/91</td>\n",
       "      <td>204.175510</td>\n",
       "      <td>33.807917</td>\n",
       "      <td>112.075747</td>\n",
       "      <td>1.583006</td>\n",
       "      <td>0.665907</td>\n",
       "      <td>27.997736</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Regular</td>\n",
       "      <td>57.820282</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>163.443512</td>\n",
       "      <td>93.217007</td>\n",
       "      <td>110/78</td>\n",
       "      <td>197.384424</td>\n",
       "      <td>34.894725</td>\n",
       "      <td>101.177692</td>\n",
       "      <td>1.785129</td>\n",
       "      <td>0.720304</td>\n",
       "      <td>32.866623</td>\n",
       "      <td>Low</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Occasional</td>\n",
       "      <td>68.783715</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>177.857644</td>\n",
       "      <td>86.258847</td>\n",
       "      <td>159/116</td>\n",
       "      <td>238.641542</td>\n",
       "      <td>27.268332</td>\n",
       "      <td>110.548146</td>\n",
       "      <td>0.366012</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>39.756270</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.133807</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>162.287164</td>\n",
       "      <td>41.371018</td>\n",
       "      <td>134/82</td>\n",
       "      <td>198.244328</td>\n",
       "      <td>15.708252</td>\n",
       "      <td>123.704379</td>\n",
       "      <td>1.452963</td>\n",
       "      <td>0.648158</td>\n",
       "      <td>43.338594</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Regular</td>\n",
       "      <td>68.864629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>175.341710</td>\n",
       "      <td>78.718038</td>\n",
       "      <td>167/91</td>\n",
       "      <td>279.118184</td>\n",
       "      <td>25.603762</td>\n",
       "      <td>156.577316</td>\n",
       "      <td>0.704319</td>\n",
       "      <td>0.578625</td>\n",
       "      <td>43.926230</td>\n",
       "      <td>High</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.892114</td>\n",
       "      <td>High School</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Height (cm)  Weight (kg) Blood Pressure (s/d)  \\\n",
       "0      171.148359    86.185197              151/109   \n",
       "1      172.946206    79.641937              134/112   \n",
       "2      155.945488    49.167058              160/101   \n",
       "3      169.078298    56.017921               133/94   \n",
       "4      163.758355    73.966304              170/106   \n",
       "...           ...          ...                  ...   \n",
       "2995   161.632502    88.323405               134/91   \n",
       "2996   163.443512    93.217007               110/78   \n",
       "2997   177.857644    86.258847              159/116   \n",
       "2998   162.287164    41.371018               134/82   \n",
       "2999   175.341710    78.718038               167/91   \n",
       "\n",
       "      Cholesterol Level (mg/dL)        BMI  Blood Glucose Level (mg/dL)  \\\n",
       "0                    259.465814  29.423017                   157.652848   \n",
       "1                    263.630292  26.626847                   118.507805   \n",
       "2                    207.846206  20.217553                   143.587550   \n",
       "3                    253.283779  19.595270                   137.448581   \n",
       "4                    236.119899  27.582078                   145.328695   \n",
       "...                         ...        ...                          ...   \n",
       "2995                 204.175510  33.807917                   112.075747   \n",
       "2996                 197.384424  34.894725                   101.177692   \n",
       "2997                 238.641542  27.268332                   110.548146   \n",
       "2998                 198.244328  15.708252                   123.704379   \n",
       "2999                 279.118184  25.603762                   156.577316   \n",
       "\n",
       "      Bone Density (g/cm²)  Vision Sharpness  Hearing Ability (dB)  \\\n",
       "0                 0.132868          0.200000             58.786198   \n",
       "1                 0.629534          0.267312             54.635270   \n",
       "2                 0.473487          0.248667             54.564632   \n",
       "3                 1.184315          0.513818             79.722963   \n",
       "4                 0.434562          0.306864             52.479469   \n",
       "...                    ...               ...                   ...   \n",
       "2995              1.583006          0.665907             27.997736   \n",
       "2996              1.785129          0.720304             32.866623   \n",
       "2997              0.366012          0.200000             39.756270   \n",
       "2998              1.452963          0.648158             43.338594   \n",
       "2999              0.704319          0.578625             43.926230   \n",
       "\n",
       "     Physical Activity Level Chronic Diseases Medication Use  \\\n",
       "0                   Moderate              NaN            NaN   \n",
       "1                        Low     Hypertension            NaN   \n",
       "2                   Moderate     Hypertension        Regular   \n",
       "3                   Moderate         Diabetes     Occasional   \n",
       "4                        Low              NaN            NaN   \n",
       "...                      ...              ...            ...   \n",
       "2995                Moderate     Hypertension        Regular   \n",
       "2996                     Low         Diabetes     Occasional   \n",
       "2997                Moderate              NaN            NaN   \n",
       "2998                Moderate         Diabetes        Regular   \n",
       "2999                    High     Hypertension            NaN   \n",
       "\n",
       "      Cognitive Function Education Level  Age (years)  \n",
       "0              44.059172             NaN           89  \n",
       "1              45.312298   Undergraduate           77  \n",
       "2              56.246991             NaN           70  \n",
       "3              55.196092             NaN           52  \n",
       "4              53.023379   Undergraduate           79  \n",
       "...                  ...             ...          ...  \n",
       "2995           57.820282   Undergraduate           22  \n",
       "2996           68.783715   Undergraduate           19  \n",
       "2997           50.133807   Undergraduate           85  \n",
       "2998           68.864629             NaN           30  \n",
       "2999           60.892114     High School           66  \n",
       "\n",
       "[3000 rows x 15 columns]"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = train_df.drop([\"Gender\",\"Smoking Status\", \"Alcohol Consumption\", \"Diet\", \"Family History\", \"Mental Health Status\", \"Sleep Patterns\", \"Stress Levels\", \"Pollution Exposure\", \"Sun Exposure\", \"Income Level\"], axis='columns')\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chronic Diseases', 'Medication Use', 'Education Level']"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_with_empty_cells = clean_df.columns[clean_df.isna().any()].tolist()\n",
    "columns_with_empty_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Blood Pressure (s/d)</th>\n",
       "      <th>Cholesterol Level (mg/dL)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Blood Glucose Level (mg/dL)</th>\n",
       "      <th>Bone Density (g/cm²)</th>\n",
       "      <th>Vision Sharpness</th>\n",
       "      <th>Hearing Ability (dB)</th>\n",
       "      <th>Physical Activity Level</th>\n",
       "      <th>Chronic Diseases</th>\n",
       "      <th>Medication Use</th>\n",
       "      <th>Cognitive Function</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Age (years)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.148359</td>\n",
       "      <td>86.185197</td>\n",
       "      <td>151/109</td>\n",
       "      <td>259.465814</td>\n",
       "      <td>29.423017</td>\n",
       "      <td>157.652848</td>\n",
       "      <td>0.132868</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>58.786198</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>None1</td>\n",
       "      <td>None2</td>\n",
       "      <td>44.059172</td>\n",
       "      <td>None3</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.946206</td>\n",
       "      <td>79.641937</td>\n",
       "      <td>134/112</td>\n",
       "      <td>263.630292</td>\n",
       "      <td>26.626847</td>\n",
       "      <td>118.507805</td>\n",
       "      <td>0.629534</td>\n",
       "      <td>0.267312</td>\n",
       "      <td>54.635270</td>\n",
       "      <td>Low</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>None2</td>\n",
       "      <td>45.312298</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155.945488</td>\n",
       "      <td>49.167058</td>\n",
       "      <td>160/101</td>\n",
       "      <td>207.846206</td>\n",
       "      <td>20.217553</td>\n",
       "      <td>143.587550</td>\n",
       "      <td>0.473487</td>\n",
       "      <td>0.248667</td>\n",
       "      <td>54.564632</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Regular</td>\n",
       "      <td>56.246991</td>\n",
       "      <td>None3</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169.078298</td>\n",
       "      <td>56.017921</td>\n",
       "      <td>133/94</td>\n",
       "      <td>253.283779</td>\n",
       "      <td>19.595270</td>\n",
       "      <td>137.448581</td>\n",
       "      <td>1.184315</td>\n",
       "      <td>0.513818</td>\n",
       "      <td>79.722963</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Occasional</td>\n",
       "      <td>55.196092</td>\n",
       "      <td>None3</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>163.758355</td>\n",
       "      <td>73.966304</td>\n",
       "      <td>170/106</td>\n",
       "      <td>236.119899</td>\n",
       "      <td>27.582078</td>\n",
       "      <td>145.328695</td>\n",
       "      <td>0.434562</td>\n",
       "      <td>0.306864</td>\n",
       "      <td>52.479469</td>\n",
       "      <td>Low</td>\n",
       "      <td>None1</td>\n",
       "      <td>None2</td>\n",
       "      <td>53.023379</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>161.632502</td>\n",
       "      <td>88.323405</td>\n",
       "      <td>134/91</td>\n",
       "      <td>204.175510</td>\n",
       "      <td>33.807917</td>\n",
       "      <td>112.075747</td>\n",
       "      <td>1.583006</td>\n",
       "      <td>0.665907</td>\n",
       "      <td>27.997736</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Regular</td>\n",
       "      <td>57.820282</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>163.443512</td>\n",
       "      <td>93.217007</td>\n",
       "      <td>110/78</td>\n",
       "      <td>197.384424</td>\n",
       "      <td>34.894725</td>\n",
       "      <td>101.177692</td>\n",
       "      <td>1.785129</td>\n",
       "      <td>0.720304</td>\n",
       "      <td>32.866623</td>\n",
       "      <td>Low</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Occasional</td>\n",
       "      <td>68.783715</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>177.857644</td>\n",
       "      <td>86.258847</td>\n",
       "      <td>159/116</td>\n",
       "      <td>238.641542</td>\n",
       "      <td>27.268332</td>\n",
       "      <td>110.548146</td>\n",
       "      <td>0.366012</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>39.756270</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>None1</td>\n",
       "      <td>None2</td>\n",
       "      <td>50.133807</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>162.287164</td>\n",
       "      <td>41.371018</td>\n",
       "      <td>134/82</td>\n",
       "      <td>198.244328</td>\n",
       "      <td>15.708252</td>\n",
       "      <td>123.704379</td>\n",
       "      <td>1.452963</td>\n",
       "      <td>0.648158</td>\n",
       "      <td>43.338594</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Regular</td>\n",
       "      <td>68.864629</td>\n",
       "      <td>None3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>175.341710</td>\n",
       "      <td>78.718038</td>\n",
       "      <td>167/91</td>\n",
       "      <td>279.118184</td>\n",
       "      <td>25.603762</td>\n",
       "      <td>156.577316</td>\n",
       "      <td>0.704319</td>\n",
       "      <td>0.578625</td>\n",
       "      <td>43.926230</td>\n",
       "      <td>High</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>None2</td>\n",
       "      <td>60.892114</td>\n",
       "      <td>High School</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Height (cm)  Weight (kg) Blood Pressure (s/d)  \\\n",
       "0      171.148359    86.185197              151/109   \n",
       "1      172.946206    79.641937              134/112   \n",
       "2      155.945488    49.167058              160/101   \n",
       "3      169.078298    56.017921               133/94   \n",
       "4      163.758355    73.966304              170/106   \n",
       "...           ...          ...                  ...   \n",
       "2995   161.632502    88.323405               134/91   \n",
       "2996   163.443512    93.217007               110/78   \n",
       "2997   177.857644    86.258847              159/116   \n",
       "2998   162.287164    41.371018               134/82   \n",
       "2999   175.341710    78.718038               167/91   \n",
       "\n",
       "      Cholesterol Level (mg/dL)        BMI  Blood Glucose Level (mg/dL)  \\\n",
       "0                    259.465814  29.423017                   157.652848   \n",
       "1                    263.630292  26.626847                   118.507805   \n",
       "2                    207.846206  20.217553                   143.587550   \n",
       "3                    253.283779  19.595270                   137.448581   \n",
       "4                    236.119899  27.582078                   145.328695   \n",
       "...                         ...        ...                          ...   \n",
       "2995                 204.175510  33.807917                   112.075747   \n",
       "2996                 197.384424  34.894725                   101.177692   \n",
       "2997                 238.641542  27.268332                   110.548146   \n",
       "2998                 198.244328  15.708252                   123.704379   \n",
       "2999                 279.118184  25.603762                   156.577316   \n",
       "\n",
       "      Bone Density (g/cm²)  Vision Sharpness  Hearing Ability (dB)  \\\n",
       "0                 0.132868          0.200000             58.786198   \n",
       "1                 0.629534          0.267312             54.635270   \n",
       "2                 0.473487          0.248667             54.564632   \n",
       "3                 1.184315          0.513818             79.722963   \n",
       "4                 0.434562          0.306864             52.479469   \n",
       "...                    ...               ...                   ...   \n",
       "2995              1.583006          0.665907             27.997736   \n",
       "2996              1.785129          0.720304             32.866623   \n",
       "2997              0.366012          0.200000             39.756270   \n",
       "2998              1.452963          0.648158             43.338594   \n",
       "2999              0.704319          0.578625             43.926230   \n",
       "\n",
       "     Physical Activity Level Chronic Diseases Medication Use  \\\n",
       "0                   Moderate            None1          None2   \n",
       "1                        Low     Hypertension          None2   \n",
       "2                   Moderate     Hypertension        Regular   \n",
       "3                   Moderate         Diabetes     Occasional   \n",
       "4                        Low            None1          None2   \n",
       "...                      ...              ...            ...   \n",
       "2995                Moderate     Hypertension        Regular   \n",
       "2996                     Low         Diabetes     Occasional   \n",
       "2997                Moderate            None1          None2   \n",
       "2998                Moderate         Diabetes        Regular   \n",
       "2999                    High     Hypertension          None2   \n",
       "\n",
       "      Cognitive Function Education Level  Age (years)  \n",
       "0              44.059172           None3           89  \n",
       "1              45.312298   Undergraduate           77  \n",
       "2              56.246991           None3           70  \n",
       "3              55.196092           None3           52  \n",
       "4              53.023379   Undergraduate           79  \n",
       "...                  ...             ...          ...  \n",
       "2995           57.820282   Undergraduate           22  \n",
       "2996           68.783715   Undergraduate           19  \n",
       "2997           50.133807   Undergraduate           85  \n",
       "2998           68.864629           None3           30  \n",
       "2999           60.892114     High School           66  \n",
       "\n",
       "[3000 rows x 15 columns]"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1\n",
    "for col in columns_with_empty_cells:\n",
    "    clean_df[col] = clean_df[col].fillna(f\"None{i}\")\n",
    "    i+=1\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Blood Pressure (s/d)</th>\n",
       "      <th>Cholesterol Level (mg/dL)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Blood Glucose Level (mg/dL)</th>\n",
       "      <th>Bone Density (g/cm²)</th>\n",
       "      <th>Vision Sharpness</th>\n",
       "      <th>Hearing Ability (dB)</th>\n",
       "      <th>Physical Activity Level</th>\n",
       "      <th>Chronic Diseases</th>\n",
       "      <th>Medication Use</th>\n",
       "      <th>Cognitive Function</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Age (years)</th>\n",
       "      <th>Systolic Blood Pressure</th>\n",
       "      <th>Diastolic Blood Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.148359</td>\n",
       "      <td>86.185197</td>\n",
       "      <td>151/109</td>\n",
       "      <td>259.465814</td>\n",
       "      <td>29.423017</td>\n",
       "      <td>157.652848</td>\n",
       "      <td>0.132868</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>58.786198</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>None1</td>\n",
       "      <td>None2</td>\n",
       "      <td>44.059172</td>\n",
       "      <td>None3</td>\n",
       "      <td>89</td>\n",
       "      <td>151</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.946206</td>\n",
       "      <td>79.641937</td>\n",
       "      <td>134/112</td>\n",
       "      <td>263.630292</td>\n",
       "      <td>26.626847</td>\n",
       "      <td>118.507805</td>\n",
       "      <td>0.629534</td>\n",
       "      <td>0.267312</td>\n",
       "      <td>54.635270</td>\n",
       "      <td>Low</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>None2</td>\n",
       "      <td>45.312298</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>77</td>\n",
       "      <td>134</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155.945488</td>\n",
       "      <td>49.167058</td>\n",
       "      <td>160/101</td>\n",
       "      <td>207.846206</td>\n",
       "      <td>20.217553</td>\n",
       "      <td>143.587550</td>\n",
       "      <td>0.473487</td>\n",
       "      <td>0.248667</td>\n",
       "      <td>54.564632</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Regular</td>\n",
       "      <td>56.246991</td>\n",
       "      <td>None3</td>\n",
       "      <td>70</td>\n",
       "      <td>160</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169.078298</td>\n",
       "      <td>56.017921</td>\n",
       "      <td>133/94</td>\n",
       "      <td>253.283779</td>\n",
       "      <td>19.595270</td>\n",
       "      <td>137.448581</td>\n",
       "      <td>1.184315</td>\n",
       "      <td>0.513818</td>\n",
       "      <td>79.722963</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Occasional</td>\n",
       "      <td>55.196092</td>\n",
       "      <td>None3</td>\n",
       "      <td>52</td>\n",
       "      <td>133</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>163.758355</td>\n",
       "      <td>73.966304</td>\n",
       "      <td>170/106</td>\n",
       "      <td>236.119899</td>\n",
       "      <td>27.582078</td>\n",
       "      <td>145.328695</td>\n",
       "      <td>0.434562</td>\n",
       "      <td>0.306864</td>\n",
       "      <td>52.479469</td>\n",
       "      <td>Low</td>\n",
       "      <td>None1</td>\n",
       "      <td>None2</td>\n",
       "      <td>53.023379</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>79</td>\n",
       "      <td>170</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>161.632502</td>\n",
       "      <td>88.323405</td>\n",
       "      <td>134/91</td>\n",
       "      <td>204.175510</td>\n",
       "      <td>33.807917</td>\n",
       "      <td>112.075747</td>\n",
       "      <td>1.583006</td>\n",
       "      <td>0.665907</td>\n",
       "      <td>27.997736</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Regular</td>\n",
       "      <td>57.820282</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>22</td>\n",
       "      <td>134</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>163.443512</td>\n",
       "      <td>93.217007</td>\n",
       "      <td>110/78</td>\n",
       "      <td>197.384424</td>\n",
       "      <td>34.894725</td>\n",
       "      <td>101.177692</td>\n",
       "      <td>1.785129</td>\n",
       "      <td>0.720304</td>\n",
       "      <td>32.866623</td>\n",
       "      <td>Low</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Occasional</td>\n",
       "      <td>68.783715</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>177.857644</td>\n",
       "      <td>86.258847</td>\n",
       "      <td>159/116</td>\n",
       "      <td>238.641542</td>\n",
       "      <td>27.268332</td>\n",
       "      <td>110.548146</td>\n",
       "      <td>0.366012</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>39.756270</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>None1</td>\n",
       "      <td>None2</td>\n",
       "      <td>50.133807</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>85</td>\n",
       "      <td>159</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>162.287164</td>\n",
       "      <td>41.371018</td>\n",
       "      <td>134/82</td>\n",
       "      <td>198.244328</td>\n",
       "      <td>15.708252</td>\n",
       "      <td>123.704379</td>\n",
       "      <td>1.452963</td>\n",
       "      <td>0.648158</td>\n",
       "      <td>43.338594</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Regular</td>\n",
       "      <td>68.864629</td>\n",
       "      <td>None3</td>\n",
       "      <td>30</td>\n",
       "      <td>134</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>175.341710</td>\n",
       "      <td>78.718038</td>\n",
       "      <td>167/91</td>\n",
       "      <td>279.118184</td>\n",
       "      <td>25.603762</td>\n",
       "      <td>156.577316</td>\n",
       "      <td>0.704319</td>\n",
       "      <td>0.578625</td>\n",
       "      <td>43.926230</td>\n",
       "      <td>High</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>None2</td>\n",
       "      <td>60.892114</td>\n",
       "      <td>High School</td>\n",
       "      <td>66</td>\n",
       "      <td>167</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Height (cm)  Weight (kg) Blood Pressure (s/d)  \\\n",
       "0      171.148359    86.185197              151/109   \n",
       "1      172.946206    79.641937              134/112   \n",
       "2      155.945488    49.167058              160/101   \n",
       "3      169.078298    56.017921               133/94   \n",
       "4      163.758355    73.966304              170/106   \n",
       "...           ...          ...                  ...   \n",
       "2995   161.632502    88.323405               134/91   \n",
       "2996   163.443512    93.217007               110/78   \n",
       "2997   177.857644    86.258847              159/116   \n",
       "2998   162.287164    41.371018               134/82   \n",
       "2999   175.341710    78.718038               167/91   \n",
       "\n",
       "      Cholesterol Level (mg/dL)        BMI  Blood Glucose Level (mg/dL)  \\\n",
       "0                    259.465814  29.423017                   157.652848   \n",
       "1                    263.630292  26.626847                   118.507805   \n",
       "2                    207.846206  20.217553                   143.587550   \n",
       "3                    253.283779  19.595270                   137.448581   \n",
       "4                    236.119899  27.582078                   145.328695   \n",
       "...                         ...        ...                          ...   \n",
       "2995                 204.175510  33.807917                   112.075747   \n",
       "2996                 197.384424  34.894725                   101.177692   \n",
       "2997                 238.641542  27.268332                   110.548146   \n",
       "2998                 198.244328  15.708252                   123.704379   \n",
       "2999                 279.118184  25.603762                   156.577316   \n",
       "\n",
       "      Bone Density (g/cm²)  Vision Sharpness  Hearing Ability (dB)  \\\n",
       "0                 0.132868          0.200000             58.786198   \n",
       "1                 0.629534          0.267312             54.635270   \n",
       "2                 0.473487          0.248667             54.564632   \n",
       "3                 1.184315          0.513818             79.722963   \n",
       "4                 0.434562          0.306864             52.479469   \n",
       "...                    ...               ...                   ...   \n",
       "2995              1.583006          0.665907             27.997736   \n",
       "2996              1.785129          0.720304             32.866623   \n",
       "2997              0.366012          0.200000             39.756270   \n",
       "2998              1.452963          0.648158             43.338594   \n",
       "2999              0.704319          0.578625             43.926230   \n",
       "\n",
       "     Physical Activity Level Chronic Diseases Medication Use  \\\n",
       "0                   Moderate            None1          None2   \n",
       "1                        Low     Hypertension          None2   \n",
       "2                   Moderate     Hypertension        Regular   \n",
       "3                   Moderate         Diabetes     Occasional   \n",
       "4                        Low            None1          None2   \n",
       "...                      ...              ...            ...   \n",
       "2995                Moderate     Hypertension        Regular   \n",
       "2996                     Low         Diabetes     Occasional   \n",
       "2997                Moderate            None1          None2   \n",
       "2998                Moderate         Diabetes        Regular   \n",
       "2999                    High     Hypertension          None2   \n",
       "\n",
       "      Cognitive Function Education Level  Age (years) Systolic Blood Pressure  \\\n",
       "0              44.059172           None3           89                     151   \n",
       "1              45.312298   Undergraduate           77                     134   \n",
       "2              56.246991           None3           70                     160   \n",
       "3              55.196092           None3           52                     133   \n",
       "4              53.023379   Undergraduate           79                     170   \n",
       "...                  ...             ...          ...                     ...   \n",
       "2995           57.820282   Undergraduate           22                     134   \n",
       "2996           68.783715   Undergraduate           19                     110   \n",
       "2997           50.133807   Undergraduate           85                     159   \n",
       "2998           68.864629           None3           30                     134   \n",
       "2999           60.892114     High School           66                     167   \n",
       "\n",
       "     Diastolic Blood Pressure  \n",
       "0                         109  \n",
       "1                         112  \n",
       "2                         101  \n",
       "3                          94  \n",
       "4                         106  \n",
       "...                       ...  \n",
       "2995                       91  \n",
       "2996                       78  \n",
       "2997                      116  \n",
       "2998                       82  \n",
       "2999                       91  \n",
       "\n",
       "[3000 rows x 17 columns]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[['Systolic Blood Pressure', 'Diastolic Blood Pressure']] = clean_df[\"Blood Pressure (s/d)\"].str.split('/', expand=True)\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Cholesterol Level (mg/dL)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Blood Glucose Level (mg/dL)</th>\n",
       "      <th>Bone Density (g/cm²)</th>\n",
       "      <th>Vision Sharpness</th>\n",
       "      <th>Hearing Ability (dB)</th>\n",
       "      <th>Physical Activity Level</th>\n",
       "      <th>Chronic Diseases</th>\n",
       "      <th>Medication Use</th>\n",
       "      <th>Cognitive Function</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Age (years)</th>\n",
       "      <th>Systolic Blood Pressure</th>\n",
       "      <th>Diastolic Blood Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.148359</td>\n",
       "      <td>86.185197</td>\n",
       "      <td>259.465814</td>\n",
       "      <td>29.423017</td>\n",
       "      <td>157.652848</td>\n",
       "      <td>0.132868</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>58.786198</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>None1</td>\n",
       "      <td>None2</td>\n",
       "      <td>44.059172</td>\n",
       "      <td>None3</td>\n",
       "      <td>89</td>\n",
       "      <td>151</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.946206</td>\n",
       "      <td>79.641937</td>\n",
       "      <td>263.630292</td>\n",
       "      <td>26.626847</td>\n",
       "      <td>118.507805</td>\n",
       "      <td>0.629534</td>\n",
       "      <td>0.267312</td>\n",
       "      <td>54.635270</td>\n",
       "      <td>Low</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>None2</td>\n",
       "      <td>45.312298</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>77</td>\n",
       "      <td>134</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155.945488</td>\n",
       "      <td>49.167058</td>\n",
       "      <td>207.846206</td>\n",
       "      <td>20.217553</td>\n",
       "      <td>143.587550</td>\n",
       "      <td>0.473487</td>\n",
       "      <td>0.248667</td>\n",
       "      <td>54.564632</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Regular</td>\n",
       "      <td>56.246991</td>\n",
       "      <td>None3</td>\n",
       "      <td>70</td>\n",
       "      <td>160</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169.078298</td>\n",
       "      <td>56.017921</td>\n",
       "      <td>253.283779</td>\n",
       "      <td>19.595270</td>\n",
       "      <td>137.448581</td>\n",
       "      <td>1.184315</td>\n",
       "      <td>0.513818</td>\n",
       "      <td>79.722963</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Occasional</td>\n",
       "      <td>55.196092</td>\n",
       "      <td>None3</td>\n",
       "      <td>52</td>\n",
       "      <td>133</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>163.758355</td>\n",
       "      <td>73.966304</td>\n",
       "      <td>236.119899</td>\n",
       "      <td>27.582078</td>\n",
       "      <td>145.328695</td>\n",
       "      <td>0.434562</td>\n",
       "      <td>0.306864</td>\n",
       "      <td>52.479469</td>\n",
       "      <td>Low</td>\n",
       "      <td>None1</td>\n",
       "      <td>None2</td>\n",
       "      <td>53.023379</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>79</td>\n",
       "      <td>170</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>161.632502</td>\n",
       "      <td>88.323405</td>\n",
       "      <td>204.175510</td>\n",
       "      <td>33.807917</td>\n",
       "      <td>112.075747</td>\n",
       "      <td>1.583006</td>\n",
       "      <td>0.665907</td>\n",
       "      <td>27.997736</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Regular</td>\n",
       "      <td>57.820282</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>22</td>\n",
       "      <td>134</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>163.443512</td>\n",
       "      <td>93.217007</td>\n",
       "      <td>197.384424</td>\n",
       "      <td>34.894725</td>\n",
       "      <td>101.177692</td>\n",
       "      <td>1.785129</td>\n",
       "      <td>0.720304</td>\n",
       "      <td>32.866623</td>\n",
       "      <td>Low</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Occasional</td>\n",
       "      <td>68.783715</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>177.857644</td>\n",
       "      <td>86.258847</td>\n",
       "      <td>238.641542</td>\n",
       "      <td>27.268332</td>\n",
       "      <td>110.548146</td>\n",
       "      <td>0.366012</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>39.756270</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>None1</td>\n",
       "      <td>None2</td>\n",
       "      <td>50.133807</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>85</td>\n",
       "      <td>159</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>162.287164</td>\n",
       "      <td>41.371018</td>\n",
       "      <td>198.244328</td>\n",
       "      <td>15.708252</td>\n",
       "      <td>123.704379</td>\n",
       "      <td>1.452963</td>\n",
       "      <td>0.648158</td>\n",
       "      <td>43.338594</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Regular</td>\n",
       "      <td>68.864629</td>\n",
       "      <td>None3</td>\n",
       "      <td>30</td>\n",
       "      <td>134</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>175.341710</td>\n",
       "      <td>78.718038</td>\n",
       "      <td>279.118184</td>\n",
       "      <td>25.603762</td>\n",
       "      <td>156.577316</td>\n",
       "      <td>0.704319</td>\n",
       "      <td>0.578625</td>\n",
       "      <td>43.926230</td>\n",
       "      <td>High</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>None2</td>\n",
       "      <td>60.892114</td>\n",
       "      <td>High School</td>\n",
       "      <td>66</td>\n",
       "      <td>167</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Height (cm)  Weight (kg)  Cholesterol Level (mg/dL)        BMI  \\\n",
       "0      171.148359    86.185197                 259.465814  29.423017   \n",
       "1      172.946206    79.641937                 263.630292  26.626847   \n",
       "2      155.945488    49.167058                 207.846206  20.217553   \n",
       "3      169.078298    56.017921                 253.283779  19.595270   \n",
       "4      163.758355    73.966304                 236.119899  27.582078   \n",
       "...           ...          ...                        ...        ...   \n",
       "2995   161.632502    88.323405                 204.175510  33.807917   \n",
       "2996   163.443512    93.217007                 197.384424  34.894725   \n",
       "2997   177.857644    86.258847                 238.641542  27.268332   \n",
       "2998   162.287164    41.371018                 198.244328  15.708252   \n",
       "2999   175.341710    78.718038                 279.118184  25.603762   \n",
       "\n",
       "      Blood Glucose Level (mg/dL)  Bone Density (g/cm²)  Vision Sharpness  \\\n",
       "0                      157.652848              0.132868          0.200000   \n",
       "1                      118.507805              0.629534          0.267312   \n",
       "2                      143.587550              0.473487          0.248667   \n",
       "3                      137.448581              1.184315          0.513818   \n",
       "4                      145.328695              0.434562          0.306864   \n",
       "...                           ...                   ...               ...   \n",
       "2995                   112.075747              1.583006          0.665907   \n",
       "2996                   101.177692              1.785129          0.720304   \n",
       "2997                   110.548146              0.366012          0.200000   \n",
       "2998                   123.704379              1.452963          0.648158   \n",
       "2999                   156.577316              0.704319          0.578625   \n",
       "\n",
       "      Hearing Ability (dB) Physical Activity Level Chronic Diseases  \\\n",
       "0                58.786198                Moderate            None1   \n",
       "1                54.635270                     Low     Hypertension   \n",
       "2                54.564632                Moderate     Hypertension   \n",
       "3                79.722963                Moderate         Diabetes   \n",
       "4                52.479469                     Low            None1   \n",
       "...                    ...                     ...              ...   \n",
       "2995             27.997736                Moderate     Hypertension   \n",
       "2996             32.866623                     Low         Diabetes   \n",
       "2997             39.756270                Moderate            None1   \n",
       "2998             43.338594                Moderate         Diabetes   \n",
       "2999             43.926230                    High     Hypertension   \n",
       "\n",
       "     Medication Use  Cognitive Function Education Level  Age (years)  \\\n",
       "0             None2           44.059172           None3           89   \n",
       "1             None2           45.312298   Undergraduate           77   \n",
       "2           Regular           56.246991           None3           70   \n",
       "3        Occasional           55.196092           None3           52   \n",
       "4             None2           53.023379   Undergraduate           79   \n",
       "...             ...                 ...             ...          ...   \n",
       "2995        Regular           57.820282   Undergraduate           22   \n",
       "2996     Occasional           68.783715   Undergraduate           19   \n",
       "2997          None2           50.133807   Undergraduate           85   \n",
       "2998        Regular           68.864629           None3           30   \n",
       "2999          None2           60.892114     High School           66   \n",
       "\n",
       "      Systolic Blood Pressure  Diastolic Blood Pressure  \n",
       "0                         151                       109  \n",
       "1                         134                       112  \n",
       "2                         160                       101  \n",
       "3                         133                        94  \n",
       "4                         170                       106  \n",
       "...                       ...                       ...  \n",
       "2995                      134                        91  \n",
       "2996                      110                        78  \n",
       "2997                      159                       116  \n",
       "2998                      134                        82  \n",
       "2999                      167                        91  \n",
       "\n",
       "[3000 rows x 16 columns]"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clean_df['Systolic Blood Pressure'] = clean_df['Systolic Blood Pressure'].astype(int)\n",
    "clean_df['Diastolic Blood Pressure'] = clean_df['Diastolic Blood Pressure'].astype(int)\n",
    "clean_df.pop(\"Blood Pressure (s/d)\")\n",
    "clean_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Height (cm)', 'Weight (kg)', 'Cholesterol Level (mg/dL)', 'BMI',\n",
      "       'Blood Glucose Level (mg/dL)', 'Bone Density (g/cm²)',\n",
      "       'Vision Sharpness', 'Hearing Ability (dB)', 'Physical Activity Level',\n",
      "       'Chronic Diseases', 'Medication Use', 'Cognitive Function',\n",
      "       'Education Level'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "non_integer_columns = clean_df.select_dtypes(exclude=['int', 'int64'])\n",
    "print(non_integer_columns.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Cholesterol Level (mg/dL)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Blood Glucose Level (mg/dL)</th>\n",
       "      <th>Bone Density (g/cm²)</th>\n",
       "      <th>Vision Sharpness</th>\n",
       "      <th>Hearing Ability (dB)</th>\n",
       "      <th>Cognitive Function</th>\n",
       "      <th>Age (years)</th>\n",
       "      <th>...</th>\n",
       "      <th>None2</th>\n",
       "      <th>Occasional</th>\n",
       "      <th>Regular</th>\n",
       "      <th>High School</th>\n",
       "      <th>None3</th>\n",
       "      <th>Postgraduate</th>\n",
       "      <th>Undergraduate</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Moderate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.148359</td>\n",
       "      <td>86.185197</td>\n",
       "      <td>259.465814</td>\n",
       "      <td>29.423017</td>\n",
       "      <td>157.652848</td>\n",
       "      <td>0.132868</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>58.786198</td>\n",
       "      <td>44.059172</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.946206</td>\n",
       "      <td>79.641937</td>\n",
       "      <td>263.630292</td>\n",
       "      <td>26.626847</td>\n",
       "      <td>118.507805</td>\n",
       "      <td>0.629534</td>\n",
       "      <td>0.267312</td>\n",
       "      <td>54.635270</td>\n",
       "      <td>45.312298</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155.945488</td>\n",
       "      <td>49.167058</td>\n",
       "      <td>207.846206</td>\n",
       "      <td>20.217553</td>\n",
       "      <td>143.587550</td>\n",
       "      <td>0.473487</td>\n",
       "      <td>0.248667</td>\n",
       "      <td>54.564632</td>\n",
       "      <td>56.246991</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169.078298</td>\n",
       "      <td>56.017921</td>\n",
       "      <td>253.283779</td>\n",
       "      <td>19.595270</td>\n",
       "      <td>137.448581</td>\n",
       "      <td>1.184315</td>\n",
       "      <td>0.513818</td>\n",
       "      <td>79.722963</td>\n",
       "      <td>55.196092</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>163.758355</td>\n",
       "      <td>73.966304</td>\n",
       "      <td>236.119899</td>\n",
       "      <td>27.582078</td>\n",
       "      <td>145.328695</td>\n",
       "      <td>0.434562</td>\n",
       "      <td>0.306864</td>\n",
       "      <td>52.479469</td>\n",
       "      <td>53.023379</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>161.632502</td>\n",
       "      <td>88.323405</td>\n",
       "      <td>204.175510</td>\n",
       "      <td>33.807917</td>\n",
       "      <td>112.075747</td>\n",
       "      <td>1.583006</td>\n",
       "      <td>0.665907</td>\n",
       "      <td>27.997736</td>\n",
       "      <td>57.820282</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>163.443512</td>\n",
       "      <td>93.217007</td>\n",
       "      <td>197.384424</td>\n",
       "      <td>34.894725</td>\n",
       "      <td>101.177692</td>\n",
       "      <td>1.785129</td>\n",
       "      <td>0.720304</td>\n",
       "      <td>32.866623</td>\n",
       "      <td>68.783715</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>177.857644</td>\n",
       "      <td>86.258847</td>\n",
       "      <td>238.641542</td>\n",
       "      <td>27.268332</td>\n",
       "      <td>110.548146</td>\n",
       "      <td>0.366012</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>39.756270</td>\n",
       "      <td>50.133807</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>162.287164</td>\n",
       "      <td>41.371018</td>\n",
       "      <td>198.244328</td>\n",
       "      <td>15.708252</td>\n",
       "      <td>123.704379</td>\n",
       "      <td>1.452963</td>\n",
       "      <td>0.648158</td>\n",
       "      <td>43.338594</td>\n",
       "      <td>68.864629</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>175.341710</td>\n",
       "      <td>78.718038</td>\n",
       "      <td>279.118184</td>\n",
       "      <td>25.603762</td>\n",
       "      <td>156.577316</td>\n",
       "      <td>0.704319</td>\n",
       "      <td>0.578625</td>\n",
       "      <td>43.926230</td>\n",
       "      <td>60.892114</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Height (cm)  Weight (kg)  Cholesterol Level (mg/dL)        BMI  \\\n",
       "0      171.148359    86.185197                 259.465814  29.423017   \n",
       "1      172.946206    79.641937                 263.630292  26.626847   \n",
       "2      155.945488    49.167058                 207.846206  20.217553   \n",
       "3      169.078298    56.017921                 253.283779  19.595270   \n",
       "4      163.758355    73.966304                 236.119899  27.582078   \n",
       "...           ...          ...                        ...        ...   \n",
       "2995   161.632502    88.323405                 204.175510  33.807917   \n",
       "2996   163.443512    93.217007                 197.384424  34.894725   \n",
       "2997   177.857644    86.258847                 238.641542  27.268332   \n",
       "2998   162.287164    41.371018                 198.244328  15.708252   \n",
       "2999   175.341710    78.718038                 279.118184  25.603762   \n",
       "\n",
       "      Blood Glucose Level (mg/dL)  Bone Density (g/cm²)  Vision Sharpness  \\\n",
       "0                      157.652848              0.132868          0.200000   \n",
       "1                      118.507805              0.629534          0.267312   \n",
       "2                      143.587550              0.473487          0.248667   \n",
       "3                      137.448581              1.184315          0.513818   \n",
       "4                      145.328695              0.434562          0.306864   \n",
       "...                           ...                   ...               ...   \n",
       "2995                   112.075747              1.583006          0.665907   \n",
       "2996                   101.177692              1.785129          0.720304   \n",
       "2997                   110.548146              0.366012          0.200000   \n",
       "2998                   123.704379              1.452963          0.648158   \n",
       "2999                   156.577316              0.704319          0.578625   \n",
       "\n",
       "      Hearing Ability (dB)  Cognitive Function  Age (years)  ...  None2  \\\n",
       "0                58.786198           44.059172           89  ...   True   \n",
       "1                54.635270           45.312298           77  ...   True   \n",
       "2                54.564632           56.246991           70  ...  False   \n",
       "3                79.722963           55.196092           52  ...  False   \n",
       "4                52.479469           53.023379           79  ...   True   \n",
       "...                    ...                 ...          ...  ...    ...   \n",
       "2995             27.997736           57.820282           22  ...  False   \n",
       "2996             32.866623           68.783715           19  ...  False   \n",
       "2997             39.756270           50.133807           85  ...   True   \n",
       "2998             43.338594           68.864629           30  ...  False   \n",
       "2999             43.926230           60.892114           66  ...   True   \n",
       "\n",
       "      Occasional  Regular  High School  None3  Postgraduate  Undergraduate  \\\n",
       "0          False    False        False   True         False          False   \n",
       "1          False    False        False  False         False           True   \n",
       "2          False     True        False   True         False          False   \n",
       "3           True    False        False   True         False          False   \n",
       "4          False    False        False  False         False           True   \n",
       "...          ...      ...          ...    ...           ...            ...   \n",
       "2995       False     True        False  False         False           True   \n",
       "2996        True    False        False  False         False           True   \n",
       "2997       False    False        False  False         False           True   \n",
       "2998       False     True        False   True         False          False   \n",
       "2999       False    False         True  False         False          False   \n",
       "\n",
       "       High    Low  Moderate  \n",
       "0     False  False      True  \n",
       "1     False   True     False  \n",
       "2     False  False      True  \n",
       "3     False  False      True  \n",
       "4     False   True     False  \n",
       "...     ...    ...       ...  \n",
       "2995  False  False      True  \n",
       "2996  False   True     False  \n",
       "2997  False  False      True  \n",
       "2998  False  False      True  \n",
       "2999   True  False     False  \n",
       "\n",
       "[3000 rows x 26 columns]"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dummy = [\"Chronic Diseases\",\"Medication Use\", \"Education Level\", \"Physical Activity Level\"]\n",
    "for dummy_column in get_dummy:\n",
    "    clean_df = pd.concat([clean_df,pd.get_dummies(clean_df[dummy_column])], axis=\"columns\")\n",
    "    clean_df.pop(dummy_column)\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Cholesterol Level (mg/dL)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Blood Glucose Level (mg/dL)</th>\n",
       "      <th>Bone Density (g/cm²)</th>\n",
       "      <th>Vision Sharpness</th>\n",
       "      <th>Hearing Ability (dB)</th>\n",
       "      <th>Cognitive Function</th>\n",
       "      <th>Systolic Blood Pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>None2</th>\n",
       "      <th>Occasional</th>\n",
       "      <th>Regular</th>\n",
       "      <th>High School</th>\n",
       "      <th>None3</th>\n",
       "      <th>Postgraduate</th>\n",
       "      <th>Undergraduate</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Moderate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.148359</td>\n",
       "      <td>86.185197</td>\n",
       "      <td>259.465814</td>\n",
       "      <td>29.423017</td>\n",
       "      <td>157.652848</td>\n",
       "      <td>0.132868</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>58.786198</td>\n",
       "      <td>44.059172</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.946206</td>\n",
       "      <td>79.641937</td>\n",
       "      <td>263.630292</td>\n",
       "      <td>26.626847</td>\n",
       "      <td>118.507805</td>\n",
       "      <td>0.629534</td>\n",
       "      <td>0.267312</td>\n",
       "      <td>54.635270</td>\n",
       "      <td>45.312298</td>\n",
       "      <td>134</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155.945488</td>\n",
       "      <td>49.167058</td>\n",
       "      <td>207.846206</td>\n",
       "      <td>20.217553</td>\n",
       "      <td>143.587550</td>\n",
       "      <td>0.473487</td>\n",
       "      <td>0.248667</td>\n",
       "      <td>54.564632</td>\n",
       "      <td>56.246991</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169.078298</td>\n",
       "      <td>56.017921</td>\n",
       "      <td>253.283779</td>\n",
       "      <td>19.595270</td>\n",
       "      <td>137.448581</td>\n",
       "      <td>1.184315</td>\n",
       "      <td>0.513818</td>\n",
       "      <td>79.722963</td>\n",
       "      <td>55.196092</td>\n",
       "      <td>133</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>163.758355</td>\n",
       "      <td>73.966304</td>\n",
       "      <td>236.119899</td>\n",
       "      <td>27.582078</td>\n",
       "      <td>145.328695</td>\n",
       "      <td>0.434562</td>\n",
       "      <td>0.306864</td>\n",
       "      <td>52.479469</td>\n",
       "      <td>53.023379</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>161.632502</td>\n",
       "      <td>88.323405</td>\n",
       "      <td>204.175510</td>\n",
       "      <td>33.807917</td>\n",
       "      <td>112.075747</td>\n",
       "      <td>1.583006</td>\n",
       "      <td>0.665907</td>\n",
       "      <td>27.997736</td>\n",
       "      <td>57.820282</td>\n",
       "      <td>134</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>163.443512</td>\n",
       "      <td>93.217007</td>\n",
       "      <td>197.384424</td>\n",
       "      <td>34.894725</td>\n",
       "      <td>101.177692</td>\n",
       "      <td>1.785129</td>\n",
       "      <td>0.720304</td>\n",
       "      <td>32.866623</td>\n",
       "      <td>68.783715</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>177.857644</td>\n",
       "      <td>86.258847</td>\n",
       "      <td>238.641542</td>\n",
       "      <td>27.268332</td>\n",
       "      <td>110.548146</td>\n",
       "      <td>0.366012</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>39.756270</td>\n",
       "      <td>50.133807</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>162.287164</td>\n",
       "      <td>41.371018</td>\n",
       "      <td>198.244328</td>\n",
       "      <td>15.708252</td>\n",
       "      <td>123.704379</td>\n",
       "      <td>1.452963</td>\n",
       "      <td>0.648158</td>\n",
       "      <td>43.338594</td>\n",
       "      <td>68.864629</td>\n",
       "      <td>134</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>175.341710</td>\n",
       "      <td>78.718038</td>\n",
       "      <td>279.118184</td>\n",
       "      <td>25.603762</td>\n",
       "      <td>156.577316</td>\n",
       "      <td>0.704319</td>\n",
       "      <td>0.578625</td>\n",
       "      <td>43.926230</td>\n",
       "      <td>60.892114</td>\n",
       "      <td>167</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Height (cm)  Weight (kg)  Cholesterol Level (mg/dL)        BMI  \\\n",
       "0      171.148359    86.185197                 259.465814  29.423017   \n",
       "1      172.946206    79.641937                 263.630292  26.626847   \n",
       "2      155.945488    49.167058                 207.846206  20.217553   \n",
       "3      169.078298    56.017921                 253.283779  19.595270   \n",
       "4      163.758355    73.966304                 236.119899  27.582078   \n",
       "...           ...          ...                        ...        ...   \n",
       "2995   161.632502    88.323405                 204.175510  33.807917   \n",
       "2996   163.443512    93.217007                 197.384424  34.894725   \n",
       "2997   177.857644    86.258847                 238.641542  27.268332   \n",
       "2998   162.287164    41.371018                 198.244328  15.708252   \n",
       "2999   175.341710    78.718038                 279.118184  25.603762   \n",
       "\n",
       "      Blood Glucose Level (mg/dL)  Bone Density (g/cm²)  Vision Sharpness  \\\n",
       "0                      157.652848              0.132868          0.200000   \n",
       "1                      118.507805              0.629534          0.267312   \n",
       "2                      143.587550              0.473487          0.248667   \n",
       "3                      137.448581              1.184315          0.513818   \n",
       "4                      145.328695              0.434562          0.306864   \n",
       "...                           ...                   ...               ...   \n",
       "2995                   112.075747              1.583006          0.665907   \n",
       "2996                   101.177692              1.785129          0.720304   \n",
       "2997                   110.548146              0.366012          0.200000   \n",
       "2998                   123.704379              1.452963          0.648158   \n",
       "2999                   156.577316              0.704319          0.578625   \n",
       "\n",
       "      Hearing Ability (dB)  Cognitive Function  Systolic Blood Pressure  ...  \\\n",
       "0                58.786198           44.059172                      151  ...   \n",
       "1                54.635270           45.312298                      134  ...   \n",
       "2                54.564632           56.246991                      160  ...   \n",
       "3                79.722963           55.196092                      133  ...   \n",
       "4                52.479469           53.023379                      170  ...   \n",
       "...                    ...                 ...                      ...  ...   \n",
       "2995             27.997736           57.820282                      134  ...   \n",
       "2996             32.866623           68.783715                      110  ...   \n",
       "2997             39.756270           50.133807                      159  ...   \n",
       "2998             43.338594           68.864629                      134  ...   \n",
       "2999             43.926230           60.892114                      167  ...   \n",
       "\n",
       "      None2  Occasional  Regular  High School  None3  Postgraduate  \\\n",
       "0      True       False    False        False   True         False   \n",
       "1      True       False    False        False  False         False   \n",
       "2     False       False     True        False   True         False   \n",
       "3     False        True    False        False   True         False   \n",
       "4      True       False    False        False  False         False   \n",
       "...     ...         ...      ...          ...    ...           ...   \n",
       "2995  False       False     True        False  False         False   \n",
       "2996  False        True    False        False  False         False   \n",
       "2997   True       False    False        False  False         False   \n",
       "2998  False       False     True        False   True         False   \n",
       "2999   True       False    False         True  False         False   \n",
       "\n",
       "      Undergraduate   High    Low  Moderate  \n",
       "0             False  False  False      True  \n",
       "1              True  False   True     False  \n",
       "2             False  False  False      True  \n",
       "3             False  False  False      True  \n",
       "4              True  False   True     False  \n",
       "...             ...    ...    ...       ...  \n",
       "2995           True  False  False      True  \n",
       "2996           True  False   True     False  \n",
       "2997           True  False  False      True  \n",
       "2998          False  False  False      True  \n",
       "2999          False   True  False     False  \n",
       "\n",
       "[3000 rows x 25 columns]"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = clean_df.drop(\"Age (years)\", axis=\"columns\")\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89\n",
       "1       77\n",
       "2       70\n",
       "3       52\n",
       "4       79\n",
       "        ..\n",
       "2995    22\n",
       "2996    19\n",
       "2997    85\n",
       "2998    30\n",
       "2999    66\n",
       "Name: Age (years), Length: 3000, dtype: int64"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain = clean_df[\"Age (years)\"]\n",
    "yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, Tensor, optim\n",
    "\n",
    "xTrainNumpy = xtrain.to_numpy()\n",
    "yTrainNumpy = yTrain.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 25)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrainNumpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrainNumpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class AgePredictionNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AgePredictionNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(25,64)\n",
    "        self.fc2 = nn.Linear(64,16)\n",
    "        self.fc3 = nn.Linear(16,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outHiddenLayer1 = self.fc1(x)\n",
    "        activate1 = F.relu(outHiddenLayer1)\n",
    "        \n",
    "        outHiddenLayer2 = self.fc2(activate1)\n",
    "        activate2 = F.relu(outHiddenLayer2)\n",
    "        \n",
    "        outHiddenLayer3 = self.fc3(activate2)\n",
    "        return outHiddenLayer3\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgePredictionNN(\n",
       "  (fc1): Linear(in_features=25, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AgePredictionNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000002424060CF20>"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[171.1484,  86.1852, 259.4658,  ...,   0.0000,   0.0000,   1.0000],\n",
      "        [172.9462,  79.6419, 263.6303,  ...,   0.0000,   1.0000,   0.0000],\n",
      "        [155.9455,  49.1671, 207.8462,  ...,   0.0000,   0.0000,   1.0000],\n",
      "        ...,\n",
      "        [177.8577,  86.2589, 238.6415,  ...,   0.0000,   0.0000,   1.0000],\n",
      "        [162.2872,  41.3710, 198.2443,  ...,   0.0000,   0.0000,   1.0000],\n",
      "        [175.3417,  78.7180, 279.1182,  ...,   1.0000,   0.0000,   0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "xTrainNumpy = np.array(xTrainNumpy, dtype=np.float32)  \n",
    "xTrainNumpy[xTrainNumpy == True] = 1\n",
    "xTrainNumpy[xTrainNumpy == False] = 0\n",
    "\n",
    "xTrainTensor = torch.tensor(xTrainNumpy, dtype=torch.float32)\n",
    "yTrainTensor = torch.tensor(yTrainNumpy, dtype=torch.float32)\n",
    "\n",
    "print(xTrainTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of xTrainTensor: torch.Size([3000, 25])\n",
      "Shape of yTrainTensor: torch.Size([3000])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of xTrainTensor:\", xTrainTensor.shape)\n",
    "print(\"Shape of yTrainTensor:\", yTrainTensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Loss: 2598.4631\n",
      "Epoch [2/10000], Loss: 2438.9229\n",
      "Epoch [3/10000], Loss: 2283.2024\n",
      "Epoch [4/10000], Loss: 2128.9883\n",
      "Epoch [5/10000], Loss: 1974.3983\n",
      "Epoch [6/10000], Loss: 1818.8375\n",
      "Epoch [7/10000], Loss: 1662.9731\n",
      "Epoch [8/10000], Loss: 1508.5099\n",
      "Epoch [9/10000], Loss: 1358.3541\n",
      "Epoch [10/10000], Loss: 1218.2855\n",
      "Epoch [11/10000], Loss: 1094.3368\n",
      "Epoch [12/10000], Loss: 980.1923\n",
      "Epoch [13/10000], Loss: 872.9128\n",
      "Epoch [14/10000], Loss: 773.1145\n",
      "Epoch [15/10000], Loss: 681.6302\n",
      "Epoch [16/10000], Loss: 599.3246\n",
      "Epoch [17/10000], Loss: 527.0477\n",
      "Epoch [18/10000], Loss: 465.5323\n",
      "Epoch [19/10000], Loss: 415.4015\n",
      "Epoch [20/10000], Loss: 376.9927\n",
      "Epoch [21/10000], Loss: 350.3398\n",
      "Epoch [22/10000], Loss: 335.0493\n",
      "Epoch [23/10000], Loss: 330.1349\n",
      "Epoch [24/10000], Loss: 333.9513\n",
      "Epoch [25/10000], Loss: 344.2423\n",
      "Epoch [26/10000], Loss: 358.3295\n",
      "Epoch [27/10000], Loss: 373.4381\n",
      "Epoch [28/10000], Loss: 387.0788\n",
      "Epoch [29/10000], Loss: 397.3629\n",
      "Epoch [30/10000], Loss: 403.1955\n",
      "Epoch [31/10000], Loss: 404.2752\n",
      "Epoch [32/10000], Loss: 400.9579\n",
      "Epoch [33/10000], Loss: 394.0616\n",
      "Epoch [34/10000], Loss: 384.6611\n",
      "Epoch [35/10000], Loss: 373.8897\n",
      "Epoch [36/10000], Loss: 362.8034\n",
      "Epoch [37/10000], Loss: 352.2703\n",
      "Epoch [38/10000], Loss: 342.9337\n",
      "Epoch [39/10000], Loss: 335.1929\n",
      "Epoch [40/10000], Loss: 329.2251\n",
      "Epoch [41/10000], Loss: 325.0096\n",
      "Epoch [42/10000], Loss: 322.3904\n",
      "Epoch [43/10000], Loss: 321.1064\n",
      "Epoch [44/10000], Loss: 320.8462\n",
      "Epoch [45/10000], Loss: 321.2801\n",
      "Epoch [46/10000], Loss: 322.0843\n",
      "Epoch [47/10000], Loss: 322.9921\n",
      "Epoch [48/10000], Loss: 323.7793\n",
      "Epoch [49/10000], Loss: 324.2724\n",
      "Epoch [50/10000], Loss: 324.3658\n",
      "Epoch [51/10000], Loss: 324.0084\n",
      "Epoch [52/10000], Loss: 323.2063\n",
      "Epoch [53/10000], Loss: 322.0012\n",
      "Epoch [54/10000], Loss: 320.4716\n",
      "Epoch [55/10000], Loss: 318.7123\n",
      "Epoch [56/10000], Loss: 316.8304\n",
      "Epoch [57/10000], Loss: 314.9267\n",
      "Epoch [58/10000], Loss: 313.0914\n",
      "Epoch [59/10000], Loss: 311.4034\n",
      "Epoch [60/10000], Loss: 309.9199\n",
      "Epoch [61/10000], Loss: 308.6709\n",
      "Epoch [62/10000], Loss: 307.6671\n",
      "Epoch [63/10000], Loss: 306.8905\n",
      "Epoch [64/10000], Loss: 306.3092\n",
      "Epoch [65/10000], Loss: 305.8738\n",
      "Epoch [66/10000], Loss: 305.5316\n",
      "Epoch [67/10000], Loss: 305.2300\n",
      "Epoch [68/10000], Loss: 304.9194\n",
      "Epoch [69/10000], Loss: 304.5599\n",
      "Epoch [70/10000], Loss: 304.1249\n",
      "Epoch [71/10000], Loss: 303.6008\n",
      "Epoch [72/10000], Loss: 302.9889\n",
      "Epoch [73/10000], Loss: 302.3002\n",
      "Epoch [74/10000], Loss: 301.5542\n",
      "Epoch [75/10000], Loss: 300.7734\n",
      "Epoch [76/10000], Loss: 299.9815\n",
      "Epoch [77/10000], Loss: 299.1989\n",
      "Epoch [78/10000], Loss: 298.4421\n",
      "Epoch [79/10000], Loss: 297.7213\n",
      "Epoch [80/10000], Loss: 297.0415\n",
      "Epoch [81/10000], Loss: 296.4014\n",
      "Epoch [82/10000], Loss: 295.7948\n",
      "Epoch [83/10000], Loss: 295.2128\n",
      "Epoch [84/10000], Loss: 294.6447\n",
      "Epoch [85/10000], Loss: 294.0792\n",
      "Epoch [86/10000], Loss: 293.5071\n",
      "Epoch [87/10000], Loss: 292.9213\n",
      "Epoch [88/10000], Loss: 292.3169\n",
      "Epoch [89/10000], Loss: 291.6921\n",
      "Epoch [90/10000], Loss: 291.0480\n",
      "Epoch [91/10000], Loss: 290.3872\n",
      "Epoch [92/10000], Loss: 289.7135\n",
      "Epoch [93/10000], Loss: 289.0319\n",
      "Epoch [94/10000], Loss: 288.3470\n",
      "Epoch [95/10000], Loss: 287.6624\n",
      "Epoch [96/10000], Loss: 286.9807\n",
      "Epoch [97/10000], Loss: 286.3031\n",
      "Epoch [98/10000], Loss: 285.6298\n",
      "Epoch [99/10000], Loss: 284.9597\n",
      "Epoch [100/10000], Loss: 284.2904\n",
      "Epoch [101/10000], Loss: 283.6195\n",
      "Epoch [102/10000], Loss: 282.9444\n",
      "Epoch [103/10000], Loss: 282.2630\n",
      "Epoch [104/10000], Loss: 281.5734\n",
      "Epoch [105/10000], Loss: 280.8750\n",
      "Epoch [106/10000], Loss: 280.1678\n",
      "Epoch [107/10000], Loss: 279.4521\n",
      "Epoch [108/10000], Loss: 278.7287\n",
      "Epoch [109/10000], Loss: 277.9994\n",
      "Epoch [110/10000], Loss: 277.2653\n",
      "Epoch [111/10000], Loss: 276.5264\n",
      "Epoch [112/10000], Loss: 275.7833\n",
      "Epoch [113/10000], Loss: 275.0365\n",
      "Epoch [114/10000], Loss: 274.2855\n",
      "Epoch [115/10000], Loss: 273.5291\n",
      "Epoch [116/10000], Loss: 272.7675\n",
      "Epoch [117/10000], Loss: 271.9998\n",
      "Epoch [118/10000], Loss: 271.2261\n",
      "Epoch [119/10000], Loss: 270.4470\n",
      "Epoch [120/10000], Loss: 269.6601\n",
      "Epoch [121/10000], Loss: 268.8663\n",
      "Epoch [122/10000], Loss: 268.0647\n",
      "Epoch [123/10000], Loss: 267.2589\n",
      "Epoch [124/10000], Loss: 266.4474\n",
      "Epoch [125/10000], Loss: 265.6301\n",
      "Epoch [126/10000], Loss: 264.8081\n",
      "Epoch [127/10000], Loss: 263.9818\n",
      "Epoch [128/10000], Loss: 263.1505\n",
      "Epoch [129/10000], Loss: 262.3148\n",
      "Epoch [130/10000], Loss: 261.4755\n",
      "Epoch [131/10000], Loss: 260.6327\n",
      "Epoch [132/10000], Loss: 259.7856\n",
      "Epoch [133/10000], Loss: 258.9332\n",
      "Epoch [134/10000], Loss: 258.0748\n",
      "Epoch [135/10000], Loss: 257.2111\n",
      "Epoch [136/10000], Loss: 256.3423\n",
      "Epoch [137/10000], Loss: 255.4680\n",
      "Epoch [138/10000], Loss: 254.5879\n",
      "Epoch [139/10000], Loss: 253.7019\n",
      "Epoch [140/10000], Loss: 252.8103\n",
      "Epoch [141/10000], Loss: 251.9132\n",
      "Epoch [142/10000], Loss: 251.0105\n",
      "Epoch [143/10000], Loss: 250.1021\n",
      "Epoch [144/10000], Loss: 249.1878\n",
      "Epoch [145/10000], Loss: 248.2680\n",
      "Epoch [146/10000], Loss: 247.3422\n",
      "Epoch [147/10000], Loss: 246.4103\n",
      "Epoch [148/10000], Loss: 245.4722\n",
      "Epoch [149/10000], Loss: 244.5277\n",
      "Epoch [150/10000], Loss: 243.5772\n",
      "Epoch [151/10000], Loss: 242.6206\n",
      "Epoch [152/10000], Loss: 241.6579\n",
      "Epoch [153/10000], Loss: 240.6894\n",
      "Epoch [154/10000], Loss: 239.7152\n",
      "Epoch [155/10000], Loss: 238.7352\n",
      "Epoch [156/10000], Loss: 237.7494\n",
      "Epoch [157/10000], Loss: 236.7577\n",
      "Epoch [158/10000], Loss: 235.7606\n",
      "Epoch [159/10000], Loss: 234.7578\n",
      "Epoch [160/10000], Loss: 233.7494\n",
      "Epoch [161/10000], Loss: 232.7354\n",
      "Epoch [162/10000], Loss: 231.7157\n",
      "Epoch [163/10000], Loss: 230.6903\n",
      "Epoch [164/10000], Loss: 229.6591\n",
      "Epoch [165/10000], Loss: 228.6227\n",
      "Epoch [166/10000], Loss: 227.5809\n",
      "Epoch [167/10000], Loss: 226.5337\n",
      "Epoch [168/10000], Loss: 225.4811\n",
      "Epoch [169/10000], Loss: 224.4236\n",
      "Epoch [170/10000], Loss: 223.3613\n",
      "Epoch [171/10000], Loss: 222.2941\n",
      "Epoch [172/10000], Loss: 221.2224\n",
      "Epoch [173/10000], Loss: 220.1461\n",
      "Epoch [174/10000], Loss: 219.0650\n",
      "Epoch [175/10000], Loss: 217.9796\n",
      "Epoch [176/10000], Loss: 216.8898\n",
      "Epoch [177/10000], Loss: 215.7958\n",
      "Epoch [178/10000], Loss: 214.6977\n",
      "Epoch [179/10000], Loss: 213.5956\n",
      "Epoch [180/10000], Loss: 212.4896\n",
      "Epoch [181/10000], Loss: 211.3800\n",
      "Epoch [182/10000], Loss: 210.2668\n",
      "Epoch [183/10000], Loss: 209.1505\n",
      "Epoch [184/10000], Loss: 208.0311\n",
      "Epoch [185/10000], Loss: 206.9088\n",
      "Epoch [186/10000], Loss: 205.7840\n",
      "Epoch [187/10000], Loss: 204.6566\n",
      "Epoch [188/10000], Loss: 203.5270\n",
      "Epoch [189/10000], Loss: 202.3952\n",
      "Epoch [190/10000], Loss: 201.2615\n",
      "Epoch [191/10000], Loss: 200.1261\n",
      "Epoch [192/10000], Loss: 198.9893\n",
      "Epoch [193/10000], Loss: 197.8514\n",
      "Epoch [194/10000], Loss: 196.7125\n",
      "Epoch [195/10000], Loss: 195.5731\n",
      "Epoch [196/10000], Loss: 194.4336\n",
      "Epoch [197/10000], Loss: 193.2942\n",
      "Epoch [198/10000], Loss: 192.1550\n",
      "Epoch [199/10000], Loss: 191.0166\n",
      "Epoch [200/10000], Loss: 189.8792\n",
      "Epoch [201/10000], Loss: 188.7429\n",
      "Epoch [202/10000], Loss: 187.6082\n",
      "Epoch [203/10000], Loss: 186.4752\n",
      "Epoch [204/10000], Loss: 185.3446\n",
      "Epoch [205/10000], Loss: 184.2166\n",
      "Epoch [206/10000], Loss: 183.0916\n",
      "Epoch [207/10000], Loss: 181.9698\n",
      "Epoch [208/10000], Loss: 180.8519\n",
      "Epoch [209/10000], Loss: 179.7379\n",
      "Epoch [210/10000], Loss: 178.6282\n",
      "Epoch [211/10000], Loss: 177.5233\n",
      "Epoch [212/10000], Loss: 176.4234\n",
      "Epoch [213/10000], Loss: 175.3290\n",
      "Epoch [214/10000], Loss: 174.2403\n",
      "Epoch [215/10000], Loss: 173.1575\n",
      "Epoch [216/10000], Loss: 172.0810\n",
      "Epoch [217/10000], Loss: 171.0112\n",
      "Epoch [218/10000], Loss: 169.9485\n",
      "Epoch [219/10000], Loss: 168.8931\n",
      "Epoch [220/10000], Loss: 167.8454\n",
      "Epoch [221/10000], Loss: 166.8059\n",
      "Epoch [222/10000], Loss: 165.7753\n",
      "Epoch [223/10000], Loss: 164.7541\n",
      "Epoch [224/10000], Loss: 163.7429\n",
      "Epoch [225/10000], Loss: 162.7418\n",
      "Epoch [226/10000], Loss: 161.7504\n",
      "Epoch [227/10000], Loss: 160.7690\n",
      "Epoch [228/10000], Loss: 159.7980\n",
      "Epoch [229/10000], Loss: 158.8379\n",
      "Epoch [230/10000], Loss: 157.8890\n",
      "Epoch [231/10000], Loss: 156.9515\n",
      "Epoch [232/10000], Loss: 156.0256\n",
      "Epoch [233/10000], Loss: 155.1119\n",
      "Epoch [234/10000], Loss: 154.2105\n",
      "Epoch [235/10000], Loss: 153.3218\n",
      "Epoch [236/10000], Loss: 152.4462\n",
      "Epoch [237/10000], Loss: 151.5836\n",
      "Epoch [238/10000], Loss: 150.7344\n",
      "Epoch [239/10000], Loss: 149.8981\n",
      "Epoch [240/10000], Loss: 149.0751\n",
      "Epoch [241/10000], Loss: 148.2657\n",
      "Epoch [242/10000], Loss: 147.4701\n",
      "Epoch [243/10000], Loss: 146.6885\n",
      "Epoch [244/10000], Loss: 145.9205\n",
      "Epoch [245/10000], Loss: 145.1666\n",
      "Epoch [246/10000], Loss: 144.4269\n",
      "Epoch [247/10000], Loss: 143.7021\n",
      "Epoch [248/10000], Loss: 142.9918\n",
      "Epoch [249/10000], Loss: 142.2960\n",
      "Epoch [250/10000], Loss: 141.6145\n",
      "Epoch [251/10000], Loss: 140.9479\n",
      "Epoch [252/10000], Loss: 140.2957\n",
      "Epoch [253/10000], Loss: 139.6581\n",
      "Epoch [254/10000], Loss: 139.0353\n",
      "Epoch [255/10000], Loss: 138.4271\n",
      "Epoch [256/10000], Loss: 137.8331\n",
      "Epoch [257/10000], Loss: 137.2534\n",
      "Epoch [258/10000], Loss: 136.6882\n",
      "Epoch [259/10000], Loss: 136.1368\n",
      "Epoch [260/10000], Loss: 135.5992\n",
      "Epoch [261/10000], Loss: 135.0751\n",
      "Epoch [262/10000], Loss: 134.5646\n",
      "Epoch [263/10000], Loss: 134.0674\n",
      "Epoch [264/10000], Loss: 133.5835\n",
      "Epoch [265/10000], Loss: 133.1125\n",
      "Epoch [266/10000], Loss: 132.6543\n",
      "Epoch [267/10000], Loss: 132.2089\n",
      "Epoch [268/10000], Loss: 131.7758\n",
      "Epoch [269/10000], Loss: 131.3544\n",
      "Epoch [270/10000], Loss: 130.9445\n",
      "Epoch [271/10000], Loss: 130.5462\n",
      "Epoch [272/10000], Loss: 130.1594\n",
      "Epoch [273/10000], Loss: 129.7837\n",
      "Epoch [274/10000], Loss: 129.4184\n",
      "Epoch [275/10000], Loss: 129.0635\n",
      "Epoch [276/10000], Loss: 128.7185\n",
      "Epoch [277/10000], Loss: 128.3833\n",
      "Epoch [278/10000], Loss: 128.0577\n",
      "Epoch [279/10000], Loss: 127.7414\n",
      "Epoch [280/10000], Loss: 127.4341\n",
      "Epoch [281/10000], Loss: 127.1358\n",
      "Epoch [282/10000], Loss: 126.8459\n",
      "Epoch [283/10000], Loss: 126.5644\n",
      "Epoch [284/10000], Loss: 126.2911\n",
      "Epoch [285/10000], Loss: 126.0255\n",
      "Epoch [286/10000], Loss: 125.7672\n",
      "Epoch [287/10000], Loss: 125.5162\n",
      "Epoch [288/10000], Loss: 125.2723\n",
      "Epoch [289/10000], Loss: 125.0352\n",
      "Epoch [290/10000], Loss: 124.8047\n",
      "Epoch [291/10000], Loss: 124.5806\n",
      "Epoch [292/10000], Loss: 124.3626\n",
      "Epoch [293/10000], Loss: 124.1504\n",
      "Epoch [294/10000], Loss: 123.9439\n",
      "Epoch [295/10000], Loss: 123.7428\n",
      "Epoch [296/10000], Loss: 123.5468\n",
      "Epoch [297/10000], Loss: 123.3558\n",
      "Epoch [298/10000], Loss: 123.1697\n",
      "Epoch [299/10000], Loss: 122.9883\n",
      "Epoch [300/10000], Loss: 122.8115\n",
      "Epoch [301/10000], Loss: 122.6391\n",
      "Epoch [302/10000], Loss: 122.4709\n",
      "Epoch [303/10000], Loss: 122.3067\n",
      "Epoch [304/10000], Loss: 122.1461\n",
      "Epoch [305/10000], Loss: 121.9892\n",
      "Epoch [306/10000], Loss: 121.8356\n",
      "Epoch [307/10000], Loss: 121.6854\n",
      "Epoch [308/10000], Loss: 121.5383\n",
      "Epoch [309/10000], Loss: 121.3940\n",
      "Epoch [310/10000], Loss: 121.2527\n",
      "Epoch [311/10000], Loss: 121.1141\n",
      "Epoch [312/10000], Loss: 120.9779\n",
      "Epoch [313/10000], Loss: 120.8445\n",
      "Epoch [314/10000], Loss: 120.7136\n",
      "Epoch [315/10000], Loss: 120.5854\n",
      "Epoch [316/10000], Loss: 120.4592\n",
      "Epoch [317/10000], Loss: 120.3352\n",
      "Epoch [318/10000], Loss: 120.2132\n",
      "Epoch [319/10000], Loss: 120.0933\n",
      "Epoch [320/10000], Loss: 119.9754\n",
      "Epoch [321/10000], Loss: 119.8592\n",
      "Epoch [322/10000], Loss: 119.7444\n",
      "Epoch [323/10000], Loss: 119.6314\n",
      "Epoch [324/10000], Loss: 119.5197\n",
      "Epoch [325/10000], Loss: 119.4092\n",
      "Epoch [326/10000], Loss: 119.2999\n",
      "Epoch [327/10000], Loss: 119.1919\n",
      "Epoch [328/10000], Loss: 119.0855\n",
      "Epoch [329/10000], Loss: 118.9806\n",
      "Epoch [330/10000], Loss: 118.8764\n",
      "Epoch [331/10000], Loss: 118.7737\n",
      "Epoch [332/10000], Loss: 118.6729\n",
      "Epoch [333/10000], Loss: 118.5732\n",
      "Epoch [334/10000], Loss: 118.4748\n",
      "Epoch [335/10000], Loss: 118.3780\n",
      "Epoch [336/10000], Loss: 118.2832\n",
      "Epoch [337/10000], Loss: 118.1904\n",
      "Epoch [338/10000], Loss: 118.0986\n",
      "Epoch [339/10000], Loss: 118.0069\n",
      "Epoch [340/10000], Loss: 117.9159\n",
      "Epoch [341/10000], Loss: 117.8261\n",
      "Epoch [342/10000], Loss: 117.7378\n",
      "Epoch [343/10000], Loss: 117.6505\n",
      "Epoch [344/10000], Loss: 117.5640\n",
      "Epoch [345/10000], Loss: 117.4781\n",
      "Epoch [346/10000], Loss: 117.3930\n",
      "Epoch [347/10000], Loss: 117.3087\n",
      "Epoch [348/10000], Loss: 117.2250\n",
      "Epoch [349/10000], Loss: 117.1422\n",
      "Epoch [350/10000], Loss: 117.0603\n",
      "Epoch [351/10000], Loss: 116.9792\n",
      "Epoch [352/10000], Loss: 116.8988\n",
      "Epoch [353/10000], Loss: 116.8193\n",
      "Epoch [354/10000], Loss: 116.7404\n",
      "Epoch [355/10000], Loss: 116.6624\n",
      "Epoch [356/10000], Loss: 116.5849\n",
      "Epoch [357/10000], Loss: 116.5081\n",
      "Epoch [358/10000], Loss: 116.4318\n",
      "Epoch [359/10000], Loss: 116.3564\n",
      "Epoch [360/10000], Loss: 116.2816\n",
      "Epoch [361/10000], Loss: 116.2073\n",
      "Epoch [362/10000], Loss: 116.1336\n",
      "Epoch [363/10000], Loss: 116.0604\n",
      "Epoch [364/10000], Loss: 115.9878\n",
      "Epoch [365/10000], Loss: 115.9157\n",
      "Epoch [366/10000], Loss: 115.8440\n",
      "Epoch [367/10000], Loss: 115.7730\n",
      "Epoch [368/10000], Loss: 115.7025\n",
      "Epoch [369/10000], Loss: 115.6325\n",
      "Epoch [370/10000], Loss: 115.5630\n",
      "Epoch [371/10000], Loss: 115.4941\n",
      "Epoch [372/10000], Loss: 115.4256\n",
      "Epoch [373/10000], Loss: 115.3576\n",
      "Epoch [374/10000], Loss: 115.2900\n",
      "Epoch [375/10000], Loss: 115.2228\n",
      "Epoch [376/10000], Loss: 115.1561\n",
      "Epoch [377/10000], Loss: 115.0898\n",
      "Epoch [378/10000], Loss: 115.0239\n",
      "Epoch [379/10000], Loss: 114.9583\n",
      "Epoch [380/10000], Loss: 114.8932\n",
      "Epoch [381/10000], Loss: 114.8285\n",
      "Epoch [382/10000], Loss: 114.7643\n",
      "Epoch [383/10000], Loss: 114.7005\n",
      "Epoch [384/10000], Loss: 114.6370\n",
      "Epoch [385/10000], Loss: 114.5740\n",
      "Epoch [386/10000], Loss: 114.5115\n",
      "Epoch [387/10000], Loss: 114.4493\n",
      "Epoch [388/10000], Loss: 114.3875\n",
      "Epoch [389/10000], Loss: 114.3259\n",
      "Epoch [390/10000], Loss: 114.2647\n",
      "Epoch [391/10000], Loss: 114.2038\n",
      "Epoch [392/10000], Loss: 114.1433\n",
      "Epoch [393/10000], Loss: 114.0830\n",
      "Epoch [394/10000], Loss: 114.0230\n",
      "Epoch [395/10000], Loss: 113.9632\n",
      "Epoch [396/10000], Loss: 113.9036\n",
      "Epoch [397/10000], Loss: 113.8444\n",
      "Epoch [398/10000], Loss: 113.7854\n",
      "Epoch [399/10000], Loss: 113.7267\n",
      "Epoch [400/10000], Loss: 113.6682\n",
      "Epoch [401/10000], Loss: 113.6099\n",
      "Epoch [402/10000], Loss: 113.5519\n",
      "Epoch [403/10000], Loss: 113.4941\n",
      "Epoch [404/10000], Loss: 113.4367\n",
      "Epoch [405/10000], Loss: 113.3794\n",
      "Epoch [406/10000], Loss: 113.3224\n",
      "Epoch [407/10000], Loss: 113.2657\n",
      "Epoch [408/10000], Loss: 113.2093\n",
      "Epoch [409/10000], Loss: 113.1530\n",
      "Epoch [410/10000], Loss: 113.0971\n",
      "Epoch [411/10000], Loss: 113.0415\n",
      "Epoch [412/10000], Loss: 112.9861\n",
      "Epoch [413/10000], Loss: 112.9311\n",
      "Epoch [414/10000], Loss: 112.8762\n",
      "Epoch [415/10000], Loss: 112.8215\n",
      "Epoch [416/10000], Loss: 112.7669\n",
      "Epoch [417/10000], Loss: 112.7124\n",
      "Epoch [418/10000], Loss: 112.6581\n",
      "Epoch [419/10000], Loss: 112.6040\n",
      "Epoch [420/10000], Loss: 112.5500\n",
      "Epoch [421/10000], Loss: 112.4960\n",
      "Epoch [422/10000], Loss: 112.4421\n",
      "Epoch [423/10000], Loss: 112.3883\n",
      "Epoch [424/10000], Loss: 112.3347\n",
      "Epoch [425/10000], Loss: 112.2812\n",
      "Epoch [426/10000], Loss: 112.2277\n",
      "Epoch [427/10000], Loss: 112.1743\n",
      "Epoch [428/10000], Loss: 112.1209\n",
      "Epoch [429/10000], Loss: 112.0676\n",
      "Epoch [430/10000], Loss: 112.0143\n",
      "Epoch [431/10000], Loss: 111.9610\n",
      "Epoch [432/10000], Loss: 111.9080\n",
      "Epoch [433/10000], Loss: 111.8553\n",
      "Epoch [434/10000], Loss: 111.8029\n",
      "Epoch [435/10000], Loss: 111.7508\n",
      "Epoch [436/10000], Loss: 111.6995\n",
      "Epoch [437/10000], Loss: 111.6484\n",
      "Epoch [438/10000], Loss: 111.5974\n",
      "Epoch [439/10000], Loss: 111.5457\n",
      "Epoch [440/10000], Loss: 111.4942\n",
      "Epoch [441/10000], Loss: 111.4429\n",
      "Epoch [442/10000], Loss: 111.3917\n",
      "Epoch [443/10000], Loss: 111.3408\n",
      "Epoch [444/10000], Loss: 111.2894\n",
      "Epoch [445/10000], Loss: 111.2381\n",
      "Epoch [446/10000], Loss: 111.1868\n",
      "Epoch [447/10000], Loss: 111.1355\n",
      "Epoch [448/10000], Loss: 111.0843\n",
      "Epoch [449/10000], Loss: 111.0330\n",
      "Epoch [450/10000], Loss: 110.9815\n",
      "Epoch [451/10000], Loss: 110.9299\n",
      "Epoch [452/10000], Loss: 110.8785\n",
      "Epoch [453/10000], Loss: 110.8268\n",
      "Epoch [454/10000], Loss: 110.7753\n",
      "Epoch [455/10000], Loss: 110.7237\n",
      "Epoch [456/10000], Loss: 110.6726\n",
      "Epoch [457/10000], Loss: 110.6220\n",
      "Epoch [458/10000], Loss: 110.5716\n",
      "Epoch [459/10000], Loss: 110.5217\n",
      "Epoch [460/10000], Loss: 110.4724\n",
      "Epoch [461/10000], Loss: 110.4230\n",
      "Epoch [462/10000], Loss: 110.3737\n",
      "Epoch [463/10000], Loss: 110.3245\n",
      "Epoch [464/10000], Loss: 110.2753\n",
      "Epoch [465/10000], Loss: 110.2266\n",
      "Epoch [466/10000], Loss: 110.1782\n",
      "Epoch [467/10000], Loss: 110.1304\n",
      "Epoch [468/10000], Loss: 110.0829\n",
      "Epoch [469/10000], Loss: 110.0355\n",
      "Epoch [470/10000], Loss: 109.9886\n",
      "Epoch [471/10000], Loss: 109.9417\n",
      "Epoch [472/10000], Loss: 109.8948\n",
      "Epoch [473/10000], Loss: 109.8481\n",
      "Epoch [474/10000], Loss: 109.8014\n",
      "Epoch [475/10000], Loss: 109.7547\n",
      "Epoch [476/10000], Loss: 109.7081\n",
      "Epoch [477/10000], Loss: 109.6615\n",
      "Epoch [478/10000], Loss: 109.6150\n",
      "Epoch [479/10000], Loss: 109.5686\n",
      "Epoch [480/10000], Loss: 109.5221\n",
      "Epoch [481/10000], Loss: 109.4758\n",
      "Epoch [482/10000], Loss: 109.4295\n",
      "Epoch [483/10000], Loss: 109.3833\n",
      "Epoch [484/10000], Loss: 109.3371\n",
      "Epoch [485/10000], Loss: 109.2910\n",
      "Epoch [486/10000], Loss: 109.2449\n",
      "Epoch [487/10000], Loss: 109.1989\n",
      "Epoch [488/10000], Loss: 109.1529\n",
      "Epoch [489/10000], Loss: 109.1071\n",
      "Epoch [490/10000], Loss: 109.0613\n",
      "Epoch [491/10000], Loss: 109.0156\n",
      "Epoch [492/10000], Loss: 108.9700\n",
      "Epoch [493/10000], Loss: 108.9244\n",
      "Epoch [494/10000], Loss: 108.8789\n",
      "Epoch [495/10000], Loss: 108.8335\n",
      "Epoch [496/10000], Loss: 108.7881\n",
      "Epoch [497/10000], Loss: 108.7427\n",
      "Epoch [498/10000], Loss: 108.6974\n",
      "Epoch [499/10000], Loss: 108.6521\n",
      "Epoch [500/10000], Loss: 108.6069\n",
      "Epoch [501/10000], Loss: 108.5618\n",
      "Epoch [502/10000], Loss: 108.5167\n",
      "Epoch [503/10000], Loss: 108.4717\n",
      "Epoch [504/10000], Loss: 108.4266\n",
      "Epoch [505/10000], Loss: 108.3816\n",
      "Epoch [506/10000], Loss: 108.3365\n",
      "Epoch [507/10000], Loss: 108.2915\n",
      "Epoch [508/10000], Loss: 108.2465\n",
      "Epoch [509/10000], Loss: 108.2016\n",
      "Epoch [510/10000], Loss: 108.1566\n",
      "Epoch [511/10000], Loss: 108.1117\n",
      "Epoch [512/10000], Loss: 108.0666\n",
      "Epoch [513/10000], Loss: 108.0215\n",
      "Epoch [514/10000], Loss: 107.9764\n",
      "Epoch [515/10000], Loss: 107.9313\n",
      "Epoch [516/10000], Loss: 107.8861\n",
      "Epoch [517/10000], Loss: 107.8407\n",
      "Epoch [518/10000], Loss: 107.7952\n",
      "Epoch [519/10000], Loss: 107.7498\n",
      "Epoch [520/10000], Loss: 107.7041\n",
      "Epoch [521/10000], Loss: 107.6582\n",
      "Epoch [522/10000], Loss: 107.6120\n",
      "Epoch [523/10000], Loss: 107.5654\n",
      "Epoch [524/10000], Loss: 107.5181\n",
      "Epoch [525/10000], Loss: 107.4704\n",
      "Epoch [526/10000], Loss: 107.4235\n",
      "Epoch [527/10000], Loss: 107.3763\n",
      "Epoch [528/10000], Loss: 107.3292\n",
      "Epoch [529/10000], Loss: 107.2824\n",
      "Epoch [530/10000], Loss: 107.2357\n",
      "Epoch [531/10000], Loss: 107.1887\n",
      "Epoch [532/10000], Loss: 107.1421\n",
      "Epoch [533/10000], Loss: 107.0960\n",
      "Epoch [534/10000], Loss: 107.0506\n",
      "Epoch [535/10000], Loss: 107.0055\n",
      "Epoch [536/10000], Loss: 106.9608\n",
      "Epoch [537/10000], Loss: 106.9155\n",
      "Epoch [538/10000], Loss: 106.8698\n",
      "Epoch [539/10000], Loss: 106.8241\n",
      "Epoch [540/10000], Loss: 106.7786\n",
      "Epoch [541/10000], Loss: 106.7329\n",
      "Epoch [542/10000], Loss: 106.6872\n",
      "Epoch [543/10000], Loss: 106.6417\n",
      "Epoch [544/10000], Loss: 106.5963\n",
      "Epoch [545/10000], Loss: 106.5508\n",
      "Epoch [546/10000], Loss: 106.5053\n",
      "Epoch [547/10000], Loss: 106.4600\n",
      "Epoch [548/10000], Loss: 106.4148\n",
      "Epoch [549/10000], Loss: 106.3695\n",
      "Epoch [550/10000], Loss: 106.3243\n",
      "Epoch [551/10000], Loss: 106.2792\n",
      "Epoch [552/10000], Loss: 106.2339\n",
      "Epoch [553/10000], Loss: 106.1887\n",
      "Epoch [554/10000], Loss: 106.1434\n",
      "Epoch [555/10000], Loss: 106.0982\n",
      "Epoch [556/10000], Loss: 106.0529\n",
      "Epoch [557/10000], Loss: 106.0076\n",
      "Epoch [558/10000], Loss: 105.9623\n",
      "Epoch [559/10000], Loss: 105.9170\n",
      "Epoch [560/10000], Loss: 105.8716\n",
      "Epoch [561/10000], Loss: 105.8262\n",
      "Epoch [562/10000], Loss: 105.7809\n",
      "Epoch [563/10000], Loss: 105.7355\n",
      "Epoch [564/10000], Loss: 105.6901\n",
      "Epoch [565/10000], Loss: 105.6447\n",
      "Epoch [566/10000], Loss: 105.5992\n",
      "Epoch [567/10000], Loss: 105.5537\n",
      "Epoch [568/10000], Loss: 105.5081\n",
      "Epoch [569/10000], Loss: 105.4626\n",
      "Epoch [570/10000], Loss: 105.4170\n",
      "Epoch [571/10000], Loss: 105.3714\n",
      "Epoch [572/10000], Loss: 105.3258\n",
      "Epoch [573/10000], Loss: 105.2803\n",
      "Epoch [574/10000], Loss: 105.2348\n",
      "Epoch [575/10000], Loss: 105.1892\n",
      "Epoch [576/10000], Loss: 105.1436\n",
      "Epoch [577/10000], Loss: 105.0980\n",
      "Epoch [578/10000], Loss: 105.0524\n",
      "Epoch [579/10000], Loss: 105.0068\n",
      "Epoch [580/10000], Loss: 104.9612\n",
      "Epoch [581/10000], Loss: 104.9156\n",
      "Epoch [582/10000], Loss: 104.8700\n",
      "Epoch [583/10000], Loss: 104.8244\n",
      "Epoch [584/10000], Loss: 104.7788\n",
      "Epoch [585/10000], Loss: 104.7332\n",
      "Epoch [586/10000], Loss: 104.6876\n",
      "Epoch [587/10000], Loss: 104.6419\n",
      "Epoch [588/10000], Loss: 104.5962\n",
      "Epoch [589/10000], Loss: 104.5505\n",
      "Epoch [590/10000], Loss: 104.5048\n",
      "Epoch [591/10000], Loss: 104.4589\n",
      "Epoch [592/10000], Loss: 104.4131\n",
      "Epoch [593/10000], Loss: 104.3674\n",
      "Epoch [594/10000], Loss: 104.3216\n",
      "Epoch [595/10000], Loss: 104.2758\n",
      "Epoch [596/10000], Loss: 104.2300\n",
      "Epoch [597/10000], Loss: 104.1842\n",
      "Epoch [598/10000], Loss: 104.1383\n",
      "Epoch [599/10000], Loss: 104.0924\n",
      "Epoch [600/10000], Loss: 104.0465\n",
      "Epoch [601/10000], Loss: 104.0005\n",
      "Epoch [602/10000], Loss: 103.9544\n",
      "Epoch [603/10000], Loss: 103.9084\n",
      "Epoch [604/10000], Loss: 103.8622\n",
      "Epoch [605/10000], Loss: 103.8160\n",
      "Epoch [606/10000], Loss: 103.7698\n",
      "Epoch [607/10000], Loss: 103.7236\n",
      "Epoch [608/10000], Loss: 103.6773\n",
      "Epoch [609/10000], Loss: 103.6311\n",
      "Epoch [610/10000], Loss: 103.5848\n",
      "Epoch [611/10000], Loss: 103.5386\n",
      "Epoch [612/10000], Loss: 103.4923\n",
      "Epoch [613/10000], Loss: 103.4460\n",
      "Epoch [614/10000], Loss: 103.3996\n",
      "Epoch [615/10000], Loss: 103.3531\n",
      "Epoch [616/10000], Loss: 103.3067\n",
      "Epoch [617/10000], Loss: 103.2601\n",
      "Epoch [618/10000], Loss: 103.2136\n",
      "Epoch [619/10000], Loss: 103.1670\n",
      "Epoch [620/10000], Loss: 103.1203\n",
      "Epoch [621/10000], Loss: 103.0736\n",
      "Epoch [622/10000], Loss: 103.0269\n",
      "Epoch [623/10000], Loss: 102.9801\n",
      "Epoch [624/10000], Loss: 102.9333\n",
      "Epoch [625/10000], Loss: 102.8865\n",
      "Epoch [626/10000], Loss: 102.8395\n",
      "Epoch [627/10000], Loss: 102.7926\n",
      "Epoch [628/10000], Loss: 102.7456\n",
      "Epoch [629/10000], Loss: 102.6985\n",
      "Epoch [630/10000], Loss: 102.6515\n",
      "Epoch [631/10000], Loss: 102.6044\n",
      "Epoch [632/10000], Loss: 102.5572\n",
      "Epoch [633/10000], Loss: 102.5101\n",
      "Epoch [634/10000], Loss: 102.4629\n",
      "Epoch [635/10000], Loss: 102.4156\n",
      "Epoch [636/10000], Loss: 102.3683\n",
      "Epoch [637/10000], Loss: 102.3210\n",
      "Epoch [638/10000], Loss: 102.2736\n",
      "Epoch [639/10000], Loss: 102.2261\n",
      "Epoch [640/10000], Loss: 102.1786\n",
      "Epoch [641/10000], Loss: 102.1311\n",
      "Epoch [642/10000], Loss: 102.0835\n",
      "Epoch [643/10000], Loss: 102.0359\n",
      "Epoch [644/10000], Loss: 101.9882\n",
      "Epoch [645/10000], Loss: 101.9405\n",
      "Epoch [646/10000], Loss: 101.8927\n",
      "Epoch [647/10000], Loss: 101.8449\n",
      "Epoch [648/10000], Loss: 101.7971\n",
      "Epoch [649/10000], Loss: 101.7492\n",
      "Epoch [650/10000], Loss: 101.7012\n",
      "Epoch [651/10000], Loss: 101.6532\n",
      "Epoch [652/10000], Loss: 101.6052\n",
      "Epoch [653/10000], Loss: 101.5571\n",
      "Epoch [654/10000], Loss: 101.5089\n",
      "Epoch [655/10000], Loss: 101.4607\n",
      "Epoch [656/10000], Loss: 101.4124\n",
      "Epoch [657/10000], Loss: 101.3641\n",
      "Epoch [658/10000], Loss: 101.3157\n",
      "Epoch [659/10000], Loss: 101.2673\n",
      "Epoch [660/10000], Loss: 101.2188\n",
      "Epoch [661/10000], Loss: 101.1702\n",
      "Epoch [662/10000], Loss: 101.1216\n",
      "Epoch [663/10000], Loss: 101.0729\n",
      "Epoch [664/10000], Loss: 101.0242\n",
      "Epoch [665/10000], Loss: 100.9754\n",
      "Epoch [666/10000], Loss: 100.9266\n",
      "Epoch [667/10000], Loss: 100.8777\n",
      "Epoch [668/10000], Loss: 100.8288\n",
      "Epoch [669/10000], Loss: 100.7798\n",
      "Epoch [670/10000], Loss: 100.7308\n",
      "Epoch [671/10000], Loss: 100.6818\n",
      "Epoch [672/10000], Loss: 100.6327\n",
      "Epoch [673/10000], Loss: 100.5835\n",
      "Epoch [674/10000], Loss: 100.5343\n",
      "Epoch [675/10000], Loss: 100.4850\n",
      "Epoch [676/10000], Loss: 100.4357\n",
      "Epoch [677/10000], Loss: 100.3863\n",
      "Epoch [678/10000], Loss: 100.3369\n",
      "Epoch [679/10000], Loss: 100.2874\n",
      "Epoch [680/10000], Loss: 100.2379\n",
      "Epoch [681/10000], Loss: 100.1883\n",
      "Epoch [682/10000], Loss: 100.1386\n",
      "Epoch [683/10000], Loss: 100.0889\n",
      "Epoch [684/10000], Loss: 100.0391\n",
      "Epoch [685/10000], Loss: 99.9892\n",
      "Epoch [686/10000], Loss: 99.9393\n",
      "Epoch [687/10000], Loss: 99.8893\n",
      "Epoch [688/10000], Loss: 99.8393\n",
      "Epoch [689/10000], Loss: 99.7891\n",
      "Epoch [690/10000], Loss: 99.7389\n",
      "Epoch [691/10000], Loss: 99.6887\n",
      "Epoch [692/10000], Loss: 99.6384\n",
      "Epoch [693/10000], Loss: 99.5879\n",
      "Epoch [694/10000], Loss: 99.5374\n",
      "Epoch [695/10000], Loss: 99.4868\n",
      "Epoch [696/10000], Loss: 99.4362\n",
      "Epoch [697/10000], Loss: 99.3855\n",
      "Epoch [698/10000], Loss: 99.3347\n",
      "Epoch [699/10000], Loss: 99.2839\n",
      "Epoch [700/10000], Loss: 99.2329\n",
      "Epoch [701/10000], Loss: 99.1820\n",
      "Epoch [702/10000], Loss: 99.1309\n",
      "Epoch [703/10000], Loss: 99.0798\n",
      "Epoch [704/10000], Loss: 99.0287\n",
      "Epoch [705/10000], Loss: 98.9775\n",
      "Epoch [706/10000], Loss: 98.9262\n",
      "Epoch [707/10000], Loss: 98.8749\n",
      "Epoch [708/10000], Loss: 98.8235\n",
      "Epoch [709/10000], Loss: 98.7721\n",
      "Epoch [710/10000], Loss: 98.7206\n",
      "Epoch [711/10000], Loss: 98.6690\n",
      "Epoch [712/10000], Loss: 98.6174\n",
      "Epoch [713/10000], Loss: 98.5656\n",
      "Epoch [714/10000], Loss: 98.5139\n",
      "Epoch [715/10000], Loss: 98.4620\n",
      "Epoch [716/10000], Loss: 98.4101\n",
      "Epoch [717/10000], Loss: 98.3581\n",
      "Epoch [718/10000], Loss: 98.3060\n",
      "Epoch [719/10000], Loss: 98.2539\n",
      "Epoch [720/10000], Loss: 98.2017\n",
      "Epoch [721/10000], Loss: 98.1494\n",
      "Epoch [722/10000], Loss: 98.0971\n",
      "Epoch [723/10000], Loss: 98.0446\n",
      "Epoch [724/10000], Loss: 97.9922\n",
      "Epoch [725/10000], Loss: 97.9397\n",
      "Epoch [726/10000], Loss: 97.8872\n",
      "Epoch [727/10000], Loss: 97.8345\n",
      "Epoch [728/10000], Loss: 97.7819\n",
      "Epoch [729/10000], Loss: 97.7291\n",
      "Epoch [730/10000], Loss: 97.6763\n",
      "Epoch [731/10000], Loss: 97.6234\n",
      "Epoch [732/10000], Loss: 97.5705\n",
      "Epoch [733/10000], Loss: 97.5174\n",
      "Epoch [734/10000], Loss: 97.4644\n",
      "Epoch [735/10000], Loss: 97.4113\n",
      "Epoch [736/10000], Loss: 97.3581\n",
      "Epoch [737/10000], Loss: 97.3048\n",
      "Epoch [738/10000], Loss: 97.2515\n",
      "Epoch [739/10000], Loss: 97.1981\n",
      "Epoch [740/10000], Loss: 97.1444\n",
      "Epoch [741/10000], Loss: 97.0907\n",
      "Epoch [742/10000], Loss: 97.0368\n",
      "Epoch [743/10000], Loss: 96.9828\n",
      "Epoch [744/10000], Loss: 96.9289\n",
      "Epoch [745/10000], Loss: 96.8749\n",
      "Epoch [746/10000], Loss: 96.8208\n",
      "Epoch [747/10000], Loss: 96.7667\n",
      "Epoch [748/10000], Loss: 96.7124\n",
      "Epoch [749/10000], Loss: 96.6580\n",
      "Epoch [750/10000], Loss: 96.6036\n",
      "Epoch [751/10000], Loss: 96.5490\n",
      "Epoch [752/10000], Loss: 96.4943\n",
      "Epoch [753/10000], Loss: 96.4396\n",
      "Epoch [754/10000], Loss: 96.3847\n",
      "Epoch [755/10000], Loss: 96.3298\n",
      "Epoch [756/10000], Loss: 96.2748\n",
      "Epoch [757/10000], Loss: 96.2197\n",
      "Epoch [758/10000], Loss: 96.1647\n",
      "Epoch [759/10000], Loss: 96.1096\n",
      "Epoch [760/10000], Loss: 96.0544\n",
      "Epoch [761/10000], Loss: 95.9991\n",
      "Epoch [762/10000], Loss: 95.9436\n",
      "Epoch [763/10000], Loss: 95.8881\n",
      "Epoch [764/10000], Loss: 95.8325\n",
      "Epoch [765/10000], Loss: 95.7768\n",
      "Epoch [766/10000], Loss: 95.7210\n",
      "Epoch [767/10000], Loss: 95.6651\n",
      "Epoch [768/10000], Loss: 95.6092\n",
      "Epoch [769/10000], Loss: 95.5531\n",
      "Epoch [770/10000], Loss: 95.4970\n",
      "Epoch [771/10000], Loss: 95.4407\n",
      "Epoch [772/10000], Loss: 95.3844\n",
      "Epoch [773/10000], Loss: 95.3279\n",
      "Epoch [774/10000], Loss: 95.2715\n",
      "Epoch [775/10000], Loss: 95.2149\n",
      "Epoch [776/10000], Loss: 95.1582\n",
      "Epoch [777/10000], Loss: 95.1014\n",
      "Epoch [778/10000], Loss: 95.0445\n",
      "Epoch [779/10000], Loss: 94.9876\n",
      "Epoch [780/10000], Loss: 94.9305\n",
      "Epoch [781/10000], Loss: 94.8734\n",
      "Epoch [782/10000], Loss: 94.8162\n",
      "Epoch [783/10000], Loss: 94.7588\n",
      "Epoch [784/10000], Loss: 94.7014\n",
      "Epoch [785/10000], Loss: 94.6440\n",
      "Epoch [786/10000], Loss: 94.5865\n",
      "Epoch [787/10000], Loss: 94.5288\n",
      "Epoch [788/10000], Loss: 94.4711\n",
      "Epoch [789/10000], Loss: 94.4133\n",
      "Epoch [790/10000], Loss: 94.3555\n",
      "Epoch [791/10000], Loss: 94.2976\n",
      "Epoch [792/10000], Loss: 94.2397\n",
      "Epoch [793/10000], Loss: 94.1816\n",
      "Epoch [794/10000], Loss: 94.1235\n",
      "Epoch [795/10000], Loss: 94.0653\n",
      "Epoch [796/10000], Loss: 94.0070\n",
      "Epoch [797/10000], Loss: 93.9487\n",
      "Epoch [798/10000], Loss: 93.8903\n",
      "Epoch [799/10000], Loss: 93.8318\n",
      "Epoch [800/10000], Loss: 93.7732\n",
      "Epoch [801/10000], Loss: 93.7146\n",
      "Epoch [802/10000], Loss: 93.6559\n",
      "Epoch [803/10000], Loss: 93.5970\n",
      "Epoch [804/10000], Loss: 93.5381\n",
      "Epoch [805/10000], Loss: 93.4791\n",
      "Epoch [806/10000], Loss: 93.4201\n",
      "Epoch [807/10000], Loss: 93.3609\n",
      "Epoch [808/10000], Loss: 93.3016\n",
      "Epoch [809/10000], Loss: 93.2422\n",
      "Epoch [810/10000], Loss: 93.1826\n",
      "Epoch [811/10000], Loss: 93.1230\n",
      "Epoch [812/10000], Loss: 93.0633\n",
      "Epoch [813/10000], Loss: 93.0035\n",
      "Epoch [814/10000], Loss: 92.9437\n",
      "Epoch [815/10000], Loss: 92.8838\n",
      "Epoch [816/10000], Loss: 92.8238\n",
      "Epoch [817/10000], Loss: 92.7638\n",
      "Epoch [818/10000], Loss: 92.7037\n",
      "Epoch [819/10000], Loss: 92.6435\n",
      "Epoch [820/10000], Loss: 92.5832\n",
      "Epoch [821/10000], Loss: 92.5229\n",
      "Epoch [822/10000], Loss: 92.4625\n",
      "Epoch [823/10000], Loss: 92.4019\n",
      "Epoch [824/10000], Loss: 92.3413\n",
      "Epoch [825/10000], Loss: 92.2806\n",
      "Epoch [826/10000], Loss: 92.2199\n",
      "Epoch [827/10000], Loss: 92.1592\n",
      "Epoch [828/10000], Loss: 92.0984\n",
      "Epoch [829/10000], Loss: 92.0375\n",
      "Epoch [830/10000], Loss: 91.9766\n",
      "Epoch [831/10000], Loss: 91.9156\n",
      "Epoch [832/10000], Loss: 91.8546\n",
      "Epoch [833/10000], Loss: 91.7936\n",
      "Epoch [834/10000], Loss: 91.7325\n",
      "Epoch [835/10000], Loss: 91.6714\n",
      "Epoch [836/10000], Loss: 91.6103\n",
      "Epoch [837/10000], Loss: 91.5490\n",
      "Epoch [838/10000], Loss: 91.4878\n",
      "Epoch [839/10000], Loss: 91.4263\n",
      "Epoch [840/10000], Loss: 91.3649\n",
      "Epoch [841/10000], Loss: 91.3034\n",
      "Epoch [842/10000], Loss: 91.2419\n",
      "Epoch [843/10000], Loss: 91.1804\n",
      "Epoch [844/10000], Loss: 91.1188\n",
      "Epoch [845/10000], Loss: 91.0572\n",
      "Epoch [846/10000], Loss: 90.9954\n",
      "Epoch [847/10000], Loss: 90.9336\n",
      "Epoch [848/10000], Loss: 90.8717\n",
      "Epoch [849/10000], Loss: 90.8098\n",
      "Epoch [850/10000], Loss: 90.7478\n",
      "Epoch [851/10000], Loss: 90.6858\n",
      "Epoch [852/10000], Loss: 90.6237\n",
      "Epoch [853/10000], Loss: 90.5616\n",
      "Epoch [854/10000], Loss: 90.4994\n",
      "Epoch [855/10000], Loss: 90.4372\n",
      "Epoch [856/10000], Loss: 90.3750\n",
      "Epoch [857/10000], Loss: 90.3127\n",
      "Epoch [858/10000], Loss: 90.2503\n",
      "Epoch [859/10000], Loss: 90.1878\n",
      "Epoch [860/10000], Loss: 90.1253\n",
      "Epoch [861/10000], Loss: 90.0627\n",
      "Epoch [862/10000], Loss: 90.0001\n",
      "Epoch [863/10000], Loss: 89.9374\n",
      "Epoch [864/10000], Loss: 89.8748\n",
      "Epoch [865/10000], Loss: 89.8120\n",
      "Epoch [866/10000], Loss: 89.7492\n",
      "Epoch [867/10000], Loss: 89.6864\n",
      "Epoch [868/10000], Loss: 89.6235\n",
      "Epoch [869/10000], Loss: 89.5606\n",
      "Epoch [870/10000], Loss: 89.4976\n",
      "Epoch [871/10000], Loss: 89.4346\n",
      "Epoch [872/10000], Loss: 89.3714\n",
      "Epoch [873/10000], Loss: 89.3081\n",
      "Epoch [874/10000], Loss: 89.2448\n",
      "Epoch [875/10000], Loss: 89.1815\n",
      "Epoch [876/10000], Loss: 89.1182\n",
      "Epoch [877/10000], Loss: 89.0548\n",
      "Epoch [878/10000], Loss: 88.9914\n",
      "Epoch [879/10000], Loss: 88.9279\n",
      "Epoch [880/10000], Loss: 88.8644\n",
      "Epoch [881/10000], Loss: 88.8008\n",
      "Epoch [882/10000], Loss: 88.7371\n",
      "Epoch [883/10000], Loss: 88.6734\n",
      "Epoch [884/10000], Loss: 88.6096\n",
      "Epoch [885/10000], Loss: 88.5458\n",
      "Epoch [886/10000], Loss: 88.4819\n",
      "Epoch [887/10000], Loss: 88.4181\n",
      "Epoch [888/10000], Loss: 88.3542\n",
      "Epoch [889/10000], Loss: 88.2903\n",
      "Epoch [890/10000], Loss: 88.2263\n",
      "Epoch [891/10000], Loss: 88.1623\n",
      "Epoch [892/10000], Loss: 88.0983\n",
      "Epoch [893/10000], Loss: 88.0343\n",
      "Epoch [894/10000], Loss: 87.9702\n",
      "Epoch [895/10000], Loss: 87.9061\n",
      "Epoch [896/10000], Loss: 87.8419\n",
      "Epoch [897/10000], Loss: 87.7777\n",
      "Epoch [898/10000], Loss: 87.7134\n",
      "Epoch [899/10000], Loss: 87.6491\n",
      "Epoch [900/10000], Loss: 87.5849\n",
      "Epoch [901/10000], Loss: 87.5205\n",
      "Epoch [902/10000], Loss: 87.4561\n",
      "Epoch [903/10000], Loss: 87.3917\n",
      "Epoch [904/10000], Loss: 87.3272\n",
      "Epoch [905/10000], Loss: 87.2628\n",
      "Epoch [906/10000], Loss: 87.1982\n",
      "Epoch [907/10000], Loss: 87.1336\n",
      "Epoch [908/10000], Loss: 87.0689\n",
      "Epoch [909/10000], Loss: 87.0040\n",
      "Epoch [910/10000], Loss: 86.9391\n",
      "Epoch [911/10000], Loss: 86.8742\n",
      "Epoch [912/10000], Loss: 86.8091\n",
      "Epoch [913/10000], Loss: 86.7442\n",
      "Epoch [914/10000], Loss: 86.6793\n",
      "Epoch [915/10000], Loss: 86.6143\n",
      "Epoch [916/10000], Loss: 86.5495\n",
      "Epoch [917/10000], Loss: 86.4846\n",
      "Epoch [918/10000], Loss: 86.4198\n",
      "Epoch [919/10000], Loss: 86.3549\n",
      "Epoch [920/10000], Loss: 86.2900\n",
      "Epoch [921/10000], Loss: 86.2251\n",
      "Epoch [922/10000], Loss: 86.1600\n",
      "Epoch [923/10000], Loss: 86.0951\n",
      "Epoch [924/10000], Loss: 86.0301\n",
      "Epoch [925/10000], Loss: 85.9653\n",
      "Epoch [926/10000], Loss: 85.9004\n",
      "Epoch [927/10000], Loss: 85.8354\n",
      "Epoch [928/10000], Loss: 85.7705\n",
      "Epoch [929/10000], Loss: 85.7056\n",
      "Epoch [930/10000], Loss: 85.6406\n",
      "Epoch [931/10000], Loss: 85.5755\n",
      "Epoch [932/10000], Loss: 85.5106\n",
      "Epoch [933/10000], Loss: 85.4457\n",
      "Epoch [934/10000], Loss: 85.3808\n",
      "Epoch [935/10000], Loss: 85.3160\n",
      "Epoch [936/10000], Loss: 85.2513\n",
      "Epoch [937/10000], Loss: 85.1865\n",
      "Epoch [938/10000], Loss: 85.1218\n",
      "Epoch [939/10000], Loss: 85.0571\n",
      "Epoch [940/10000], Loss: 84.9924\n",
      "Epoch [941/10000], Loss: 84.9278\n",
      "Epoch [942/10000], Loss: 84.8632\n",
      "Epoch [943/10000], Loss: 84.7986\n",
      "Epoch [944/10000], Loss: 84.7340\n",
      "Epoch [945/10000], Loss: 84.6693\n",
      "Epoch [946/10000], Loss: 84.6046\n",
      "Epoch [947/10000], Loss: 84.5398\n",
      "Epoch [948/10000], Loss: 84.4751\n",
      "Epoch [949/10000], Loss: 84.4103\n",
      "Epoch [950/10000], Loss: 84.3456\n",
      "Epoch [951/10000], Loss: 84.2810\n",
      "Epoch [952/10000], Loss: 84.2165\n",
      "Epoch [953/10000], Loss: 84.1519\n",
      "Epoch [954/10000], Loss: 84.0873\n",
      "Epoch [955/10000], Loss: 84.0227\n",
      "Epoch [956/10000], Loss: 83.9581\n",
      "Epoch [957/10000], Loss: 83.8934\n",
      "Epoch [958/10000], Loss: 83.8288\n",
      "Epoch [959/10000], Loss: 83.7643\n",
      "Epoch [960/10000], Loss: 83.6998\n",
      "Epoch [961/10000], Loss: 83.6356\n",
      "Epoch [962/10000], Loss: 83.5714\n",
      "Epoch [963/10000], Loss: 83.5072\n",
      "Epoch [964/10000], Loss: 83.4431\n",
      "Epoch [965/10000], Loss: 83.3789\n",
      "Epoch [966/10000], Loss: 83.3148\n",
      "Epoch [967/10000], Loss: 83.2509\n",
      "Epoch [968/10000], Loss: 83.1870\n",
      "Epoch [969/10000], Loss: 83.1231\n",
      "Epoch [970/10000], Loss: 83.0591\n",
      "Epoch [971/10000], Loss: 82.9952\n",
      "Epoch [972/10000], Loss: 82.9314\n",
      "Epoch [973/10000], Loss: 82.8676\n",
      "Epoch [974/10000], Loss: 82.8038\n",
      "Epoch [975/10000], Loss: 82.7400\n",
      "Epoch [976/10000], Loss: 82.6762\n",
      "Epoch [977/10000], Loss: 82.6124\n",
      "Epoch [978/10000], Loss: 82.5485\n",
      "Epoch [979/10000], Loss: 82.4846\n",
      "Epoch [980/10000], Loss: 82.4208\n",
      "Epoch [981/10000], Loss: 82.3573\n",
      "Epoch [982/10000], Loss: 82.2940\n",
      "Epoch [983/10000], Loss: 82.2306\n",
      "Epoch [984/10000], Loss: 82.1673\n",
      "Epoch [985/10000], Loss: 82.1043\n",
      "Epoch [986/10000], Loss: 82.0417\n",
      "Epoch [987/10000], Loss: 81.9791\n",
      "Epoch [988/10000], Loss: 81.9165\n",
      "Epoch [989/10000], Loss: 81.8540\n",
      "Epoch [990/10000], Loss: 81.7915\n",
      "Epoch [991/10000], Loss: 81.7290\n",
      "Epoch [992/10000], Loss: 81.6665\n",
      "Epoch [993/10000], Loss: 81.6041\n",
      "Epoch [994/10000], Loss: 81.5417\n",
      "Epoch [995/10000], Loss: 81.4796\n",
      "Epoch [996/10000], Loss: 81.4177\n",
      "Epoch [997/10000], Loss: 81.3556\n",
      "Epoch [998/10000], Loss: 81.2935\n",
      "Epoch [999/10000], Loss: 81.2313\n",
      "Epoch [1000/10000], Loss: 81.1692\n",
      "Epoch [1001/10000], Loss: 81.1071\n",
      "Epoch [1002/10000], Loss: 81.0454\n",
      "Epoch [1003/10000], Loss: 80.9836\n",
      "Epoch [1004/10000], Loss: 80.9219\n",
      "Epoch [1005/10000], Loss: 80.8601\n",
      "Epoch [1006/10000], Loss: 80.7985\n",
      "Epoch [1007/10000], Loss: 80.7369\n",
      "Epoch [1008/10000], Loss: 80.6754\n",
      "Epoch [1009/10000], Loss: 80.6142\n",
      "Epoch [1010/10000], Loss: 80.5530\n",
      "Epoch [1011/10000], Loss: 80.4919\n",
      "Epoch [1012/10000], Loss: 80.4311\n",
      "Epoch [1013/10000], Loss: 80.3704\n",
      "Epoch [1014/10000], Loss: 80.3097\n",
      "Epoch [1015/10000], Loss: 80.2494\n",
      "Epoch [1016/10000], Loss: 80.1894\n",
      "Epoch [1017/10000], Loss: 80.1304\n",
      "Epoch [1018/10000], Loss: 80.0719\n",
      "Epoch [1019/10000], Loss: 80.0126\n",
      "Epoch [1020/10000], Loss: 79.9525\n",
      "Epoch [1021/10000], Loss: 79.8906\n",
      "Epoch [1022/10000], Loss: 79.8295\n",
      "Epoch [1023/10000], Loss: 79.7693\n",
      "Epoch [1024/10000], Loss: 79.7094\n",
      "Epoch [1025/10000], Loss: 79.6503\n",
      "Epoch [1026/10000], Loss: 79.5924\n",
      "Epoch [1027/10000], Loss: 79.5363\n",
      "Epoch [1028/10000], Loss: 79.4818\n",
      "Epoch [1029/10000], Loss: 79.4262\n",
      "Epoch [1030/10000], Loss: 79.3718\n",
      "Epoch [1031/10000], Loss: 79.3129\n",
      "Epoch [1032/10000], Loss: 79.2539\n",
      "Epoch [1033/10000], Loss: 79.1910\n",
      "Epoch [1034/10000], Loss: 79.1269\n",
      "Epoch [1035/10000], Loss: 79.0639\n",
      "Epoch [1036/10000], Loss: 79.0041\n",
      "Epoch [1037/10000], Loss: 78.9473\n",
      "Epoch [1038/10000], Loss: 78.8929\n",
      "Epoch [1039/10000], Loss: 78.8407\n",
      "Epoch [1040/10000], Loss: 78.7897\n",
      "Epoch [1041/10000], Loss: 78.7395\n",
      "Epoch [1042/10000], Loss: 78.6856\n",
      "Epoch [1043/10000], Loss: 78.6275\n",
      "Epoch [1044/10000], Loss: 78.5631\n",
      "Epoch [1045/10000], Loss: 78.4996\n",
      "Epoch [1046/10000], Loss: 78.4344\n",
      "Epoch [1047/10000], Loss: 78.3726\n",
      "Epoch [1048/10000], Loss: 78.3184\n",
      "Epoch [1049/10000], Loss: 78.2690\n",
      "Epoch [1050/10000], Loss: 78.2187\n",
      "Epoch [1051/10000], Loss: 78.1598\n",
      "Epoch [1052/10000], Loss: 78.0965\n",
      "Epoch [1053/10000], Loss: 78.0338\n",
      "Epoch [1054/10000], Loss: 77.9757\n",
      "Epoch [1055/10000], Loss: 77.9226\n",
      "Epoch [1056/10000], Loss: 77.8739\n",
      "Epoch [1057/10000], Loss: 77.8270\n",
      "Epoch [1058/10000], Loss: 77.7775\n",
      "Epoch [1059/10000], Loss: 77.7235\n",
      "Epoch [1060/10000], Loss: 77.6610\n",
      "Epoch [1061/10000], Loss: 77.5951\n",
      "Epoch [1062/10000], Loss: 77.5309\n",
      "Epoch [1063/10000], Loss: 77.4737\n",
      "Epoch [1064/10000], Loss: 77.4223\n",
      "Epoch [1065/10000], Loss: 77.3725\n",
      "Epoch [1066/10000], Loss: 77.3226\n",
      "Epoch [1067/10000], Loss: 77.2684\n",
      "Epoch [1068/10000], Loss: 77.2110\n",
      "Epoch [1069/10000], Loss: 77.1507\n",
      "Epoch [1070/10000], Loss: 77.0915\n",
      "Epoch [1071/10000], Loss: 77.0332\n",
      "Epoch [1072/10000], Loss: 76.9769\n",
      "Epoch [1073/10000], Loss: 76.9218\n",
      "Epoch [1074/10000], Loss: 76.8678\n",
      "Epoch [1075/10000], Loss: 76.8141\n",
      "Epoch [1076/10000], Loss: 76.7598\n",
      "Epoch [1077/10000], Loss: 76.7057\n",
      "Epoch [1078/10000], Loss: 76.6524\n",
      "Epoch [1079/10000], Loss: 76.5995\n",
      "Epoch [1080/10000], Loss: 76.5477\n",
      "Epoch [1081/10000], Loss: 76.4976\n",
      "Epoch [1082/10000], Loss: 76.4497\n",
      "Epoch [1083/10000], Loss: 76.4054\n",
      "Epoch [1084/10000], Loss: 76.3641\n",
      "Epoch [1085/10000], Loss: 76.3222\n",
      "Epoch [1086/10000], Loss: 76.2698\n",
      "Epoch [1087/10000], Loss: 76.2062\n",
      "Epoch [1088/10000], Loss: 76.1354\n",
      "Epoch [1089/10000], Loss: 76.0659\n",
      "Epoch [1090/10000], Loss: 76.0053\n",
      "Epoch [1091/10000], Loss: 75.9564\n",
      "Epoch [1092/10000], Loss: 75.9124\n",
      "Epoch [1093/10000], Loss: 75.8654\n",
      "Epoch [1094/10000], Loss: 75.8091\n",
      "Epoch [1095/10000], Loss: 75.7506\n",
      "Epoch [1096/10000], Loss: 75.6894\n",
      "Epoch [1097/10000], Loss: 75.6335\n",
      "Epoch [1098/10000], Loss: 75.5812\n",
      "Epoch [1099/10000], Loss: 75.5314\n",
      "Epoch [1100/10000], Loss: 75.4844\n",
      "Epoch [1101/10000], Loss: 75.4360\n",
      "Epoch [1102/10000], Loss: 75.3864\n",
      "Epoch [1103/10000], Loss: 75.3336\n",
      "Epoch [1104/10000], Loss: 75.2788\n",
      "Epoch [1105/10000], Loss: 75.2223\n",
      "Epoch [1106/10000], Loss: 75.1655\n",
      "Epoch [1107/10000], Loss: 75.1101\n",
      "Epoch [1108/10000], Loss: 75.0554\n",
      "Epoch [1109/10000], Loss: 75.0023\n",
      "Epoch [1110/10000], Loss: 74.9505\n",
      "Epoch [1111/10000], Loss: 74.8995\n",
      "Epoch [1112/10000], Loss: 74.8487\n",
      "Epoch [1113/10000], Loss: 74.7973\n",
      "Epoch [1114/10000], Loss: 74.7457\n",
      "Epoch [1115/10000], Loss: 74.6940\n",
      "Epoch [1116/10000], Loss: 74.6426\n",
      "Epoch [1117/10000], Loss: 74.5919\n",
      "Epoch [1118/10000], Loss: 74.5420\n",
      "Epoch [1119/10000], Loss: 74.4927\n",
      "Epoch [1120/10000], Loss: 74.4465\n",
      "Epoch [1121/10000], Loss: 74.4061\n",
      "Epoch [1122/10000], Loss: 74.3781\n",
      "Epoch [1123/10000], Loss: 74.3615\n",
      "Epoch [1124/10000], Loss: 74.3506\n",
      "Epoch [1125/10000], Loss: 74.3215\n",
      "Epoch [1126/10000], Loss: 74.2520\n",
      "Epoch [1127/10000], Loss: 74.1357\n",
      "Epoch [1128/10000], Loss: 74.0295\n",
      "Epoch [1129/10000], Loss: 73.9683\n",
      "Epoch [1130/10000], Loss: 73.9488\n",
      "Epoch [1131/10000], Loss: 73.9357\n",
      "Epoch [1132/10000], Loss: 73.8855\n",
      "Epoch [1133/10000], Loss: 73.7961\n",
      "Epoch [1134/10000], Loss: 73.7038\n",
      "Epoch [1135/10000], Loss: 73.6391\n",
      "Epoch [1136/10000], Loss: 73.5974\n",
      "Epoch [1137/10000], Loss: 73.5487\n",
      "Epoch [1138/10000], Loss: 73.4599\n",
      "Epoch [1139/10000], Loss: 73.3478\n",
      "Epoch [1140/10000], Loss: 73.2240\n",
      "Epoch [1141/10000], Loss: 73.1188\n",
      "Epoch [1142/10000], Loss: 73.0559\n",
      "Epoch [1143/10000], Loss: 72.9962\n",
      "Epoch [1144/10000], Loss: 72.9474\n",
      "Epoch [1145/10000], Loss: 72.8864\n",
      "Epoch [1146/10000], Loss: 72.8230\n",
      "Epoch [1147/10000], Loss: 72.7527\n",
      "Epoch [1148/10000], Loss: 72.6743\n",
      "Epoch [1149/10000], Loss: 72.5939\n",
      "Epoch [1150/10000], Loss: 72.5130\n",
      "Epoch [1151/10000], Loss: 72.4324\n",
      "Epoch [1152/10000], Loss: 72.3533\n",
      "Epoch [1153/10000], Loss: 72.2750\n",
      "Epoch [1154/10000], Loss: 72.2019\n",
      "Epoch [1155/10000], Loss: 72.1361\n",
      "Epoch [1156/10000], Loss: 72.0763\n",
      "Epoch [1157/10000], Loss: 72.0181\n",
      "Epoch [1158/10000], Loss: 71.9560\n",
      "Epoch [1159/10000], Loss: 71.8929\n",
      "Epoch [1160/10000], Loss: 71.8212\n",
      "Epoch [1161/10000], Loss: 71.7473\n",
      "Epoch [1162/10000], Loss: 71.6629\n",
      "Epoch [1163/10000], Loss: 71.5754\n",
      "Epoch [1164/10000], Loss: 71.4865\n",
      "Epoch [1165/10000], Loss: 71.3914\n",
      "Epoch [1166/10000], Loss: 71.2935\n",
      "Epoch [1167/10000], Loss: 71.2007\n",
      "Epoch [1168/10000], Loss: 71.1132\n",
      "Epoch [1169/10000], Loss: 71.0298\n",
      "Epoch [1170/10000], Loss: 70.9477\n",
      "Epoch [1171/10000], Loss: 70.8660\n",
      "Epoch [1172/10000], Loss: 70.7845\n",
      "Epoch [1173/10000], Loss: 70.7033\n",
      "Epoch [1174/10000], Loss: 70.6214\n",
      "Epoch [1175/10000], Loss: 70.5393\n",
      "Epoch [1176/10000], Loss: 70.4598\n",
      "Epoch [1177/10000], Loss: 70.3835\n",
      "Epoch [1178/10000], Loss: 70.3137\n",
      "Epoch [1179/10000], Loss: 70.2640\n",
      "Epoch [1180/10000], Loss: 70.2531\n",
      "Epoch [1181/10000], Loss: 70.3491\n",
      "Epoch [1182/10000], Loss: 70.6354\n",
      "Epoch [1183/10000], Loss: 70.9830\n",
      "Epoch [1184/10000], Loss: 70.7494\n",
      "Epoch [1185/10000], Loss: 69.9278\n",
      "Epoch [1186/10000], Loss: 69.7507\n",
      "Epoch [1187/10000], Loss: 70.2092\n",
      "Epoch [1188/10000], Loss: 70.0239\n",
      "Epoch [1189/10000], Loss: 69.4764\n",
      "Epoch [1190/10000], Loss: 69.6204\n",
      "Epoch [1191/10000], Loss: 69.7761\n",
      "Epoch [1192/10000], Loss: 69.3681\n",
      "Epoch [1193/10000], Loss: 69.2493\n",
      "Epoch [1194/10000], Loss: 69.4631\n",
      "Epoch [1195/10000], Loss: 69.2486\n",
      "Epoch [1196/10000], Loss: 68.9876\n",
      "Epoch [1197/10000], Loss: 69.1350\n",
      "Epoch [1198/10000], Loss: 69.0840\n",
      "Epoch [1199/10000], Loss: 68.7936\n",
      "Epoch [1200/10000], Loss: 68.8222\n",
      "Epoch [1201/10000], Loss: 68.8518\n",
      "Epoch [1202/10000], Loss: 68.6228\n",
      "Epoch [1203/10000], Loss: 68.5532\n",
      "Epoch [1204/10000], Loss: 68.6015\n",
      "Epoch [1205/10000], Loss: 68.4512\n",
      "Epoch [1206/10000], Loss: 68.3192\n",
      "Epoch [1207/10000], Loss: 68.3362\n",
      "Epoch [1208/10000], Loss: 68.2632\n",
      "Epoch [1209/10000], Loss: 68.1191\n",
      "Epoch [1210/10000], Loss: 68.0815\n",
      "Epoch [1211/10000], Loss: 68.0522\n",
      "Epoch [1212/10000], Loss: 67.9384\n",
      "Epoch [1213/10000], Loss: 67.8499\n",
      "Epoch [1214/10000], Loss: 67.8239\n",
      "Epoch [1215/10000], Loss: 67.7549\n",
      "Epoch [1216/10000], Loss: 67.6489\n",
      "Epoch [1217/10000], Loss: 67.5861\n",
      "Epoch [1218/10000], Loss: 67.5446\n",
      "Epoch [1219/10000], Loss: 67.4670\n",
      "Epoch [1220/10000], Loss: 67.3750\n",
      "Epoch [1221/10000], Loss: 67.3173\n",
      "Epoch [1222/10000], Loss: 67.2673\n",
      "Epoch [1223/10000], Loss: 67.1876\n",
      "Epoch [1224/10000], Loss: 67.1029\n",
      "Epoch [1225/10000], Loss: 67.0417\n",
      "Epoch [1226/10000], Loss: 66.9841\n",
      "Epoch [1227/10000], Loss: 66.9100\n",
      "Epoch [1228/10000], Loss: 66.8302\n",
      "Epoch [1229/10000], Loss: 66.7634\n",
      "Epoch [1230/10000], Loss: 66.7026\n",
      "Epoch [1231/10000], Loss: 66.6346\n",
      "Epoch [1232/10000], Loss: 66.5593\n",
      "Epoch [1233/10000], Loss: 66.4848\n",
      "Epoch [1234/10000], Loss: 66.4173\n",
      "Epoch [1235/10000], Loss: 66.3523\n",
      "Epoch [1236/10000], Loss: 66.2852\n",
      "Epoch [1237/10000], Loss: 66.2132\n",
      "Epoch [1238/10000], Loss: 66.1388\n",
      "Epoch [1239/10000], Loss: 66.0674\n",
      "Epoch [1240/10000], Loss: 65.9994\n",
      "Epoch [1241/10000], Loss: 65.9312\n",
      "Epoch [1242/10000], Loss: 65.8615\n",
      "Epoch [1243/10000], Loss: 65.7896\n",
      "Epoch [1244/10000], Loss: 65.7172\n",
      "Epoch [1245/10000], Loss: 65.6454\n",
      "Epoch [1246/10000], Loss: 65.5749\n",
      "Epoch [1247/10000], Loss: 65.5048\n",
      "Epoch [1248/10000], Loss: 65.4347\n",
      "Epoch [1249/10000], Loss: 65.3658\n",
      "Epoch [1250/10000], Loss: 65.2987\n",
      "Epoch [1251/10000], Loss: 65.2357\n",
      "Epoch [1252/10000], Loss: 65.1738\n",
      "Epoch [1253/10000], Loss: 65.1168\n",
      "Epoch [1254/10000], Loss: 65.0577\n",
      "Epoch [1255/10000], Loss: 65.0007\n",
      "Epoch [1256/10000], Loss: 64.9462\n",
      "Epoch [1257/10000], Loss: 64.8967\n",
      "Epoch [1258/10000], Loss: 64.8519\n",
      "Epoch [1259/10000], Loss: 64.7941\n",
      "Epoch [1260/10000], Loss: 64.7314\n",
      "Epoch [1261/10000], Loss: 64.6448\n",
      "Epoch [1262/10000], Loss: 64.5552\n",
      "Epoch [1263/10000], Loss: 64.4480\n",
      "Epoch [1264/10000], Loss: 64.3549\n",
      "Epoch [1265/10000], Loss: 64.2585\n",
      "Epoch [1266/10000], Loss: 64.1699\n",
      "Epoch [1267/10000], Loss: 64.0909\n",
      "Epoch [1268/10000], Loss: 64.0184\n",
      "Epoch [1269/10000], Loss: 63.9495\n",
      "Epoch [1270/10000], Loss: 63.8837\n",
      "Epoch [1271/10000], Loss: 63.8219\n",
      "Epoch [1272/10000], Loss: 63.7696\n",
      "Epoch [1273/10000], Loss: 63.7307\n",
      "Epoch [1274/10000], Loss: 63.7140\n",
      "Epoch [1275/10000], Loss: 63.7341\n",
      "Epoch [1276/10000], Loss: 63.7869\n",
      "Epoch [1277/10000], Loss: 63.8908\n",
      "Epoch [1278/10000], Loss: 63.9244\n",
      "Epoch [1279/10000], Loss: 63.8278\n",
      "Epoch [1280/10000], Loss: 63.5297\n",
      "Epoch [1281/10000], Loss: 63.2193\n",
      "Epoch [1282/10000], Loss: 63.0440\n",
      "Epoch [1283/10000], Loss: 63.0689\n",
      "Epoch [1284/10000], Loss: 63.1951\n",
      "Epoch [1285/10000], Loss: 63.2101\n",
      "Epoch [1286/10000], Loss: 63.0550\n",
      "Epoch [1287/10000], Loss: 62.8045\n",
      "Epoch [1288/10000], Loss: 62.6438\n",
      "Epoch [1289/10000], Loss: 62.6236\n",
      "Epoch [1290/10000], Loss: 62.6677\n",
      "Epoch [1291/10000], Loss: 62.6658\n",
      "Epoch [1292/10000], Loss: 62.5535\n",
      "Epoch [1293/10000], Loss: 62.3874\n",
      "Epoch [1294/10000], Loss: 62.2506\n",
      "Epoch [1295/10000], Loss: 62.1849\n",
      "Epoch [1296/10000], Loss: 62.1745\n",
      "Epoch [1297/10000], Loss: 62.1624\n",
      "Epoch [1298/10000], Loss: 62.1124\n",
      "Epoch [1299/10000], Loss: 62.0080\n",
      "Epoch [1300/10000], Loss: 61.8880\n",
      "Epoch [1301/10000], Loss: 61.7800\n",
      "Epoch [1302/10000], Loss: 61.7044\n",
      "Epoch [1303/10000], Loss: 61.6557\n",
      "Epoch [1304/10000], Loss: 61.6114\n",
      "Epoch [1305/10000], Loss: 61.5657\n",
      "Epoch [1306/10000], Loss: 61.5074\n",
      "Epoch [1307/10000], Loss: 61.4301\n",
      "Epoch [1308/10000], Loss: 61.3437\n",
      "Epoch [1309/10000], Loss: 61.2534\n",
      "Epoch [1310/10000], Loss: 61.1655\n",
      "Epoch [1311/10000], Loss: 61.0871\n",
      "Epoch [1312/10000], Loss: 61.0199\n",
      "Epoch [1313/10000], Loss: 60.9594\n",
      "Epoch [1314/10000], Loss: 60.9025\n",
      "Epoch [1315/10000], Loss: 60.8465\n",
      "Epoch [1316/10000], Loss: 60.7959\n",
      "Epoch [1317/10000], Loss: 60.7484\n",
      "Epoch [1318/10000], Loss: 60.7039\n",
      "Epoch [1319/10000], Loss: 60.6532\n",
      "Epoch [1320/10000], Loss: 60.5924\n",
      "Epoch [1321/10000], Loss: 60.5247\n",
      "Epoch [1322/10000], Loss: 60.4404\n",
      "Epoch [1323/10000], Loss: 60.3575\n",
      "Epoch [1324/10000], Loss: 60.2627\n",
      "Epoch [1325/10000], Loss: 60.1689\n",
      "Epoch [1326/10000], Loss: 60.0753\n",
      "Epoch [1327/10000], Loss: 59.9894\n",
      "Epoch [1328/10000], Loss: 59.9094\n",
      "Epoch [1329/10000], Loss: 59.8386\n",
      "Epoch [1330/10000], Loss: 59.7706\n",
      "Epoch [1331/10000], Loss: 59.7100\n",
      "Epoch [1332/10000], Loss: 59.6554\n",
      "Epoch [1333/10000], Loss: 59.6115\n",
      "Epoch [1334/10000], Loss: 59.5905\n",
      "Epoch [1335/10000], Loss: 59.5999\n",
      "Epoch [1336/10000], Loss: 59.6683\n",
      "Epoch [1337/10000], Loss: 59.7794\n",
      "Epoch [1338/10000], Loss: 59.9098\n",
      "Epoch [1339/10000], Loss: 59.9481\n",
      "Epoch [1340/10000], Loss: 59.7755\n",
      "Epoch [1341/10000], Loss: 59.4024\n",
      "Epoch [1342/10000], Loss: 59.0399\n",
      "Epoch [1343/10000], Loss: 58.8577\n",
      "Epoch [1344/10000], Loss: 58.8775\n",
      "Epoch [1345/10000], Loss: 58.9925\n",
      "Epoch [1346/10000], Loss: 59.0819\n",
      "Epoch [1347/10000], Loss: 58.9974\n",
      "Epoch [1348/10000], Loss: 58.7682\n",
      "Epoch [1349/10000], Loss: 58.5183\n",
      "Epoch [1350/10000], Loss: 58.3891\n",
      "Epoch [1351/10000], Loss: 58.4006\n",
      "Epoch [1352/10000], Loss: 58.4624\n",
      "Epoch [1353/10000], Loss: 58.4711\n",
      "Epoch [1354/10000], Loss: 58.3419\n",
      "Epoch [1355/10000], Loss: 58.1658\n",
      "Epoch [1356/10000], Loss: 58.0038\n",
      "Epoch [1357/10000], Loss: 57.9177\n",
      "Epoch [1358/10000], Loss: 57.8995\n",
      "Epoch [1359/10000], Loss: 57.8853\n",
      "Epoch [1360/10000], Loss: 57.8437\n",
      "Epoch [1361/10000], Loss: 57.7492\n",
      "Epoch [1362/10000], Loss: 57.6362\n",
      "Epoch [1363/10000], Loss: 57.5234\n",
      "Epoch [1364/10000], Loss: 57.4420\n",
      "Epoch [1365/10000], Loss: 57.3967\n",
      "Epoch [1366/10000], Loss: 57.3590\n",
      "Epoch [1367/10000], Loss: 57.3117\n",
      "Epoch [1368/10000], Loss: 57.2402\n",
      "Epoch [1369/10000], Loss: 57.1502\n",
      "Epoch [1370/10000], Loss: 57.0566\n",
      "Epoch [1371/10000], Loss: 56.9674\n",
      "Epoch [1372/10000], Loss: 56.8949\n",
      "Epoch [1373/10000], Loss: 56.8356\n",
      "Epoch [1374/10000], Loss: 56.7755\n",
      "Epoch [1375/10000], Loss: 56.7149\n",
      "Epoch [1376/10000], Loss: 56.6433\n",
      "Epoch [1377/10000], Loss: 56.5708\n",
      "Epoch [1378/10000], Loss: 56.4931\n",
      "Epoch [1379/10000], Loss: 56.4195\n",
      "Epoch [1380/10000], Loss: 56.3464\n",
      "Epoch [1381/10000], Loss: 56.2761\n",
      "Epoch [1382/10000], Loss: 56.2082\n",
      "Epoch [1383/10000], Loss: 56.1418\n",
      "Epoch [1384/10000], Loss: 56.0760\n",
      "Epoch [1385/10000], Loss: 56.0104\n",
      "Epoch [1386/10000], Loss: 55.9458\n",
      "Epoch [1387/10000], Loss: 55.8806\n",
      "Epoch [1388/10000], Loss: 55.8160\n",
      "Epoch [1389/10000], Loss: 55.7523\n",
      "Epoch [1390/10000], Loss: 55.6990\n",
      "Epoch [1391/10000], Loss: 55.6555\n",
      "Epoch [1392/10000], Loss: 55.6376\n",
      "Epoch [1393/10000], Loss: 55.6617\n",
      "Epoch [1394/10000], Loss: 55.7790\n",
      "Epoch [1395/10000], Loss: 56.1296\n",
      "Epoch [1396/10000], Loss: 56.8658\n",
      "Epoch [1397/10000], Loss: 57.6334\n",
      "Epoch [1398/10000], Loss: 57.9598\n",
      "Epoch [1399/10000], Loss: 56.6986\n",
      "Epoch [1400/10000], Loss: 55.2024\n",
      "Epoch [1401/10000], Loss: 55.0806\n",
      "Epoch [1402/10000], Loss: 55.9821\n",
      "Epoch [1403/10000], Loss: 56.2802\n",
      "Epoch [1404/10000], Loss: 55.2383\n",
      "Epoch [1405/10000], Loss: 54.6827\n",
      "Epoch [1406/10000], Loss: 55.2649\n",
      "Epoch [1407/10000], Loss: 55.6342\n",
      "Epoch [1408/10000], Loss: 55.0140\n",
      "Epoch [1409/10000], Loss: 54.4251\n",
      "Epoch [1410/10000], Loss: 54.7178\n",
      "Epoch [1411/10000], Loss: 55.0675\n",
      "Epoch [1412/10000], Loss: 54.6556\n",
      "Epoch [1413/10000], Loss: 54.1916\n",
      "Epoch [1414/10000], Loss: 54.3305\n",
      "Epoch [1415/10000], Loss: 54.5396\n",
      "Epoch [1416/10000], Loss: 54.2959\n",
      "Epoch [1417/10000], Loss: 53.9514\n",
      "Epoch [1418/10000], Loss: 54.0188\n",
      "Epoch [1419/10000], Loss: 54.1638\n",
      "Epoch [1420/10000], Loss: 53.9570\n",
      "Epoch [1421/10000], Loss: 53.7058\n",
      "Epoch [1422/10000], Loss: 53.7253\n",
      "Epoch [1423/10000], Loss: 53.7787\n",
      "Epoch [1424/10000], Loss: 53.6356\n",
      "Epoch [1425/10000], Loss: 53.4586\n",
      "Epoch [1426/10000], Loss: 53.4465\n",
      "Epoch [1427/10000], Loss: 53.4748\n",
      "Epoch [1428/10000], Loss: 53.3670\n",
      "Epoch [1429/10000], Loss: 53.2171\n",
      "Epoch [1430/10000], Loss: 53.1624\n",
      "Epoch [1431/10000], Loss: 53.1649\n",
      "Epoch [1432/10000], Loss: 53.1028\n",
      "Epoch [1433/10000], Loss: 52.9864\n",
      "Epoch [1434/10000], Loss: 52.8977\n",
      "Epoch [1435/10000], Loss: 52.8700\n",
      "Epoch [1436/10000], Loss: 52.8380\n",
      "Epoch [1437/10000], Loss: 52.7544\n",
      "Epoch [1438/10000], Loss: 52.6554\n",
      "Epoch [1439/10000], Loss: 52.5851\n",
      "Epoch [1440/10000], Loss: 52.5441\n",
      "Epoch [1441/10000], Loss: 52.4955\n",
      "Epoch [1442/10000], Loss: 52.4183\n",
      "Epoch [1443/10000], Loss: 52.3367\n",
      "Epoch [1444/10000], Loss: 52.2657\n",
      "Epoch [1445/10000], Loss: 52.2108\n",
      "Epoch [1446/10000], Loss: 52.1634\n",
      "Epoch [1447/10000], Loss: 52.1043\n",
      "Epoch [1448/10000], Loss: 52.0341\n",
      "Epoch [1449/10000], Loss: 51.9542\n",
      "Epoch [1450/10000], Loss: 51.8817\n",
      "Epoch [1451/10000], Loss: 51.8194\n",
      "Epoch [1452/10000], Loss: 51.7625\n",
      "Epoch [1453/10000], Loss: 51.7074\n",
      "Epoch [1454/10000], Loss: 51.6434\n",
      "Epoch [1455/10000], Loss: 51.5789\n",
      "Epoch [1456/10000], Loss: 51.5066\n",
      "Epoch [1457/10000], Loss: 51.4352\n",
      "Epoch [1458/10000], Loss: 51.3640\n",
      "Epoch [1459/10000], Loss: 51.2975\n",
      "Epoch [1460/10000], Loss: 51.2352\n",
      "Epoch [1461/10000], Loss: 51.1743\n",
      "Epoch [1462/10000], Loss: 51.1144\n",
      "Epoch [1463/10000], Loss: 51.0517\n",
      "Epoch [1464/10000], Loss: 50.9885\n",
      "Epoch [1465/10000], Loss: 50.9220\n",
      "Epoch [1466/10000], Loss: 50.8555\n",
      "Epoch [1467/10000], Loss: 50.7875\n",
      "Epoch [1468/10000], Loss: 50.7186\n",
      "Epoch [1469/10000], Loss: 50.6488\n",
      "Epoch [1470/10000], Loss: 50.5791\n",
      "Epoch [1471/10000], Loss: 50.5106\n",
      "Epoch [1472/10000], Loss: 50.4410\n",
      "Epoch [1473/10000], Loss: 50.3728\n",
      "Epoch [1474/10000], Loss: 50.3050\n",
      "Epoch [1475/10000], Loss: 50.2379\n",
      "Epoch [1476/10000], Loss: 50.1715\n",
      "Epoch [1477/10000], Loss: 50.1056\n",
      "Epoch [1478/10000], Loss: 50.0418\n",
      "Epoch [1479/10000], Loss: 49.9819\n",
      "Epoch [1480/10000], Loss: 49.9283\n",
      "Epoch [1481/10000], Loss: 49.8858\n",
      "Epoch [1482/10000], Loss: 49.8722\n",
      "Epoch [1483/10000], Loss: 49.8947\n",
      "Epoch [1484/10000], Loss: 50.0051\n",
      "Epoch [1485/10000], Loss: 50.2628\n",
      "Epoch [1486/10000], Loss: 50.7522\n",
      "Epoch [1487/10000], Loss: 51.5248\n",
      "Epoch [1488/10000], Loss: 52.4837\n",
      "Epoch [1489/10000], Loss: 52.2058\n",
      "Epoch [1490/10000], Loss: 50.9941\n",
      "Epoch [1491/10000], Loss: 49.4646\n",
      "Epoch [1492/10000], Loss: 49.2643\n",
      "Epoch [1493/10000], Loss: 50.1172\n",
      "Epoch [1494/10000], Loss: 50.5083\n",
      "Epoch [1495/10000], Loss: 49.8399\n",
      "Epoch [1496/10000], Loss: 48.9729\n",
      "Epoch [1497/10000], Loss: 49.0198\n",
      "Epoch [1498/10000], Loss: 49.6237\n",
      "Epoch [1499/10000], Loss: 49.6769\n",
      "Epoch [1500/10000], Loss: 49.0361\n",
      "Epoch [1501/10000], Loss: 48.5950\n",
      "Epoch [1502/10000], Loss: 48.8165\n",
      "Epoch [1503/10000], Loss: 49.1150\n",
      "Epoch [1504/10000], Loss: 48.9131\n",
      "Epoch [1505/10000], Loss: 48.4672\n",
      "Epoch [1506/10000], Loss: 48.3273\n",
      "Epoch [1507/10000], Loss: 48.5188\n",
      "Epoch [1508/10000], Loss: 48.5873\n",
      "Epoch [1509/10000], Loss: 48.3307\n",
      "Epoch [1510/10000], Loss: 48.0747\n",
      "Epoch [1511/10000], Loss: 48.0743\n",
      "Epoch [1512/10000], Loss: 48.1778\n",
      "Epoch [1513/10000], Loss: 48.1233\n",
      "Epoch [1514/10000], Loss: 47.9263\n",
      "Epoch [1515/10000], Loss: 47.7703\n",
      "Epoch [1516/10000], Loss: 47.7598\n",
      "Epoch [1517/10000], Loss: 47.7889\n",
      "Epoch [1518/10000], Loss: 47.7299\n",
      "Epoch [1519/10000], Loss: 47.5917\n",
      "Epoch [1520/10000], Loss: 47.4726\n",
      "Epoch [1521/10000], Loss: 47.4404\n",
      "Epoch [1522/10000], Loss: 47.4424\n",
      "Epoch [1523/10000], Loss: 47.3901\n",
      "Epoch [1524/10000], Loss: 47.2802\n",
      "Epoch [1525/10000], Loss: 47.1767\n",
      "Epoch [1526/10000], Loss: 47.1276\n",
      "Epoch [1527/10000], Loss: 47.1079\n",
      "Epoch [1528/10000], Loss: 47.0651\n",
      "Epoch [1529/10000], Loss: 46.9821\n",
      "Epoch [1530/10000], Loss: 46.8855\n",
      "Epoch [1531/10000], Loss: 46.8126\n",
      "Epoch [1532/10000], Loss: 46.7691\n",
      "Epoch [1533/10000], Loss: 46.7283\n",
      "Epoch [1534/10000], Loss: 46.6739\n",
      "Epoch [1535/10000], Loss: 46.5946\n",
      "Epoch [1536/10000], Loss: 46.5166\n",
      "Epoch [1537/10000], Loss: 46.4491\n",
      "Epoch [1538/10000], Loss: 46.3940\n",
      "Epoch [1539/10000], Loss: 46.3452\n",
      "Epoch [1540/10000], Loss: 46.2884\n",
      "Epoch [1541/10000], Loss: 46.2271\n",
      "Epoch [1542/10000], Loss: 46.1561\n",
      "Epoch [1543/10000], Loss: 46.0875\n",
      "Epoch [1544/10000], Loss: 46.0231\n",
      "Epoch [1545/10000], Loss: 45.9659\n",
      "Epoch [1546/10000], Loss: 45.9136\n",
      "Epoch [1547/10000], Loss: 45.8585\n",
      "Epoch [1548/10000], Loss: 45.8027\n",
      "Epoch [1549/10000], Loss: 45.7403\n",
      "Epoch [1550/10000], Loss: 45.6773\n",
      "Epoch [1551/10000], Loss: 45.6111\n",
      "Epoch [1552/10000], Loss: 45.5429\n",
      "Epoch [1553/10000], Loss: 45.4759\n",
      "Epoch [1554/10000], Loss: 45.4106\n",
      "Epoch [1555/10000], Loss: 45.3479\n",
      "Epoch [1556/10000], Loss: 45.2883\n",
      "Epoch [1557/10000], Loss: 45.2319\n",
      "Epoch [1558/10000], Loss: 45.1779\n",
      "Epoch [1559/10000], Loss: 45.1289\n",
      "Epoch [1560/10000], Loss: 45.0816\n",
      "Epoch [1561/10000], Loss: 45.0520\n",
      "Epoch [1562/10000], Loss: 45.0320\n",
      "Epoch [1563/10000], Loss: 45.0545\n",
      "Epoch [1564/10000], Loss: 45.1352\n",
      "Epoch [1565/10000], Loss: 45.2979\n",
      "Epoch [1566/10000], Loss: 45.6017\n",
      "Epoch [1567/10000], Loss: 45.9914\n",
      "Epoch [1568/10000], Loss: 46.4966\n",
      "Epoch [1569/10000], Loss: 46.6901\n",
      "Epoch [1570/10000], Loss: 46.5640\n",
      "Epoch [1571/10000], Loss: 45.6915\n",
      "Epoch [1572/10000], Loss: 44.7398\n",
      "Epoch [1573/10000], Loss: 44.2679\n",
      "Epoch [1574/10000], Loss: 44.4672\n",
      "Epoch [1575/10000], Loss: 44.9533\n",
      "Epoch [1576/10000], Loss: 45.1407\n",
      "Epoch [1577/10000], Loss: 44.8271\n",
      "Epoch [1578/10000], Loss: 44.2591\n",
      "Epoch [1579/10000], Loss: 43.9321\n",
      "Epoch [1580/10000], Loss: 44.0088\n",
      "Epoch [1581/10000], Loss: 44.2734\n",
      "Epoch [1582/10000], Loss: 44.3774\n",
      "Epoch [1583/10000], Loss: 44.1520\n",
      "Epoch [1584/10000], Loss: 43.7993\n",
      "Epoch [1585/10000], Loss: 43.5938\n",
      "Epoch [1586/10000], Loss: 43.6247\n",
      "Epoch [1587/10000], Loss: 43.7702\n",
      "Epoch [1588/10000], Loss: 43.8363\n",
      "Epoch [1589/10000], Loss: 43.7361\n",
      "Epoch [1590/10000], Loss: 43.5103\n",
      "Epoch [1591/10000], Loss: 43.2912\n",
      "Epoch [1592/10000], Loss: 43.2091\n",
      "Epoch [1593/10000], Loss: 43.2448\n",
      "Epoch [1594/10000], Loss: 43.2852\n",
      "Epoch [1595/10000], Loss: 43.2621\n",
      "Epoch [1596/10000], Loss: 43.1486\n",
      "Epoch [1597/10000], Loss: 43.0086\n",
      "Epoch [1598/10000], Loss: 42.8796\n",
      "Epoch [1599/10000], Loss: 42.8185\n",
      "Epoch [1600/10000], Loss: 42.8126\n",
      "Epoch [1601/10000], Loss: 42.8028\n",
      "Epoch [1602/10000], Loss: 42.7725\n",
      "Epoch [1603/10000], Loss: 42.7051\n",
      "Epoch [1604/10000], Loss: 42.6155\n",
      "Epoch [1605/10000], Loss: 42.5206\n",
      "Epoch [1606/10000], Loss: 42.4263\n",
      "Epoch [1607/10000], Loss: 42.3646\n",
      "Epoch [1608/10000], Loss: 42.3297\n",
      "Epoch [1609/10000], Loss: 42.3009\n",
      "Epoch [1610/10000], Loss: 42.2677\n",
      "Epoch [1611/10000], Loss: 42.2119\n",
      "Epoch [1612/10000], Loss: 42.1538\n",
      "Epoch [1613/10000], Loss: 42.0831\n",
      "Epoch [1614/10000], Loss: 42.0168\n",
      "Epoch [1615/10000], Loss: 41.9492\n",
      "Epoch [1616/10000], Loss: 41.8874\n",
      "Epoch [1617/10000], Loss: 41.8217\n",
      "Epoch [1618/10000], Loss: 41.7624\n",
      "Epoch [1619/10000], Loss: 41.7022\n",
      "Epoch [1620/10000], Loss: 41.6472\n",
      "Epoch [1621/10000], Loss: 41.5927\n",
      "Epoch [1622/10000], Loss: 41.5461\n",
      "Epoch [1623/10000], Loss: 41.5091\n",
      "Epoch [1624/10000], Loss: 41.4889\n",
      "Epoch [1625/10000], Loss: 41.4946\n",
      "Epoch [1626/10000], Loss: 41.5495\n",
      "Epoch [1627/10000], Loss: 41.6843\n",
      "Epoch [1628/10000], Loss: 42.0420\n",
      "Epoch [1629/10000], Loss: 42.5917\n",
      "Epoch [1630/10000], Loss: 43.6575\n",
      "Epoch [1631/10000], Loss: 44.5700\n",
      "Epoch [1632/10000], Loss: 45.2099\n",
      "Epoch [1633/10000], Loss: 43.7264\n",
      "Epoch [1634/10000], Loss: 41.8001\n",
      "Epoch [1635/10000], Loss: 40.8362\n",
      "Epoch [1636/10000], Loss: 41.5783\n",
      "Epoch [1637/10000], Loss: 42.6343\n",
      "Epoch [1638/10000], Loss: 42.1947\n",
      "Epoch [1639/10000], Loss: 41.0440\n",
      "Epoch [1640/10000], Loss: 40.6335\n",
      "Epoch [1641/10000], Loss: 41.2324\n",
      "Epoch [1642/10000], Loss: 41.6523\n",
      "Epoch [1643/10000], Loss: 41.1115\n",
      "Epoch [1644/10000], Loss: 40.4668\n",
      "Epoch [1645/10000], Loss: 40.4582\n",
      "Epoch [1646/10000], Loss: 40.8629\n",
      "Epoch [1647/10000], Loss: 40.9633\n",
      "Epoch [1648/10000], Loss: 40.5080\n",
      "Epoch [1649/10000], Loss: 40.1502\n",
      "Epoch [1650/10000], Loss: 40.2291\n",
      "Epoch [1651/10000], Loss: 40.4907\n",
      "Epoch [1652/10000], Loss: 40.5613\n",
      "Epoch [1653/10000], Loss: 40.2415\n",
      "Epoch [1654/10000], Loss: 39.9362\n",
      "Epoch [1655/10000], Loss: 39.8803\n",
      "Epoch [1656/10000], Loss: 40.0097\n",
      "Epoch [1657/10000], Loss: 40.0902\n",
      "Epoch [1658/10000], Loss: 39.9552\n",
      "Epoch [1659/10000], Loss: 39.7469\n",
      "Epoch [1660/10000], Loss: 39.6063\n",
      "Epoch [1661/10000], Loss: 39.5919\n",
      "Epoch [1662/10000], Loss: 39.6241\n",
      "Epoch [1663/10000], Loss: 39.6114\n",
      "Epoch [1664/10000], Loss: 39.5314\n",
      "Epoch [1665/10000], Loss: 39.4102\n",
      "Epoch [1666/10000], Loss: 39.3159\n",
      "Epoch [1667/10000], Loss: 39.2787\n",
      "Epoch [1668/10000], Loss: 39.2787\n",
      "Epoch [1669/10000], Loss: 39.2729\n",
      "Epoch [1670/10000], Loss: 39.2246\n",
      "Epoch [1671/10000], Loss: 39.1453\n",
      "Epoch [1672/10000], Loss: 39.0517\n",
      "Epoch [1673/10000], Loss: 38.9760\n",
      "Epoch [1674/10000], Loss: 38.9266\n",
      "Epoch [1675/10000], Loss: 38.8991\n",
      "Epoch [1676/10000], Loss: 38.8782\n",
      "Epoch [1677/10000], Loss: 38.8568\n",
      "Epoch [1678/10000], Loss: 38.8230\n",
      "Epoch [1679/10000], Loss: 38.7731\n",
      "Epoch [1680/10000], Loss: 38.7135\n",
      "Epoch [1681/10000], Loss: 38.6463\n",
      "Epoch [1682/10000], Loss: 38.5797\n",
      "Epoch [1683/10000], Loss: 38.5175\n",
      "Epoch [1684/10000], Loss: 38.4592\n",
      "Epoch [1685/10000], Loss: 38.4036\n",
      "Epoch [1686/10000], Loss: 38.3502\n",
      "Epoch [1687/10000], Loss: 38.2997\n",
      "Epoch [1688/10000], Loss: 38.2500\n",
      "Epoch [1689/10000], Loss: 38.2012\n",
      "Epoch [1690/10000], Loss: 38.1528\n",
      "Epoch [1691/10000], Loss: 38.1052\n",
      "Epoch [1692/10000], Loss: 38.0578\n",
      "Epoch [1693/10000], Loss: 38.0116\n",
      "Epoch [1694/10000], Loss: 37.9670\n",
      "Epoch [1695/10000], Loss: 37.9247\n",
      "Epoch [1696/10000], Loss: 37.8888\n",
      "Epoch [1697/10000], Loss: 37.8608\n",
      "Epoch [1698/10000], Loss: 37.8545\n",
      "Epoch [1699/10000], Loss: 37.8861\n",
      "Epoch [1700/10000], Loss: 37.9914\n",
      "Epoch [1701/10000], Loss: 38.2220\n",
      "Epoch [1702/10000], Loss: 38.6273\n",
      "Epoch [1703/10000], Loss: 39.1212\n",
      "Epoch [1704/10000], Loss: 39.7173\n",
      "Epoch [1705/10000], Loss: 39.8832\n",
      "Epoch [1706/10000], Loss: 39.6972\n",
      "Epoch [1707/10000], Loss: 38.8313\n",
      "Epoch [1708/10000], Loss: 37.9019\n",
      "Epoch [1709/10000], Loss: 37.3108\n",
      "Epoch [1710/10000], Loss: 37.3550\n",
      "Epoch [1711/10000], Loss: 37.8265\n",
      "Epoch [1712/10000], Loss: 38.1342\n",
      "Epoch [1713/10000], Loss: 38.1272\n",
      "Epoch [1714/10000], Loss: 37.6199\n",
      "Epoch [1715/10000], Loss: 37.1639\n",
      "Epoch [1716/10000], Loss: 36.9764\n",
      "Epoch [1717/10000], Loss: 37.1188\n",
      "Epoch [1718/10000], Loss: 37.4132\n",
      "Epoch [1719/10000], Loss: 37.5210\n",
      "Epoch [1720/10000], Loss: 37.4402\n",
      "Epoch [1721/10000], Loss: 37.1179\n",
      "Epoch [1722/10000], Loss: 36.8328\n",
      "Epoch [1723/10000], Loss: 36.6754\n",
      "Epoch [1724/10000], Loss: 36.6505\n",
      "Epoch [1725/10000], Loss: 36.7122\n",
      "Epoch [1726/10000], Loss: 36.8021\n",
      "Epoch [1727/10000], Loss: 36.8711\n",
      "Epoch [1728/10000], Loss: 36.8634\n",
      "Epoch [1729/10000], Loss: 36.7629\n",
      "Epoch [1730/10000], Loss: 36.6090\n",
      "Epoch [1731/10000], Loss: 36.4563\n",
      "Epoch [1732/10000], Loss: 36.3297\n",
      "Epoch [1733/10000], Loss: 36.2481\n",
      "Epoch [1734/10000], Loss: 36.2194\n",
      "Epoch [1735/10000], Loss: 36.2265\n",
      "Epoch [1736/10000], Loss: 36.2465\n",
      "Epoch [1737/10000], Loss: 36.2530\n",
      "Epoch [1738/10000], Loss: 36.2573\n",
      "Epoch [1739/10000], Loss: 36.2332\n",
      "Epoch [1740/10000], Loss: 36.1902\n",
      "Epoch [1741/10000], Loss: 36.1271\n",
      "Epoch [1742/10000], Loss: 36.0588\n",
      "Epoch [1743/10000], Loss: 35.9757\n",
      "Epoch [1744/10000], Loss: 35.8923\n",
      "Epoch [1745/10000], Loss: 35.8079\n",
      "Epoch [1746/10000], Loss: 35.7355\n",
      "Epoch [1747/10000], Loss: 35.6745\n",
      "Epoch [1748/10000], Loss: 35.6240\n",
      "Epoch [1749/10000], Loss: 35.5840\n",
      "Epoch [1750/10000], Loss: 35.5520\n",
      "Epoch [1751/10000], Loss: 35.5303\n",
      "Epoch [1752/10000], Loss: 35.5154\n",
      "Epoch [1753/10000], Loss: 35.5121\n",
      "Epoch [1754/10000], Loss: 35.5209\n",
      "Epoch [1755/10000], Loss: 35.5488\n",
      "Epoch [1756/10000], Loss: 35.5824\n",
      "Epoch [1757/10000], Loss: 35.6317\n",
      "Epoch [1758/10000], Loss: 35.6937\n",
      "Epoch [1759/10000], Loss: 35.7918\n",
      "Epoch [1760/10000], Loss: 35.9165\n",
      "Epoch [1761/10000], Loss: 36.0722\n",
      "Epoch [1762/10000], Loss: 36.2291\n",
      "Epoch [1763/10000], Loss: 36.3748\n",
      "Epoch [1764/10000], Loss: 36.3832\n",
      "Epoch [1765/10000], Loss: 36.2709\n",
      "Epoch [1766/10000], Loss: 35.9494\n",
      "Epoch [1767/10000], Loss: 35.5386\n",
      "Epoch [1768/10000], Loss: 35.1197\n",
      "Epoch [1769/10000], Loss: 34.8397\n",
      "Epoch [1770/10000], Loss: 34.7724\n",
      "Epoch [1771/10000], Loss: 34.8769\n",
      "Epoch [1772/10000], Loss: 35.0269\n",
      "Epoch [1773/10000], Loss: 35.1168\n",
      "Epoch [1774/10000], Loss: 35.1319\n",
      "Epoch [1775/10000], Loss: 35.0147\n",
      "Epoch [1776/10000], Loss: 34.8498\n",
      "Epoch [1777/10000], Loss: 34.6586\n",
      "Epoch [1778/10000], Loss: 34.5081\n",
      "Epoch [1779/10000], Loss: 34.4243\n",
      "Epoch [1780/10000], Loss: 34.4132\n",
      "Epoch [1781/10000], Loss: 34.4453\n",
      "Epoch [1782/10000], Loss: 34.4823\n",
      "Epoch [1783/10000], Loss: 34.5228\n",
      "Epoch [1784/10000], Loss: 34.5386\n",
      "Epoch [1785/10000], Loss: 34.5517\n",
      "Epoch [1786/10000], Loss: 34.5157\n",
      "Epoch [1787/10000], Loss: 34.4746\n",
      "Epoch [1788/10000], Loss: 34.3869\n",
      "Epoch [1789/10000], Loss: 34.2952\n",
      "Epoch [1790/10000], Loss: 34.1923\n",
      "Epoch [1791/10000], Loss: 34.1075\n",
      "Epoch [1792/10000], Loss: 34.0212\n",
      "Epoch [1793/10000], Loss: 33.9474\n",
      "Epoch [1794/10000], Loss: 33.8893\n",
      "Epoch [1795/10000], Loss: 33.8436\n",
      "Epoch [1796/10000], Loss: 33.8056\n",
      "Epoch [1797/10000], Loss: 33.7739\n",
      "Epoch [1798/10000], Loss: 33.7472\n",
      "Epoch [1799/10000], Loss: 33.7271\n",
      "Epoch [1800/10000], Loss: 33.7173\n",
      "Epoch [1801/10000], Loss: 33.7262\n",
      "Epoch [1802/10000], Loss: 33.7781\n",
      "Epoch [1803/10000], Loss: 33.8958\n",
      "Epoch [1804/10000], Loss: 34.1514\n",
      "Epoch [1805/10000], Loss: 34.5350\n",
      "Epoch [1806/10000], Loss: 35.1432\n",
      "Epoch [1807/10000], Loss: 35.8514\n",
      "Epoch [1808/10000], Loss: 36.6034\n",
      "Epoch [1809/10000], Loss: 36.6911\n",
      "Epoch [1810/10000], Loss: 36.0848\n",
      "Epoch [1811/10000], Loss: 34.7041\n",
      "Epoch [1812/10000], Loss: 33.5702\n",
      "Epoch [1813/10000], Loss: 33.2614\n",
      "Epoch [1814/10000], Loss: 33.8138\n",
      "Epoch [1815/10000], Loss: 34.5811\n",
      "Epoch [1816/10000], Loss: 34.6978\n",
      "Epoch [1817/10000], Loss: 34.1922\n",
      "Epoch [1818/10000], Loss: 33.3847\n",
      "Epoch [1819/10000], Loss: 33.0584\n",
      "Epoch [1820/10000], Loss: 33.3382\n",
      "Epoch [1821/10000], Loss: 33.7280\n",
      "Epoch [1822/10000], Loss: 33.8189\n",
      "Epoch [1823/10000], Loss: 33.4658\n",
      "Epoch [1824/10000], Loss: 33.0479\n",
      "Epoch [1825/10000], Loss: 32.8720\n",
      "Epoch [1826/10000], Loss: 33.0292\n",
      "Epoch [1827/10000], Loss: 33.2826\n",
      "Epoch [1828/10000], Loss: 33.3124\n",
      "Epoch [1829/10000], Loss: 33.1418\n",
      "Epoch [1830/10000], Loss: 32.8511\n",
      "Epoch [1831/10000], Loss: 32.6888\n",
      "Epoch [1832/10000], Loss: 32.7110\n",
      "Epoch [1833/10000], Loss: 32.8366\n",
      "Epoch [1834/10000], Loss: 32.9420\n",
      "Epoch [1835/10000], Loss: 32.9227\n",
      "Epoch [1836/10000], Loss: 32.7935\n",
      "Epoch [1837/10000], Loss: 32.6129\n",
      "Epoch [1838/10000], Loss: 32.4907\n",
      "Epoch [1839/10000], Loss: 32.4564\n",
      "Epoch [1840/10000], Loss: 32.4900\n",
      "Epoch [1841/10000], Loss: 32.5356\n",
      "Epoch [1842/10000], Loss: 32.5461\n",
      "Epoch [1843/10000], Loss: 32.5062\n",
      "Epoch [1844/10000], Loss: 32.4235\n",
      "Epoch [1845/10000], Loss: 32.3312\n",
      "Epoch [1846/10000], Loss: 32.2584\n",
      "Epoch [1847/10000], Loss: 32.2160\n",
      "Epoch [1848/10000], Loss: 32.2030\n",
      "Epoch [1849/10000], Loss: 32.2050\n",
      "Epoch [1850/10000], Loss: 32.2027\n",
      "Epoch [1851/10000], Loss: 32.1913\n",
      "Epoch [1852/10000], Loss: 32.1673\n",
      "Epoch [1853/10000], Loss: 32.1319\n",
      "Epoch [1854/10000], Loss: 32.0900\n",
      "Epoch [1855/10000], Loss: 32.0423\n",
      "Epoch [1856/10000], Loss: 31.9916\n",
      "Epoch [1857/10000], Loss: 31.9458\n",
      "Epoch [1858/10000], Loss: 31.9063\n",
      "Epoch [1859/10000], Loss: 31.8746\n",
      "Epoch [1860/10000], Loss: 31.8498\n",
      "Epoch [1861/10000], Loss: 31.8280\n",
      "Epoch [1862/10000], Loss: 31.8061\n",
      "Epoch [1863/10000], Loss: 31.7841\n",
      "Epoch [1864/10000], Loss: 31.7617\n",
      "Epoch [1865/10000], Loss: 31.7399\n",
      "Epoch [1866/10000], Loss: 31.7179\n",
      "Epoch [1867/10000], Loss: 31.6964\n",
      "Epoch [1868/10000], Loss: 31.6748\n",
      "Epoch [1869/10000], Loss: 31.6570\n",
      "Epoch [1870/10000], Loss: 31.6402\n",
      "Epoch [1871/10000], Loss: 31.6304\n",
      "Epoch [1872/10000], Loss: 31.6318\n",
      "Epoch [1873/10000], Loss: 31.6489\n",
      "Epoch [1874/10000], Loss: 31.6820\n",
      "Epoch [1875/10000], Loss: 31.7648\n",
      "Epoch [1876/10000], Loss: 31.8678\n",
      "Epoch [1877/10000], Loss: 32.0109\n",
      "Epoch [1878/10000], Loss: 32.1826\n",
      "Epoch [1879/10000], Loss: 32.3532\n",
      "Epoch [1880/10000], Loss: 32.5477\n",
      "Epoch [1881/10000], Loss: 32.6817\n",
      "Epoch [1882/10000], Loss: 32.7091\n",
      "Epoch [1883/10000], Loss: 32.5682\n",
      "Epoch [1884/10000], Loss: 32.2744\n",
      "Epoch [1885/10000], Loss: 31.8646\n",
      "Epoch [1886/10000], Loss: 31.4839\n",
      "Epoch [1887/10000], Loss: 31.2248\n",
      "Epoch [1888/10000], Loss: 31.1097\n",
      "Epoch [1889/10000], Loss: 31.1139\n",
      "Epoch [1890/10000], Loss: 31.2021\n",
      "Epoch [1891/10000], Loss: 31.3342\n",
      "Epoch [1892/10000], Loss: 31.4520\n",
      "Epoch [1893/10000], Loss: 31.5107\n",
      "Epoch [1894/10000], Loss: 31.4787\n",
      "Epoch [1895/10000], Loss: 31.3713\n",
      "Epoch [1896/10000], Loss: 31.2188\n",
      "Epoch [1897/10000], Loss: 31.0613\n",
      "Epoch [1898/10000], Loss: 30.9301\n",
      "Epoch [1899/10000], Loss: 30.8534\n",
      "Epoch [1900/10000], Loss: 30.8200\n",
      "Epoch [1901/10000], Loss: 30.8196\n",
      "Epoch [1902/10000], Loss: 30.8413\n",
      "Epoch [1903/10000], Loss: 30.8712\n",
      "Epoch [1904/10000], Loss: 30.9117\n",
      "Epoch [1905/10000], Loss: 30.9241\n",
      "Epoch [1906/10000], Loss: 30.9276\n",
      "Epoch [1907/10000], Loss: 30.9077\n",
      "Epoch [1908/10000], Loss: 30.8796\n",
      "Epoch [1909/10000], Loss: 30.8358\n",
      "Epoch [1910/10000], Loss: 30.7904\n",
      "Epoch [1911/10000], Loss: 30.7293\n",
      "Epoch [1912/10000], Loss: 30.6815\n",
      "Epoch [1913/10000], Loss: 30.6263\n",
      "Epoch [1914/10000], Loss: 30.5840\n",
      "Epoch [1915/10000], Loss: 30.5378\n",
      "Epoch [1916/10000], Loss: 30.5031\n",
      "Epoch [1917/10000], Loss: 30.4682\n",
      "Epoch [1918/10000], Loss: 30.4371\n",
      "Epoch [1919/10000], Loss: 30.4069\n",
      "Epoch [1920/10000], Loss: 30.3780\n",
      "Epoch [1921/10000], Loss: 30.3508\n",
      "Epoch [1922/10000], Loss: 30.3244\n",
      "Epoch [1923/10000], Loss: 30.2991\n",
      "Epoch [1924/10000], Loss: 30.2743\n",
      "Epoch [1925/10000], Loss: 30.2512\n",
      "Epoch [1926/10000], Loss: 30.2291\n",
      "Epoch [1927/10000], Loss: 30.2075\n",
      "Epoch [1928/10000], Loss: 30.1865\n",
      "Epoch [1929/10000], Loss: 30.1659\n",
      "Epoch [1930/10000], Loss: 30.1465\n",
      "Epoch [1931/10000], Loss: 30.1289\n",
      "Epoch [1932/10000], Loss: 30.1148\n",
      "Epoch [1933/10000], Loss: 30.1078\n",
      "Epoch [1934/10000], Loss: 30.1104\n",
      "Epoch [1935/10000], Loss: 30.1237\n",
      "Epoch [1936/10000], Loss: 30.1604\n",
      "Epoch [1937/10000], Loss: 30.2379\n",
      "Epoch [1938/10000], Loss: 30.4100\n",
      "Epoch [1939/10000], Loss: 30.7547\n",
      "Epoch [1940/10000], Loss: 31.4316\n",
      "Epoch [1941/10000], Loss: 32.6615\n",
      "Epoch [1942/10000], Loss: 34.7501\n",
      "Epoch [1943/10000], Loss: 36.8637\n",
      "Epoch [1944/10000], Loss: 38.3223\n",
      "Epoch [1945/10000], Loss: 35.7019\n",
      "Epoch [1946/10000], Loss: 31.7468\n",
      "Epoch [1947/10000], Loss: 29.8107\n",
      "Epoch [1948/10000], Loss: 31.3278\n",
      "Epoch [1949/10000], Loss: 33.4210\n",
      "Epoch [1950/10000], Loss: 32.6166\n",
      "Epoch [1951/10000], Loss: 30.4342\n",
      "Epoch [1952/10000], Loss: 29.8430\n",
      "Epoch [1953/10000], Loss: 31.2109\n",
      "Epoch [1954/10000], Loss: 31.9790\n",
      "Epoch [1955/10000], Loss: 30.7917\n",
      "Epoch [1956/10000], Loss: 29.6979\n",
      "Epoch [1957/10000], Loss: 30.1712\n",
      "Epoch [1958/10000], Loss: 30.9876\n",
      "Epoch [1959/10000], Loss: 30.6666\n",
      "Epoch [1960/10000], Loss: 29.7716\n",
      "Epoch [1961/10000], Loss: 29.7005\n",
      "Epoch [1962/10000], Loss: 30.3023\n",
      "Epoch [1963/10000], Loss: 30.4466\n",
      "Epoch [1964/10000], Loss: 29.8780\n",
      "Epoch [1965/10000], Loss: 29.5238\n",
      "Epoch [1966/10000], Loss: 29.7728\n",
      "Epoch [1967/10000], Loss: 30.0203\n",
      "Epoch [1968/10000], Loss: 29.8269\n",
      "Epoch [1969/10000], Loss: 29.4969\n",
      "Epoch [1970/10000], Loss: 29.5057\n",
      "Epoch [1971/10000], Loss: 29.7185\n",
      "Epoch [1972/10000], Loss: 29.7354\n",
      "Epoch [1973/10000], Loss: 29.5132\n",
      "Epoch [1974/10000], Loss: 29.3749\n",
      "Epoch [1975/10000], Loss: 29.4654\n",
      "Epoch [1976/10000], Loss: 29.5556\n",
      "Epoch [1977/10000], Loss: 29.4792\n",
      "Epoch [1978/10000], Loss: 29.3325\n",
      "Epoch [1979/10000], Loss: 29.3090\n",
      "Epoch [1980/10000], Loss: 29.3846\n",
      "Epoch [1981/10000], Loss: 29.3952\n",
      "Epoch [1982/10000], Loss: 29.3194\n",
      "Epoch [1983/10000], Loss: 29.2345\n",
      "Epoch [1984/10000], Loss: 29.2254\n",
      "Epoch [1985/10000], Loss: 29.2685\n",
      "Epoch [1986/10000], Loss: 29.2810\n",
      "Epoch [1987/10000], Loss: 29.2360\n",
      "Epoch [1988/10000], Loss: 29.1681\n",
      "Epoch [1989/10000], Loss: 29.1311\n",
      "Epoch [1990/10000], Loss: 29.1369\n",
      "Epoch [1991/10000], Loss: 29.1526\n",
      "Epoch [1992/10000], Loss: 29.1394\n",
      "Epoch [1993/10000], Loss: 29.0991\n",
      "Epoch [1994/10000], Loss: 29.0572\n",
      "Epoch [1995/10000], Loss: 29.0394\n",
      "Epoch [1996/10000], Loss: 29.0405\n",
      "Epoch [1997/10000], Loss: 29.0405\n",
      "Epoch [1998/10000], Loss: 29.0215\n",
      "Epoch [1999/10000], Loss: 28.9897\n",
      "Epoch [2000/10000], Loss: 28.9612\n",
      "Epoch [2001/10000], Loss: 28.9452\n",
      "Epoch [2002/10000], Loss: 28.9383\n",
      "Epoch [2003/10000], Loss: 28.9319\n",
      "Epoch [2004/10000], Loss: 28.9168\n",
      "Epoch [2005/10000], Loss: 28.8951\n",
      "Epoch [2006/10000], Loss: 28.8720\n",
      "Epoch [2007/10000], Loss: 28.8533\n",
      "Epoch [2008/10000], Loss: 28.8405\n",
      "Epoch [2009/10000], Loss: 28.8305\n",
      "Epoch [2010/10000], Loss: 28.8181\n",
      "Epoch [2011/10000], Loss: 28.8021\n",
      "Epoch [2012/10000], Loss: 28.7844\n",
      "Epoch [2013/10000], Loss: 28.7664\n",
      "Epoch [2014/10000], Loss: 28.7499\n",
      "Epoch [2015/10000], Loss: 28.7357\n",
      "Epoch [2016/10000], Loss: 28.7232\n",
      "Epoch [2017/10000], Loss: 28.7109\n",
      "Epoch [2018/10000], Loss: 28.6979\n",
      "Epoch [2019/10000], Loss: 28.6832\n",
      "Epoch [2020/10000], Loss: 28.6673\n",
      "Epoch [2021/10000], Loss: 28.6510\n",
      "Epoch [2022/10000], Loss: 28.6351\n",
      "Epoch [2023/10000], Loss: 28.6201\n",
      "Epoch [2024/10000], Loss: 28.6060\n",
      "Epoch [2025/10000], Loss: 28.5923\n",
      "Epoch [2026/10000], Loss: 28.5790\n",
      "Epoch [2027/10000], Loss: 28.5659\n",
      "Epoch [2028/10000], Loss: 28.5526\n",
      "Epoch [2029/10000], Loss: 28.5391\n",
      "Epoch [2030/10000], Loss: 28.5253\n",
      "Epoch [2031/10000], Loss: 28.5113\n",
      "Epoch [2032/10000], Loss: 28.4971\n",
      "Epoch [2033/10000], Loss: 28.4830\n",
      "Epoch [2034/10000], Loss: 28.4688\n",
      "Epoch [2035/10000], Loss: 28.4545\n",
      "Epoch [2036/10000], Loss: 28.4408\n",
      "Epoch [2037/10000], Loss: 28.4277\n",
      "Epoch [2038/10000], Loss: 28.4150\n",
      "Epoch [2039/10000], Loss: 28.4022\n",
      "Epoch [2040/10000], Loss: 28.3894\n",
      "Epoch [2041/10000], Loss: 28.3760\n",
      "Epoch [2042/10000], Loss: 28.3631\n",
      "Epoch [2043/10000], Loss: 28.3503\n",
      "Epoch [2044/10000], Loss: 28.3378\n",
      "Epoch [2045/10000], Loss: 28.3263\n",
      "Epoch [2046/10000], Loss: 28.3160\n",
      "Epoch [2047/10000], Loss: 28.3072\n",
      "Epoch [2048/10000], Loss: 28.2996\n",
      "Epoch [2049/10000], Loss: 28.2949\n",
      "Epoch [2050/10000], Loss: 28.2912\n",
      "Epoch [2051/10000], Loss: 28.2862\n",
      "Epoch [2052/10000], Loss: 28.2842\n",
      "Epoch [2053/10000], Loss: 28.2816\n",
      "Epoch [2054/10000], Loss: 28.2848\n",
      "Epoch [2055/10000], Loss: 28.2898\n",
      "Epoch [2056/10000], Loss: 28.3074\n",
      "Epoch [2057/10000], Loss: 28.3371\n",
      "Epoch [2058/10000], Loss: 28.3891\n",
      "Epoch [2059/10000], Loss: 28.4706\n",
      "Epoch [2060/10000], Loss: 28.6090\n",
      "Epoch [2061/10000], Loss: 28.8204\n",
      "Epoch [2062/10000], Loss: 29.1226\n",
      "Epoch [2063/10000], Loss: 29.5121\n",
      "Epoch [2064/10000], Loss: 30.0318\n",
      "Epoch [2065/10000], Loss: 30.5632\n",
      "Epoch [2066/10000], Loss: 31.0478\n",
      "Epoch [2067/10000], Loss: 31.0945\n",
      "Epoch [2068/10000], Loss: 30.6666\n",
      "Epoch [2069/10000], Loss: 29.6948\n",
      "Epoch [2070/10000], Loss: 28.6675\n",
      "Epoch [2071/10000], Loss: 28.0670\n",
      "Epoch [2072/10000], Loss: 28.0955\n",
      "Epoch [2073/10000], Loss: 28.5566\n",
      "Epoch [2074/10000], Loss: 29.0416\n",
      "Epoch [2075/10000], Loss: 29.2013\n",
      "Epoch [2076/10000], Loss: 28.9182\n",
      "Epoch [2077/10000], Loss: 28.4137\n",
      "Epoch [2078/10000], Loss: 28.0186\n",
      "Epoch [2079/10000], Loss: 27.9478\n",
      "Epoch [2080/10000], Loss: 28.1512\n",
      "Epoch [2081/10000], Loss: 28.4071\n",
      "Epoch [2082/10000], Loss: 28.4976\n",
      "Epoch [2083/10000], Loss: 28.3649\n",
      "Epoch [2084/10000], Loss: 28.1107\n",
      "Epoch [2085/10000], Loss: 27.9103\n",
      "Epoch [2086/10000], Loss: 27.8619\n",
      "Epoch [2087/10000], Loss: 27.9403\n",
      "Epoch [2088/10000], Loss: 28.0516\n",
      "Epoch [2089/10000], Loss: 28.1128\n",
      "Epoch [2090/10000], Loss: 28.0774\n",
      "Epoch [2091/10000], Loss: 27.9735\n",
      "Epoch [2092/10000], Loss: 27.8561\n",
      "Epoch [2093/10000], Loss: 27.7890\n",
      "Epoch [2094/10000], Loss: 27.7820\n",
      "Epoch [2095/10000], Loss: 27.8169\n",
      "Epoch [2096/10000], Loss: 27.8667\n",
      "Epoch [2097/10000], Loss: 27.8864\n",
      "Epoch [2098/10000], Loss: 27.8707\n",
      "Epoch [2099/10000], Loss: 27.8187\n",
      "Epoch [2100/10000], Loss: 27.7627\n",
      "Epoch [2101/10000], Loss: 27.7185\n",
      "Epoch [2102/10000], Loss: 27.6939\n",
      "Epoch [2103/10000], Loss: 27.6892\n",
      "Epoch [2104/10000], Loss: 27.6962\n",
      "Epoch [2105/10000], Loss: 27.7054\n",
      "Epoch [2106/10000], Loss: 27.7131\n",
      "Epoch [2107/10000], Loss: 27.7099\n",
      "Epoch [2108/10000], Loss: 27.6991\n",
      "Epoch [2109/10000], Loss: 27.6791\n",
      "Epoch [2110/10000], Loss: 27.6561\n",
      "Epoch [2111/10000], Loss: 27.6311\n",
      "Epoch [2112/10000], Loss: 27.6088\n",
      "Epoch [2113/10000], Loss: 27.5912\n",
      "Epoch [2114/10000], Loss: 27.5791\n",
      "Epoch [2115/10000], Loss: 27.5717\n",
      "Epoch [2116/10000], Loss: 27.5671\n",
      "Epoch [2117/10000], Loss: 27.5633\n",
      "Epoch [2118/10000], Loss: 27.5589\n",
      "Epoch [2119/10000], Loss: 27.5533\n",
      "Epoch [2120/10000], Loss: 27.5464\n",
      "Epoch [2121/10000], Loss: 27.5384\n",
      "Epoch [2122/10000], Loss: 27.5282\n",
      "Epoch [2123/10000], Loss: 27.5173\n",
      "Epoch [2124/10000], Loss: 27.5059\n",
      "Epoch [2125/10000], Loss: 27.4937\n",
      "Epoch [2126/10000], Loss: 27.4818\n",
      "Epoch [2127/10000], Loss: 27.4712\n",
      "Epoch [2128/10000], Loss: 27.4609\n",
      "Epoch [2129/10000], Loss: 27.4514\n",
      "Epoch [2130/10000], Loss: 27.4424\n",
      "Epoch [2131/10000], Loss: 27.4335\n",
      "Epoch [2132/10000], Loss: 27.4244\n",
      "Epoch [2133/10000], Loss: 27.4154\n",
      "Epoch [2134/10000], Loss: 27.4064\n",
      "Epoch [2135/10000], Loss: 27.3986\n",
      "Epoch [2136/10000], Loss: 27.3914\n",
      "Epoch [2137/10000], Loss: 27.3849\n",
      "Epoch [2138/10000], Loss: 27.3801\n",
      "Epoch [2139/10000], Loss: 27.3774\n",
      "Epoch [2140/10000], Loss: 27.3781\n",
      "Epoch [2141/10000], Loss: 27.3848\n",
      "Epoch [2142/10000], Loss: 27.4040\n",
      "Epoch [2143/10000], Loss: 27.4378\n",
      "Epoch [2144/10000], Loss: 27.4996\n",
      "Epoch [2145/10000], Loss: 27.6070\n",
      "Epoch [2146/10000], Loss: 27.7956\n",
      "Epoch [2147/10000], Loss: 28.1114\n",
      "Epoch [2148/10000], Loss: 28.6574\n",
      "Epoch [2149/10000], Loss: 29.4660\n",
      "Epoch [2150/10000], Loss: 30.6261\n",
      "Epoch [2151/10000], Loss: 31.7436\n",
      "Epoch [2152/10000], Loss: 32.5801\n",
      "Epoch [2153/10000], Loss: 32.1357\n",
      "Epoch [2154/10000], Loss: 30.4677\n",
      "Epoch [2155/10000], Loss: 28.2906\n",
      "Epoch [2156/10000], Loss: 27.2449\n",
      "Epoch [2157/10000], Loss: 27.7991\n",
      "Epoch [2158/10000], Loss: 28.9976\n",
      "Epoch [2159/10000], Loss: 29.5182\n",
      "Epoch [2160/10000], Loss: 28.7952\n",
      "Epoch [2161/10000], Loss: 27.6469\n",
      "Epoch [2162/10000], Loss: 27.2111\n",
      "Epoch [2163/10000], Loss: 27.7398\n",
      "Epoch [2164/10000], Loss: 28.4225\n",
      "Epoch [2165/10000], Loss: 28.3720\n",
      "Epoch [2166/10000], Loss: 27.7075\n",
      "Epoch [2167/10000], Loss: 27.1955\n",
      "Epoch [2168/10000], Loss: 27.3309\n",
      "Epoch [2169/10000], Loss: 27.7919\n",
      "Epoch [2170/10000], Loss: 27.9216\n",
      "Epoch [2171/10000], Loss: 27.6127\n",
      "Epoch [2172/10000], Loss: 27.2177\n",
      "Epoch [2173/10000], Loss: 27.1555\n",
      "Epoch [2174/10000], Loss: 27.3948\n",
      "Epoch [2175/10000], Loss: 27.5618\n",
      "Epoch [2176/10000], Loss: 27.4754\n",
      "Epoch [2177/10000], Loss: 27.2245\n",
      "Epoch [2178/10000], Loss: 27.0951\n",
      "Epoch [2179/10000], Loss: 27.1710\n",
      "Epoch [2180/10000], Loss: 27.3129\n",
      "Epoch [2181/10000], Loss: 27.3483\n",
      "Epoch [2182/10000], Loss: 27.2295\n",
      "Epoch [2183/10000], Loss: 27.0954\n",
      "Epoch [2184/10000], Loss: 27.0584\n",
      "Epoch [2185/10000], Loss: 27.1198\n",
      "Epoch [2186/10000], Loss: 27.1889\n",
      "Epoch [2187/10000], Loss: 27.1868\n",
      "Epoch [2188/10000], Loss: 27.1160\n",
      "Epoch [2189/10000], Loss: 27.0423\n",
      "Epoch [2190/10000], Loss: 27.0159\n",
      "Epoch [2191/10000], Loss: 27.0384\n",
      "Epoch [2192/10000], Loss: 27.0723\n",
      "Epoch [2193/10000], Loss: 27.0774\n",
      "Epoch [2194/10000], Loss: 27.0461\n",
      "Epoch [2195/10000], Loss: 27.0037\n",
      "Epoch [2196/10000], Loss: 26.9777\n",
      "Epoch [2197/10000], Loss: 26.9783\n",
      "Epoch [2198/10000], Loss: 26.9932\n",
      "Epoch [2199/10000], Loss: 27.0027\n",
      "Epoch [2200/10000], Loss: 26.9949\n",
      "Epoch [2201/10000], Loss: 26.9735\n",
      "Epoch [2202/10000], Loss: 26.9497\n",
      "Epoch [2203/10000], Loss: 26.9347\n",
      "Epoch [2204/10000], Loss: 26.9318\n",
      "Epoch [2205/10000], Loss: 26.9357\n",
      "Epoch [2206/10000], Loss: 26.9378\n",
      "Epoch [2207/10000], Loss: 26.9331\n",
      "Epoch [2208/10000], Loss: 26.9212\n",
      "Epoch [2209/10000], Loss: 26.9067\n",
      "Epoch [2210/10000], Loss: 26.8948\n",
      "Epoch [2211/10000], Loss: 26.8879\n",
      "Epoch [2212/10000], Loss: 26.8856\n",
      "Epoch [2213/10000], Loss: 26.8846\n",
      "Epoch [2214/10000], Loss: 26.8821\n",
      "Epoch [2215/10000], Loss: 26.8765\n",
      "Epoch [2216/10000], Loss: 26.8679\n",
      "Epoch [2217/10000], Loss: 26.8584\n",
      "Epoch [2218/10000], Loss: 26.8498\n",
      "Epoch [2219/10000], Loss: 26.8428\n",
      "Epoch [2220/10000], Loss: 26.8377\n",
      "Epoch [2221/10000], Loss: 26.8340\n",
      "Epoch [2222/10000], Loss: 26.8301\n",
      "Epoch [2223/10000], Loss: 26.8257\n",
      "Epoch [2224/10000], Loss: 26.8204\n",
      "Epoch [2225/10000], Loss: 26.8140\n",
      "Epoch [2226/10000], Loss: 26.8072\n",
      "Epoch [2227/10000], Loss: 26.8006\n",
      "Epoch [2228/10000], Loss: 26.7942\n",
      "Epoch [2229/10000], Loss: 26.7887\n",
      "Epoch [2230/10000], Loss: 26.7838\n",
      "Epoch [2231/10000], Loss: 26.7791\n",
      "Epoch [2232/10000], Loss: 26.7744\n",
      "Epoch [2233/10000], Loss: 26.7697\n",
      "Epoch [2234/10000], Loss: 26.7644\n",
      "Epoch [2235/10000], Loss: 26.7593\n",
      "Epoch [2236/10000], Loss: 26.7538\n",
      "Epoch [2237/10000], Loss: 26.7482\n",
      "Epoch [2238/10000], Loss: 26.7427\n",
      "Epoch [2239/10000], Loss: 26.7373\n",
      "Epoch [2240/10000], Loss: 26.7319\n",
      "Epoch [2241/10000], Loss: 26.7268\n",
      "Epoch [2242/10000], Loss: 26.7218\n",
      "Epoch [2243/10000], Loss: 26.7169\n",
      "Epoch [2244/10000], Loss: 26.7120\n",
      "Epoch [2245/10000], Loss: 26.7073\n",
      "Epoch [2246/10000], Loss: 26.7026\n",
      "Epoch [2247/10000], Loss: 26.6979\n",
      "Epoch [2248/10000], Loss: 26.6934\n",
      "Epoch [2249/10000], Loss: 26.6889\n",
      "Epoch [2250/10000], Loss: 26.6850\n",
      "Epoch [2251/10000], Loss: 26.6811\n",
      "Epoch [2252/10000], Loss: 26.6776\n",
      "Epoch [2253/10000], Loss: 26.6744\n",
      "Epoch [2254/10000], Loss: 26.6718\n",
      "Epoch [2255/10000], Loss: 26.6695\n",
      "Epoch [2256/10000], Loss: 26.6681\n",
      "Epoch [2257/10000], Loss: 26.6676\n",
      "Training completed, Epoch: 2258, Final Loss: 26.6680\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "num_epoch = 10000\n",
    "training_losses = []\n",
    "loss_history = []\n",
    "tolerance = 5\n",
    "xTrainTensor = torch.tensor(xTrainNumpy, dtype=torch.float32)\n",
    "yTrainTensor = torch.tensor(yTrainNumpy, dtype=torch.float32)\n",
    "for epoch in range(1,num_epoch+1):\n",
    "    predict = model(xTrainTensor)\n",
    "    loss = criterion(predict.squeeze(), yTrainTensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    current_loss:float = loss.item()\n",
    "    loss_history.append(round(current_loss, 2))\n",
    "    if len(loss_history)>5:\n",
    "        if all(loss_history[-1] == last_loss for last_loss in loss_history[-tolerance-1:-1]):\n",
    "            print(f\"Training completed, Epoch: {epoch}, Final Loss: {current_loss:.4f}\")\n",
    "            break\n",
    "    print(f'Epoch [{epoch}/{num_epoch}], Loss: {current_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))  \n",
    "plt.plot(loss_history, label='Loss History', color='blue')  \n",
    "plt.title('Loss History Over Epochs')  \n",
    "plt.xlabel('Epoch')  # X-axis label\n",
    "plt.ylabel('Loss')  # Y-axis label\n",
    "plt.legend()  \n",
    "plt.grid()  \n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaner(file_name):\n",
    "    train_df = pd.read_csv(file_name)\n",
    "    clean_df = train_df.drop([\"Gender\",\"Smoking Status\", \"Alcohol Consumption\", \"Diet\", \"Family History\", \"Mental Health Status\", \"Sleep Patterns\", \"Stress Levels\", \"Pollution Exposure\", \"Sun Exposure\", \"Income Level\"], axis='columns')\n",
    "    columns_with_empty_cells = clean_df.columns[clean_df.isna().any()].tolist()\n",
    "    i=1\n",
    "    \n",
    "    for col in columns_with_empty_cells:\n",
    "        clean_df[col] = clean_df[col].fillna(f\"None{i}\")\n",
    "        i+=1\n",
    "    clean_df[['Systolic Blood Pressure', 'Diastolic Blood Pressure']] = clean_df[\"Blood Pressure (s/d)\"].str.split('/', expand=True)\n",
    "    clean_df['Systolic Blood Pressure'] = clean_df['Systolic Blood Pressure'].astype(int)\n",
    "    clean_df['Diastolic Blood Pressure'] = clean_df['Diastolic Blood Pressure'].astype(int)\n",
    "    clean_df.pop(\"Blood Pressure (s/d)\")\n",
    "    get_dummy = [\"Chronic Diseases\",\"Medication Use\", \"Education Level\", \"Physical Activity Level\"]\n",
    "    \n",
    "    for dummy_column in get_dummy:\n",
    "        clean_df = pd.concat([clean_df,pd.get_dummies(clean_df[dummy_column])], axis=\"columns\")\n",
    "        clean_df.pop(dummy_column)\n",
    "    \n",
    "    xdf = clean_df\n",
    "    xNumpy = xdf.to_numpy()\n",
    "\n",
    "    \n",
    "    xNumpy = np.array(xNumpy, dtype=np.float32)  \n",
    "    xNumpy[xNumpy == True] = 1\n",
    "    xNumpy[xNumpy == False] = 0\n",
    "\n",
    "    xTensor = torch.tensor(xNumpy, dtype=torch.float32)\n",
    "\n",
    "    return xTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[171.1484,  86.1852, 259.4658,  ...,   0.0000,   0.0000,   1.0000],\n",
       "        [172.9462,  79.6419, 263.6303,  ...,   0.0000,   1.0000,   0.0000],\n",
       "        [155.9455,  49.1671, 207.8462,  ...,   0.0000,   0.0000,   1.0000],\n",
       "        ...,\n",
       "        [177.8577,  86.2589, 238.6415,  ...,   0.0000,   0.0000,   1.0000],\n",
       "        [162.2872,  41.3710, 198.2443,  ...,   0.0000,   0.0000,   1.0000],\n",
       "        [175.3417,  78.7180, 279.1182,  ...,   1.0000,   0.0000,   0.0000]])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTestTensor = data_cleaner(\"Test.csv\")\n",
    "xTestTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[87.9974],\n",
       "        [69.8477],\n",
       "        [73.3121],\n",
       "        [52.4340],\n",
       "        [76.4921],\n",
       "        [27.2247],\n",
       "        [80.0094],\n",
       "        [25.1503],\n",
       "        [56.1197],\n",
       "        [83.3820],\n",
       "        [80.4051],\n",
       "        [64.6561],\n",
       "        [71.3804],\n",
       "        [20.6265],\n",
       "        [47.9932],\n",
       "        [28.3483],\n",
       "        [58.9140],\n",
       "        [45.0237],\n",
       "        [73.8733],\n",
       "        [24.1365],\n",
       "        [30.3598],\n",
       "        [47.4267],\n",
       "        [31.7771],\n",
       "        [77.6068],\n",
       "        [43.8938],\n",
       "        [63.6615],\n",
       "        [40.2658],\n",
       "        [29.3742],\n",
       "        [85.9194],\n",
       "        [35.9477]])"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(xTestTensor[:30])\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
